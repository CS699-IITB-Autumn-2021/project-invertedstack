[
      {
            "data_id": "B1G5ViAqFm",
            "paper_title": "Convolutional Neural Networks on Non-uniform Geometrical Signals Using Euclidean Spectral Transformation",
            "forum_link": "https://openreview.net/forum?id=B1G5ViAqFm",
            "pdf_link": "https://openreview.net/pdf?id=B1G5ViAqFm",
            "authors": [
                  "Chiyu Max Jiang",
                  "Dequan Wang",
                  "Jingwei Huang",
                  "Philip Marcus",
                  "Matthias Niessner"
            ],
            "abstract": "Convolutional Neural Networks (CNN) have been successful in processing data signals that are uniformly sampled in the spatial domain (e.g., images). However, most data signals do not natively exist on a grid, and in the process of being sampled onto a uniform physical grid suffer significant aliasing error and information loss. Moreover, signals can exist in different topological structures as, for example, points, lines, surfaces and volumes. It has been challenging to analyze signals with mixed topologies (for example, point cloud with surface mesh). To this end, we develop mathematical formulations for Non-Uniform Fourier Transforms (NUFT) to directly, and optimally, sample nonuniform data signals of different topologies defined on a simplex mesh into the spectral domain with no spatial sampling error. The spectral transform is performed in the Euclidean space, which removes the translation ambiguity from works on the graph spectrum. Our representation has four distinct advantages: (1) the process causes no spatial sampling error during initial sampling, (2) the generality of this approach provides a unified framework for using CNNs to analyze signals of mixed topologies, (3) it allows us to leverage state-of-the-art backbone CNN architectures for effective learning without having to design a particular architecture for a particular data structure in an ad-hoc fashion, and (4) the representation allows weighted meshes where each element has a different weight (i.e., texture) indicating local properties. We achieve good results on-par with state-of-the-art for 3D shape retrieval task, and new state-of-the-art for point cloud to surface reconstruction task.",
            "keywords": "Non-uniform Fourier Transform, 3D Learning, CNN, surface reconstruction",
            "tl;dr": "We use non-Euclidean Fourier Transformation of shapes defined by a simplicial complex for deep learning, achieving significantly better results than point-based sampling techiques used in current 3D learning literature."
      },
      {
            "data_id": "B1G9doA9F7",
            "paper_title": "Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation",
            "forum_link": "https://openreview.net/forum?id=B1G9doA9F7",
            "pdf_link": "https://openreview.net/pdf?id=B1G9doA9F7",
            "authors": [
                  "Ehsan Hosseini-Asl",
                  "Yingbo Zhou",
                  "Caiming Xiong",
                  "Richard Socher"
            ],
            "abstract": "Training a model to perform a task typically requires a large amount of data from the domains in which the task will be applied.\n        However, it is often the case that data are abundant in some domains but scarce in others. Domain adaptation deals with the challenge of adapting a model trained from a data-rich source domain to perform well in a data-poor target domain. In general, this requires learning plausible mappings between domains. CycleGAN is a powerful framework that efficiently learns to map inputs from one domain to another using adversarial training and a cycle-consistency constraint. However, the conventional approach of enforcing cycle-consistency via reconstruction may be overly restrictive in cases where one or more domains have limited training data. In this paper, we propose an augmented cyclic adversarial learning model that enforces the cycle-consistency constraint via an external task specific model, which encourages the preservation of task-relevant content as opposed to exact reconstruction. We explore digit classification in a low-resource setting in supervised, semi and unsupervised situation, as well as high resource unsupervised. In low-resource supervised setting, the results show that our approach improves absolute performance by 14% and 4% when adapting SVHN to MNIST and vice versa, respectively, which outperforms unsupervised domain adaptation methods that require high-resource unlabeled target domain.  Moreover, using only few unsupervised target data, our approach can still outperforms many high-resource unsupervised models. Our model also outperforms on USPS to MNIST and synthetic digit to SVHN for high resource unsupervised adaptation. In speech domains, we similarly adopt a speech recognition model from each domain as the task specific model. Our approach improves absolute performance of speech recognition by 2% for female speakers in the TIMIT dataset, where the majority of training samples are from male voices.",
            "keywords": "Domain adaptation, generative adversarial network, cyclic adversarial learning, speech",
            "tl;dr": "A new cyclic adversarial learning augmented with auxiliary task model which improves domain adaptation performance in low resource supervised and unsupervised situations"
      },
      {
            "data_id": "B1GAUs0cKQ",
            "paper_title": "Variance Networks: When Expectation Does Not Meet Your Expectations",
            "forum_link": "https://openreview.net/forum?id=B1GAUs0cKQ",
            "pdf_link": "https://openreview.net/pdf?id=B1GAUs0cKQ",
            "authors": [
                  "Kirill Neklyudov",
                  "Dmitry Molchanov",
                  "Arsenii Ashukha",
                  "Dmitry Vetrov"
            ],
            "abstract": "Ordinary stochastic neural networks mostly rely on the expected values of their weights to make predictions, whereas the induced noise is mostly used to capture the uncertainty, prevent overfitting and slightly boost the performance through test-time averaging. In this paper, we introduce variance layers, a different kind of stochastic layers. Each weight of a variance layer follows a zero-mean distribution and is only parameterized by its variance. It means that each object is represented by a zero-mean distribution in the space of the activations. We show that such layers can learn surprisingly well, can serve as an efficient exploration tool in reinforcement learning tasks and provide a decent defense against adversarial attacks. We also show that a number of conventional Bayesian neural networks naturally converge to such zero-mean posteriors. We observe that in these cases such zero-mean parameterization leads to a much better training objective than more flexible conventional parameterizations where the mean is being learned.",
            "keywords": "deep learning, variational inference, variational dropout",
            "tl;dr": "It is possible to learn a zero-centered Gaussian distribution over the weights of a neural network by learning only variances, and it works surprisingly well."
      },
      {
            "data_id": "B1GMDsR5tm",
            "paper_title": "Initialized Equilibrium Propagation for Backprop-Free Training",
            "forum_link": "https://openreview.net/forum?id=B1GMDsR5tm",
            "pdf_link": "https://openreview.net/pdf?id=B1GMDsR5tm",
            "authors": [
                  "Peter O'Connor",
                  "Efstratios Gavves",
                  "Max Welling"
            ],
            "abstract": "Deep neural networks are almost universally trained with reverse-mode automatic differentiation (a.k.a. backpropagation). Biological networks, on the other hand, appear to lack any mechanism for sending gradients back to their input neurons, and thus cannot be learning in this way. In response to this, Scellier &amp; Bengio (2017) proposed Equilibrium Propagation - a method for gradient-based train- ing of neural networks which uses only local learning rules and, crucially, does not rely on neurons having a mechanism for back-propagating an error gradient. Equilibrium propagation, however, has a major practical limitation: inference involves doing an iterative optimization of neural activations to find a fixed-point, and the number of steps required to closely approximate this fixed point scales poorly with the depth of the network. In response to this problem, we propose Initialized Equilibrium Propagation, which trains a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. This feed-forward network learns to approximate the state of the fixed-point using a local learning rule. After training, we can simply use this initializing network for inference, resulting in a learned feedforward network. Our experiments show that this network appears to work as well or better than the original version of Equilibrium propagation. This shows how we might go about training deep networks without using backpropagation.",
            "keywords": "credit assignment, energy-based models, biologically plausible learning",
            "tl;dr": "We train a feedforward network without backprop by using an energy-based model to provide local targets"
      },
      {
            "data_id": "B1MXz20cYQ",
            "paper_title": "Explaining Image Classifiers by Counterfactual Generation",
            "forum_link": "https://openreview.net/forum?id=B1MXz20cYQ",
            "pdf_link": "https://openreview.net/pdf?id=B1MXz20cYQ",
            "authors": [
                  "Chun-Hao Chang",
                  "Elliot Creager",
                  "Anna Goldenberg",
                  "David Duvenaud"
            ],
            "abstract": "When an image classifier makes a prediction, which parts of the image are relevant and why? We can rephrase this question to ask: which parts of the image, if they were not seen by the classifier, would most change its decision? Producing an answer requires marginalizing over images that could have been seen but weren't. We can sample plausible image in-fills by conditioning a generative model on the rest of the image. We then optimize to find the image regions that most change the classifier's decision after in-fill. Our approach contrasts with ad-hoc in-filling approaches, such as blurring or injecting noise, which generate inputs far from the data distribution, and ignore informative relationships between different parts of the image. Our method produces more compact and relevant saliency maps, with fewer artifacts compared to previous methods.",
            "keywords": "Explainability, Interpretability, Generative Models, Saliency Map, Machine Learning, Deep Learning",
            "tl;dr": "We compute saliency by using a strong generative model to efficiently marginalize over plausible alternative inputs, revealing concentrated pixel areas that preserve label information."
      },
      {
            "data_id": "B1VZqjAcYX",
            "paper_title": "SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY",
            "forum_link": "https://openreview.net/forum?id=B1VZqjAcYX",
            "pdf_link": "https://openreview.net/pdf?id=B1VZqjAcYX",
            "authors": [
                  "Namhoon Lee",
                  "Thalaiyasingam Ajanthan",
                  "Philip Torr"
            ],
            "abstract": "Pruning large neural networks while maintaining their performance is often desirable due to the reduced space and time complexity. In existing methods, pruning is done within an iterative optimization procedure with either heuristically designed pruning schedules or additional hyperparameters, undermining their utility. In this work, we present a new approach that prunes a given network once at initialization prior to training. To achieve this, we introduce a saliency criterion based on connection sensitivity that identifies structurally important connections in the network for the given task. This eliminates the need for both pretraining and the complex pruning schedule while making it robust to architecture variations. After pruning, the sparse network is trained in the standard way. Our method obtains extremely sparse networks with virtually the same accuracy as the reference network on the MNIST, CIFAR-10, and Tiny-ImageNet classification tasks and is broadly applicable to various architectures including convolutional, residual and recurrent networks. Unlike existing methods, our approach enables us to demonstrate that the retained connections are indeed relevant to the given task.",
            "keywords": "neural network pruning, connection sensitivity",
            "tl;dr": "We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications."
      },
      {
            "data_id": "B1e0X3C9tQ",
            "paper_title": "Diagnosing and Enhancing VAE Models",
            "forum_link": "https://openreview.net/forum?id=B1e0X3C9tQ",
            "pdf_link": "https://openreview.net/pdf?id=B1e0X3C9tQ",
            "authors": [
                  "Bin Dai",
                  "David Wipf"
            ],
            "abstract": "Although variational autoencoders (VAEs) represent a widely influential deep generative model, many aspects of the underlying energy function remain poorly understood.  In particular, it is commonly believed that Gaussian encoder/decoder assumptions reduce the effectiveness of VAEs in generating realistic samples.  In this regard, we rigorously analyze the VAE objective, differentiating situations where this belief is and is not actually true.  We then leverage the corresponding insights to develop a simple VAE enhancement that requires no additional hyperparameters or sensitive tuning.  Quantitatively, this proposal produces crisp samples and stable FID scores that are actually competitive with a variety of GAN models, all while retaining desirable attributes of the original VAE architecture. The code for our model is available at \\url{https://github.com/daib13/TwoStageVAE}.",
            "keywords": "variational autoencoder, generative models",
            "tl;dr": "We closely analyze the VAE objective function and draw novel conclusions that lead to simple enhancements."
      },
      {
            "data_id": "B1exrnCcF7",
            "paper_title": "Disjoint Mapping Network for Cross-modal Matching of Voices and Faces",
            "forum_link": "https://openreview.net/forum?id=B1exrnCcF7",
            "pdf_link": "https://openreview.net/pdf?id=B1exrnCcF7",
            "authors": [
                  "Yandong Wen",
                  "Mahmoud Al Ismail",
                  "Weiyang Liu",
                  "Bhiksha Raj",
                  "Rita Singh"
            ],
            "abstract": "We propose a novel framework, called Disjoint Mapping Network (DIMNet), for cross-modal biometric matching, in particular of voices and faces. Different from the existing methods, DIMNet does not explicitly learn the joint relationship between the modalities. Instead, DIMNet learns a shared representation for different modalities by mapping them individually to their common covariates. These shared representations can then be used to find the correspondences between the modalities. We show empirically that DIMNet is able to achieve better performance than the current state-of-the-art methods, with the additional benefits of being conceptually simpler and less data-intensive.",
            "keywords": "cross-modal matching, voices, faces"
      },
      {
            "data_id": "B1ffQnRcKX",
            "paper_title": "Automatically Composing Representation Transformations as a Means for Generalization",
            "forum_link": "https://openreview.net/forum?id=B1ffQnRcKX",
            "pdf_link": "https://openreview.net/pdf?id=B1ffQnRcKX",
            "authors": [
                  "Michael Chang",
                  "Abhishek Gupta",
                  "Sergey Levine",
                  "Thomas L. Griffiths"
            ],
            "abstract": "A generally intelligent learner should generalize to more complex tasks than it has previously encountered, but the two common paradigms in machine learning -- either training a separate learner per task or training a single learner for all tasks -- both have difficulty with such generalization because they do not leverage  the compositional structure of the task distribution. This paper introduces the compositional problem graph as a broadly applicable formalism to relate tasks of different complexity in terms of problems with shared subproblems. We propose the compositional generalization problem for measuring how readily old knowledge can be reused and hence built upon. As a first step for tackling compositional generalization, we introduce the compositional recursive learner, a domain-general framework for learning algorithmic procedures for composing representation transformations, producing a learner that reasons about what computation to execute by making analogies to previously seen problems. We show on a symbolic and a high-dimensional domain that our compositional approach can generalize to more complex problems than the learner has previously encountered, whereas baselines that are not explicitly compositional do not.",
            "keywords": "compositionality, deep learning, metareasoning",
            "tl;dr": "We explore the problem of compositional generalization and propose a means for endowing neural network architectures with the ability to compose themselves to solve these problems."
      },
      {
            "data_id": "B1fpDsAqt7",
            "paper_title": "Visual Reasoning by Progressive Module Networks",
            "forum_link": "https://openreview.net/forum?id=B1fpDsAqt7",
            "pdf_link": "https://openreview.net/pdf?id=B1fpDsAqt7",
            "authors": [
                  "Seung Wook Kim",
                  "Makarand Tapaswi",
                  "Sanja Fidler"
            ],
            "abstract": "Humans learn to solve tasks of increasing complexity by building on top of previously acquired knowledge. Typically, there exists a natural progression in the tasks that we learn \u2013 most do not require completely independent solutions, but can be broken down into simpler subtasks. We propose to represent a solver for each task as a neural module that calls existing modules (solvers for simpler tasks) in a functional program-like manner. Lower modules are a black box to the calling module, and communicate only via a query and an output. Thus, a module for a new task learns to query existing modules and composes their outputs in order to produce its own output. Our model effectively combines previous skill-sets, does not suffer from forgetting, and is fully differentiable. We test our model in learning a set of visual reasoning tasks, and demonstrate improved performances in all tasks by learning progressively. By evaluating the reasoning process using human judges, we show that our model is more interpretable than an attention-based baseline."
      },
      {
            "data_id": "B1g30j0qF7",
            "paper_title": "Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes",
            "forum_link": "https://openreview.net/forum?id=B1g30j0qF7",
            "pdf_link": "https://openreview.net/pdf?id=B1g30j0qF7",
            "authors": [
                  "Roman Novak",
                  "Lechao Xiao",
                  "Yasaman Bahri",
                  "Jaehoon Lee",
                  "Greg Yang",
                  "Jiri Hron",
                  "Daniel A. Abolafia",
                  "Jeffrey Pennington",
                  "Jascha Sohl-dickstein"
            ],
            "abstract": "There is a previously identified equivalence between wide fully connected neural networks (FCNs) and Gaussian processes (GPs). This equivalence enables, for instance, test set predictions that would have resulted from a fully Bayesian, infinitely wide trained FCN to be computed without ever instantiating the FCN, but by instead evaluating the corresponding GP. In this work, we derive an analogous equivalence for multi-layer convolutional neural networks (CNNs) both with and without pooling layers, and achieve state of the art results on CIFAR10 for GPs without trainable kernels. We also introduce a Monte Carlo method to estimate the GP corresponding to a given neural network architecture, even in cases where the analytic form has too many terms to be computationally feasible. \n        \n        Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs with and without weight sharing are identical. As a consequence, translation equivariance, beneficial in finite channel CNNs trained with stochastic gradient descent (SGD), is guaranteed to play no role in the Bayesian treatment of the infinite channel limit - a qualitative difference between the two regimes that is not present in the FCN case. We confirm experimentally, that while in some scenarios the performance of SGD-trained finite CNNs approaches that of the corresponding GPs as the channel count increases, with careful tuning SGD-trained CNNs can significantly outperform their corresponding GPs, suggesting advantages from SGD training compared to fully Bayesian parameter estimation.",
            "keywords": "Deep Convolutional Neural Networks, Gaussian Processes, Bayesian",
            "tl;dr": "Finite-width SGD trained CNNs vs. infinitely wide fully Bayesian CNNs. Who wins?"
      },
      {
            "data_id": "B1gTShAct7",
            "paper_title": "Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference",
            "forum_link": "https://openreview.net/forum?id=B1gTShAct7",
            "pdf_link": "https://openreview.net/pdf?id=B1gTShAct7",
            "authors": [
                  "Matthew Riemer",
                  "Ignacio Cases",
                  "Robert Ajemian",
                  "Miao Liu",
                  "Irina Rish",
                  "Yuhai Tu",
                  "and Gerald Tesauro"
            ],
            "abstract": "Lack of performance when it comes to continual learning over non-stationary distributions of data remains a major challenge in scaling neural network learning to more human realistic settings. In this work we propose a new conceptualization of the continual learning problem in terms of a temporally symmetric trade-off between transfer and interference that can be optimized by enforcing gradient alignment across examples. We then propose a new algorithm, Meta-Experience Replay (MER), that directly exploits this view by combining experience replay with optimization based meta-learning. This method learns parameters that make interference based on future gradients less likely and transfer based on future gradients more likely. We conduct experiments across continual lifelong supervised learning benchmarks and non-stationary reinforcement learning environments demonstrating that our approach consistently outperforms recently proposed baselines for continual learning. Our experiments show that the gap between the performance of MER and baseline algorithms grows both as the environment gets more non-stationary and as the fraction of the total experiences stored gets smaller."
      },
      {
            "data_id": "B1gstsCqt7",
            "paper_title": "Sparse Dictionary Learning by Dynamical Neural Networks",
            "forum_link": "https://openreview.net/forum?id=B1gstsCqt7",
            "pdf_link": "https://openreview.net/pdf?id=B1gstsCqt7",
            "authors": [
                  "Tsung-Han Lin",
                  "Ping Tak Peter Tang"
            ],
            "abstract": "A dynamical neural network consists of a set of interconnected neurons that interact over time continuously. It can exhibit computational properties in the sense that the dynamical system\u2019s evolution and/or limit points in the associated state space can correspond to numerical solutions to certain mathematical optimization or learning problems. Such a computational system is particularly attractive in that it can be mapped to a massively parallel computer architecture for power and throughput efficiency, especially if each neuron can rely solely on local information (i.e., local memory). Deriving gradients from the dynamical network\u2019s various states while conforming to this last constraint, however, is challenging. We show that by combining ideas of top-down feedback and contrastive learning, a dynamical network for solving the l1-minimizing dictionary learning problem can be constructed, and the true gradients for learning are provably computable by individual neurons. Using spiking neurons to construct our dynamical network, we present a learning process, its rigorous mathematical analysis, and numerical results on several dictionary learning problems.",
            "keywords": "dynamical neural networks, spiking neural networks, dynamical system, hardware friendly learning, feedback, contrastive learning, dictionary learning, sparse coding"
      },
      {
            "data_id": "B1lKS2AqtX",
            "paper_title": "Eidetic 3D LSTM: A Model for Video Prediction and Beyond",
            "forum_link": "https://openreview.net/forum?id=B1lKS2AqtX",
            "pdf_link": "https://openreview.net/pdf?id=B1lKS2AqtX",
            "authors": [
                  "Yunbo Wang",
                  "Lu Jiang",
                  "Ming-Hsuan Yang",
                  "Li-Jia Li",
                  "Mingsheng Long",
                  "Li Fei-Fei"
            ],
            "abstract": "Spatiotemporal predictive learning, though long considered to be a promising self-supervised feature learning method, seldom shows its effectiveness beyond future video prediction. The reason is that it is difficult to learn good representations for both short-term frame dependency and long-term high-level relations. We present a new model, Eidetic 3D LSTM (E3D-LSTM), that integrates 3D convolutions into RNNs. The encapsulated 3D-Conv makes local perceptrons of RNNs motion-aware and enables the memory cell to store better short-term features. For long-term relations, we make the present memory state interact with its historical records via a gate-controlled self-attention module. We describe this memory transition mechanism eidetic as it is able to effectively recall the stored memories across multiple time stamps even after long periods of disturbance. We first evaluate the E3D-LSTM network on widely-used future video prediction datasets and achieve the state-of-the-art performance. Then we show that the E3D-LSTM network also performs well on the early activity recognition to infer what is happening or what will happen after observing only limited frames of video. This task aligns well with video prediction in modeling action intentions and tendency."
      },
      {
            "data_id": "B1lnzn0ctQ",
            "paper_title": "ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA",
            "forum_link": "https://openreview.net/forum?id=B1lnzn0ctQ",
            "pdf_link": "https://openreview.net/pdf?id=B1lnzn0ctQ",
            "authors": [
                  "Jialin Liu",
                  "Xiaohan Chen",
                  "Zhangyang Wang",
                  "Wotao Yin"
            ],
            "abstract": "Deep neural networks based on unfolding an iterative algorithm, for example, LISTA (learned iterative shrinkage thresholding algorithm), have been an empirical success for sparse signal recovery. The weights of these neural networks are currently determined by data-driven \u201cblack-box\u201d training. In this work, we propose Analytic LISTA (ALISTA), where the weight matrix in LISTA is computed as the solution to a data-free optimization problem, leaving only the stepsize and threshold parameters to data-driven learning. This signi\ufb01cantly simpli\ufb01es the training. Speci\ufb01cally, the data-free optimization problem is based on coherence minimization. We show our ALISTA retains the optimal linear convergence proved in (Chen et al., 2018) and has a performance comparable to LISTA. Furthermore, we extend ALISTA to convolutional linear operators, again determined in a data-free manner. We also propose a feed-forward framework that combines the data-free optimization and ALISTA networks from end to end, one that can be jointly trained to gain robustness to small perturbations in the encoding model.",
            "keywords": "sparse recovery, neural networks"
      },
      {
            "data_id": "B1lz-3Rct7",
            "paper_title": "Three Mechanisms of Weight Decay Regularization",
            "forum_link": "https://openreview.net/forum?id=B1lz-3Rct7",
            "pdf_link": "https://openreview.net/pdf?id=B1lz-3Rct7",
            "authors": [
                  "Guodong Zhang",
                  "Chaoqi Wang",
                  "Bowen Xu",
                  "Roger Grosse"
            ],
            "abstract": "Weight decay is one of the standard tricks in the neural network toolbox, but the reasons for its regularization effect are poorly understood, and recent results have cast doubt on the traditional interpretation in terms of <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"0\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-msub><mjx-mi class=\"mjx-i\" noic=\"true\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-script style=\"vertical-align: -0.15em;\"><mjx-mn class=\"mjx-n\" size=\"s\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>L</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> regularization.\n        Literal weight decay has been shown to outperform <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"1\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-msub><mjx-mi class=\"mjx-i\" noic=\"true\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-script style=\"vertical-align: -0.15em;\"><mjx-mn class=\"mjx-n\" size=\"s\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>L</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container> regularization for optimizers for which they differ. \n        We empirically investigate weight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a variety of network architectures. We identify three distinct mechanisms by which weight decay exerts a regularization effect, depending on the particular optimization algorithm and architecture: (1) increasing the effective learning rate, (2) approximately regularizing the input-output Jacobian norm, and (3) reducing the effective damping coefficient for second-order optimization. \n        Our results provide insight into how to improve the regularization of neural networks.",
            "keywords": "Generalization, Regularization, Optimization",
            "tl;dr": "We investigate weight decay regularization for different optimizers and identify three distinct mechanisms by which weight decay improves generalization."
      },
      {
            "data_id": "B1xJAsA5F7",
            "paper_title": "Learning Multimodal Graph-to-Graph Translation for Molecule Optimization",
            "forum_link": "https://openreview.net/forum?id=B1xJAsA5F7",
            "pdf_link": "https://openreview.net/pdf?id=B1xJAsA5F7",
            "authors": [
                  "Wengong Jin",
                  "Kevin Yang",
                  "Regina Barzilay",
                  "Tommi Jaakkola"
            ],
            "abstract": "We view molecule optimization as a graph-to-graph translation problem. The goal is to learn to map from one molecular graph to another with better properties based on an available corpus of paired molecules. Since molecules can be optimized in different ways, there are multiple viable translations for each input graph. A key challenge is therefore to model diverse translation outputs. Our primary contributions include a junction tree encoder-decoder for learning diverse graph translations along with a novel adversarial training method for aligning distributions of molecules. Diverse output distributions in our model are explicitly realized by low-dimensional latent vectors that modulate the translation process. We evaluate our model on multiple molecule optimization tasks and show that our model outperforms previous state-of-the-art baselines by a significant margin.",
            "keywords": "graph-to-graph translation, graph generation, molecular optimization",
            "tl;dr": "We introduce a graph-to-graph encoder-decoder framework for learning diverse graph translations."
      },
      {
            "data_id": "B1xVTjCqKQ",
            "paper_title": "A Data-Driven and Distributed Approach to Sparse Signal Representation and Recovery",
            "forum_link": "https://openreview.net/forum?id=B1xVTjCqKQ",
            "pdf_link": "https://openreview.net/pdf?id=B1xVTjCqKQ",
            "authors": [
                  "Ali Mousavi",
                  "Gautam Dasarathy",
                  "Richard G. Baraniuk"
            ],
            "abstract": "In this paper, we focus on two challenges which offset the promise of sparse signal representation, sensing, and recovery. First, real-world signals can seldom be described as perfectly sparse vectors in a known basis, and traditionally used random measurement schemes are seldom optimal for sensing them. Second, existing signal recovery algorithms are usually not fast enough to make them applicable to real-time problems. In this paper, we address these two challenges by presenting a novel framework based on deep learning. For the first challenge, we cast the problem of finding informative measurements by using a maximum likelihood (ML) formulation and show how we can build a data-driven dimensionality reduction protocol for sensing signals using convolutional architectures. For the second challenge, we discuss and analyze a novel parallelization scheme and show it significantly speeds-up the signal recovery process. We demonstrate the significant improvement our method obtains over competing methods through a series of experiments.",
            "keywords": "Sparsity, Compressive Sensing, Convolutional Network",
            "tl;dr": "We use deep learning techniques to solve the sparse signal representation and recovery problem."
      },
      {
            "data_id": "B1xWcj0qYm",
            "paper_title": "On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data",
            "forum_link": "https://openreview.net/forum?id=B1xWcj0qYm",
            "pdf_link": "https://openreview.net/pdf?id=B1xWcj0qYm",
            "authors": [
                  "Nan Lu",
                  "Gang Niu",
                  "Aditya Krishna Menon",
                  "Masashi Sugiyama"
            ],
            "abstract": "Empirical risk minimization (ERM), with proper loss function and regularization, is the common practice of supervised classification. In this paper, we study training arbitrary (from linear to deep) binary classifier from only unlabeled (U) data by ERM. We prove that it is impossible to estimate the risk of an arbitrary binary classifier in an unbiased manner given a single set of U data, but it becomes possible given two sets of U data with different class priors. These two facts answer a fundamental question---what the minimal supervision is for training any binary classifier from only U data. Following these findings, we propose an ERM-based learning method from two sets of U data, and then prove it is consistent. Experiments demonstrate the proposed method could train deep models and outperform state-of-the-art methods for learning from two sets of U data.",
            "keywords": "learning from only unlabeled data, empirical risk minimization, unbiased risk estimator",
            "tl;dr": "Three class priors are all you need to train deep models from only U data, while any two should not be enough."
      },
      {
            "data_id": "B1xY-hRctX",
            "paper_title": "Neural Logic Machines",
            "forum_link": "https://openreview.net/forum?id=B1xY-hRctX",
            "pdf_link": "https://openreview.net/pdf?id=B1xY-hRctX",
            "authors": [
                  "Honghua Dong",
                  "Jiayuan Mao",
                  "Tian Lin",
                  "Chong Wang",
                  "Lihong Li",
                  "Denny Zhou"
            ],
            "abstract": "We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks---as function approximators, and logic programming---as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers.  After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks or inductive logic programming alone.",
            "keywords": "Neuro-Symbolic Computation, Logic Induction",
            "tl;dr": "We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning."
      },
      {
            "data_id": "B1xf9jAqFQ",
            "paper_title": "Neural Speed Reading with Structural-Jump-LSTM",
            "forum_link": "https://openreview.net/forum?id=B1xf9jAqFQ",
            "pdf_link": "https://openreview.net/pdf?id=B1xf9jAqFQ",
            "authors": [
                  "Christian Hansen",
                  "Casper Hansen",
                  "Stephen Alstrup",
                  "Jakob Grue Simonsen",
                  "Christina Lioma"
            ],
            "abstract": "Recurrent neural networks (RNNs) can model natural language by sequentially ''reading'' input tokens and outputting a distributed representation of each token. Due to the sequential nature of RNNs, inference time is linearly dependent on the input length, and all inputs are read regardless of their importance. Efforts to speed up this inference, known as ''neural speed reading'', either ignore or skim over part of the input. We present Structural-Jump-LSTM: the first neural speed reading model to both skip and jump text during inference. The model consists of a standard LSTM and two agents: one capable of skipping single words when reading, and one capable of exploiting punctuation structure (sub-sentence separators (,:), sentence end symbols (.!?), or end of text markers) to jump ahead after reading a word.\n        A comprehensive experimental evaluation of our model against all five state-of-the-art neural reading models shows that \n        Structural-Jump-LSTM achieves the best overall floating point operations (FLOP) reduction (hence is faster), while keeping the same accuracy or even improving it compared to a vanilla LSTM that reads the whole text.",
            "keywords": "natural language processing, speed reading, recurrent neural network, classification",
            "tl;dr": "We propose a new model for neural speed reading that utilizes the inherent punctuation structure of a text to define effective jumping and skipping behavior."
      },
      {
            "data_id": "B1xhQhRcK7",
            "paper_title": "Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures",
            "forum_link": "https://openreview.net/forum?id=B1xhQhRcK7",
            "pdf_link": "https://openreview.net/pdf?id=B1xhQhRcK7",
            "authors": [
                  "Jonathan Uesato*",
                  "Ananya Kumar*",
                  "Csaba Szepesvari*",
                  "Tom Erez",
                  "Avraham Ruderman",
                  "Keith Anderson",
                  "Krishnamurthy (Dj) Dvijotham",
                  "Nicolas Heess",
                  "Pushmeet Kohli"
            ],
            "abstract": "This paper addresses the problem of evaluating learning systems in safety critical domains such as autonomous driving, where failures can have catastrophic consequences. We focus on two problems: searching for scenarios when learned agents fail and assessing their probability of failure. The standard method for agent evaluation in reinforcement learning, Vanilla Monte Carlo, can miss failures entirely, leading to the deployment of unsafe agents. We demonstrate this is an issue for current agents, where even matching the compute used for training is sometimes insufficient for evaluation. To address this shortcoming, we draw upon the rare event probability estimation literature and propose an adversarial evaluation approach. Our approach focuses evaluation on adversarially chosen situations, while still providing unbiased estimates of failure probabilities. The key difficulty is in identifying these adversarial situations -- since failures are rare there is little signal to drive optimization. To solve this we propose a continuation approach that learns failure modes in related but less robust agents. Our approach also allows reuse of data already collected for training the agent. We demonstrate the efficacy of adversarial evaluation on two standard domains: humanoid control and simulated driving. Experimental results show that our methods can find catastrophic failures and estimate failures rates of agents multiple orders of magnitude faster than standard evaluation schemes, in minutes to hours rather than days.",
            "keywords": "agent evaluation, adversarial examples, robustness, safety, reinforcement learning",
            "tl;dr": "We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this."
      },
      {
            "data_id": "BJG0voC9YQ",
            "paper_title": "Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search",
            "forum_link": "https://openreview.net/forum?id=BJG0voC9YQ",
            "pdf_link": "https://openreview.net/pdf?id=BJG0voC9YQ",
            "authors": [
                  "Lars Buesing",
                  "Theophane Weber",
                  "Yori Zwols",
                  "Nicolas Heess",
                  "Sebastien Racaniere",
                  "Arthur Guez",
                  "Jean-Baptiste Lespiau"
            ],
            "abstract": "Learning policies on data synthesized by models can in principle quench the thirst of reinforcement learning algorithms for large amounts of real experience, which is often costly to acquire. However, simulating plausible experience de novo is a hard problem for many complex environments, often resulting in biases for model-based policy evaluation and search. Instead of de novo synthesis of data, here we assume logged, real experience and model alternative outcomes of this experience under counterfactual actions, i.e. actions that were not actually taken. Based on this, we propose the Counterfactually-Guided Policy Search (CF-GPS) algorithm for learning policies in POMDPs from off-policy experience. It leverages structural causal models for counterfactual evaluation of arbitrary policies on individual off-policy episodes. CF-GPS can improve on vanilla model-based RL algorithms by making use of available logged data to de-bias model predictions. In contrast to off-policy algorithms based on Importance Sampling which re-weight data, CF-GPS leverages a model to explicitly consider alternative outcomes, allowing the algorithm to make better use of experience data. We find empirically that these advantages translate into improved policy evaluation and search results on a non-trivial grid-world task. Finally, we show that CF-GPS generalizes the previously proposed Guided Policy Search and that reparameterization-based algorithms such Stochastic Value Gradient can be interpreted as counterfactual methods.",
            "keywords": "reinforcement learning, generative models, model-based reinforcement learning, causal inference"
      },
      {
            "data_id": "BJe-DsC5Fm",
            "paper_title": "signSGD via Zeroth-Order Oracle",
            "forum_link": "https://openreview.net/forum?id=BJe-DsC5Fm",
            "pdf_link": "https://openreview.net/pdf?id=BJe-DsC5Fm",
            "authors": [
                  "Sijia Liu",
                  "Pin-Yu Chen",
                  "Xiangyi Chen",
                  "Mingyi Hong"
            ],
            "abstract": "In this paper, we design and analyze a new zeroth-order (ZO) stochastic optimization algorithm, ZO-signSGD, which enjoys dual advantages of gradient-free operations and signSGD. The latter requires only the sign information of  gradient estimates but is able to achieve a comparable  or even better convergence speed than SGD-type algorithms. Our study  shows that ZO signSGD requires <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"2\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c221A\"></mjx-c></mjx-mo></mjx-surd><mjx-box style=\"padding-top: 0.156em;\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D451 TEX-I\"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msqrt><mi>d</mi></msqrt></math></mjx-assistive-mml></mjx-container> times more iterations than signSGD, leading to a convergence rate of  <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"3\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D442 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c221A\"></mjx-c></mjx-mo></mjx-surd><mjx-box style=\"padding-top: 0.156em;\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D451 TEX-I\"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-texatom texclass=\"ORD\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2F\"></mjx-c></mjx-mo></mjx-texatom><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c221A\"></mjx-c></mjx-mo></mjx-surd><mjx-box style=\"padding-top: 0.169em;\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D447 TEX-I\"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msqrt><mi>d</mi></msqrt><mrow><mo>/</mo></mrow><msqrt><mi>T</mi></msqrt><mo stretchy=\"false\">)</mo></math></mjx-assistive-mml></mjx-container> under mild conditions, where <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"4\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D451 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></mjx-assistive-mml></mjx-container> is the number of optimization variables, and <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"5\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D447 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi></math></mjx-assistive-mml></mjx-container> is the number of iterations. In addition, we analyze the effects of different types of gradient estimators on the convergence of ZO-signSGD, and propose two variants of ZO-signSGD that  at least  achieve <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"6\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D442 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c221A\"></mjx-c></mjx-mo></mjx-surd><mjx-box style=\"padding-top: 0.156em;\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D451 TEX-I\"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-texatom texclass=\"ORD\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2F\"></mjx-c></mjx-mo></mjx-texatom><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c221A\"></mjx-c></mjx-mo></mjx-surd><mjx-box style=\"padding-top: 0.169em;\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D447 TEX-I\"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msqrt><mi>d</mi></msqrt><mrow><mo>/</mo></mrow><msqrt><mi>T</mi></msqrt><mo stretchy=\"false\">)</mo></math></mjx-assistive-mml></mjx-container> convergence rate. On the application side we explore the connection between ZO-signSGD and  black-box adversarial attacks in robust deep learning.  Our empirical evaluations on image classification datasets MNIST and CIFAR-10 demonstrate the superior performance of ZO-signSGD on the generation of   adversarial examples from black-box neural networks.",
            "keywords": "nonconvex optimization, zeroth-order algorithm, black-box adversarial attack",
            "tl;dr": "We design and analyze a new zeroth-order stochastic optimization algorithm, ZO-signSGD, and demonstrate its connection and application to black-box adversarial attacks in robust deep learning"
      },
      {
            "data_id": "BJe0Gn0cY7",
            "paper_title": "Preventing Posterior Collapse with delta-VAEs",
            "forum_link": "https://openreview.net/forum?id=BJe0Gn0cY7",
            "pdf_link": "https://openreview.net/pdf?id=BJe0Gn0cY7",
            "authors": [
                  "Ali Razavi",
                  "Aaron van den Oord",
                  "Ben Poole",
                  "Oriol Vinyals"
            ],
            "abstract": "Due to the phenomenon of \u201cposterior collapse,\u201d current latent variable generative models pose a challenging design choice that either weakens the capacity of the decoder or requires altering the training objective. We develop an alternative that utilizes the most powerful generative models as decoders, optimize the variational lower bound, and ensures that the latent variables preserve and encode useful information. Our proposed \u03b4-VAEs achieve this by constraining the variational family for the posterior to have a minimum distance to the prior. For sequential latent variable models, our approach resembles the classic representation learning approach of slow feature analysis. We demonstrate our method\u2019s efficacy at modeling text on LM1B and modeling images: learning representations, improving sample quality, and achieving state of the art log-likelihood on CIFAR-10 and ImageNet 32 \u00d7 32.",
            "keywords": "Posterior Collapse, VAE, Autoregressive Models",
            "tl;dr": "Avoid posterior collapse by lower bounding the rate."
      },
      {
            "data_id": "BJe1E2R5KX",
            "paper_title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees",
            "forum_link": "https://openreview.net/forum?id=BJe1E2R5KX",
            "pdf_link": "https://openreview.net/pdf?id=BJe1E2R5KX",
            "authors": [
                  "Yuping Luo",
                  "Huazhe Xu",
                  "Yuanzhi Li",
                  "Yuandong Tian",
                  "Trevor Darrell",
                  "Tengyu Ma"
            ],
            "abstract": "Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL. However, the theoretical understanding of such methods has been rather limited. This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees. We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward. The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model. The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires no explicit uncertainty quantification. Instantiating our framework with simplification gives a  variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO). Experiments demonstrate that SLBO achieves the state-of-the-art performance when only 1M or fewer samples are permitted on a range of continuous control benchmark tasks.",
            "keywords": "model-based reinforcement learning, sample efficiency, deep reinforcement learning",
            "tl;dr": "We design model-based reinforcement learning algorithms with theoretical guarantees and achieve state-of-the-art results on Mujuco benchmark tasks when one million or fewer samples are permitted."
      },
      {
            "data_id": "BJeOioA9Y7",
            "paper_title": "Knowledge Flow: Improve Upon Your Teachers",
            "forum_link": "https://openreview.net/forum?id=BJeOioA9Y7",
            "pdf_link": "https://openreview.net/pdf?id=BJeOioA9Y7",
            "authors": [
                  "Iou-Jen Liu",
                  "Jian Peng",
                  "Alexander Schwing"
            ],
            "abstract": "A zoo of deep nets is available these days for almost any given task, and it is increasingly unclear which net to start with when addressing a new task, or which net to use as an initialization for fine-tuning a new model. To address this issue, in this paper, we develop knowledge flow which moves \u2018knowledge\u2019 from multiple deep nets, referred to as teachers, to a new deep net model, called the student. The structure of the teachers and the student can differ arbitrarily and they can be trained on entirely different tasks with different output spaces too. Upon training with knowledge flow the student is independent of the teachers. We demonstrate our approach on a variety of supervised and reinforcement learning tasks, outperforming fine-tuning and other \u2018knowledge exchange\u2019 methods.",
            "keywords": "Transfer Learning, Reinforcement Learning",
            "tl;dr": "\u2018Knowledge Flow\u2019 trains a deep net (student) by injecting information from multiple nets (teachers). The student is independent upon training and performs very well on learned tasks irrespective of the setting (reinforcement or supervised learning)."
      },
      {
            "data_id": "BJeWUs05KQ",
            "paper_title": "Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information",
            "forum_link": "https://openreview.net/forum?id=BJeWUs05KQ",
            "pdf_link": "https://openreview.net/pdf?id=BJeWUs05KQ",
            "authors": [
                  "Mohit Sharma",
                  "Arjun Sharma",
                  "Nicholas Rhinehart",
                  "Kris M. Kitani"
            ],
            "abstract": "The use of imitation learning to learn a single policy for a complex task that has multiple modes or hierarchical structure can be challenging. In fact, previous work has shown that when the modes are known, learning separate policies for each mode or sub-task can greatly improve the performance of imitation learning. In this work, we discover the interaction between sub-tasks from their resulting state-action trajectory sequences using a directed graphical model. We propose a new algorithm based on the generative adversarial imitation learning framework which automatically learns sub-task policies from unsegmented demonstrations. Our approach maximizes the directed information flow in the graphical model between sub-task latent variables and their generated trajectories. We also show how our approach connects with the existing Options framework, which is commonly used to learn hierarchical policies.",
            "keywords": "Imitation Learning, Reinforcement Learning, Deep Learning",
            "tl;dr": "Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information"
      },
      {
            "data_id": "BJej72AqF7",
            "paper_title": "A Max-Affine Spline Perspective of Recurrent Neural Networks",
            "forum_link": "https://openreview.net/forum?id=BJej72AqF7",
            "pdf_link": "https://openreview.net/pdf?id=BJej72AqF7",
            "authors": [
                  "Zichao Wang",
                  "Randall Balestriero",
                  "Richard Baraniuk"
            ],
            "abstract": "We develop a framework for understanding and improving recurrent neural networks (RNNs) using max-affine spline operators (MASOs). We prove that RNNs using piecewise affine and convex nonlinearities can be written as a simple piecewise affine spline operator. The resulting representation provides several new perspectives for analyzing RNNs, three of which we study in this paper. First, we show that an RNN internally partitions the input space during training and that it builds up the partition through time. Second, we show that the affine slope parameter of an RNN corresponds to an input-specific template, from which we can interpret an RNN as performing a simple template matching (matched filtering) given the input. Third, by carefully examining the MASO RNN affine mapping, we prove that using a random initial hidden state corresponds to an explicit L2 regularization of the affine parameters, which can mollify exploding gradients and improve generalization. Extensive experiments on several datasets of various modalities demonstrate and validate each of the above conclusions. In particular, using a random initial hidden states elevates simple RNNs to near state-of-the-art performers on these datasets.",
            "keywords": "RNN, max-affine spline operators",
            "tl;dr": "We provide new insights and interpretations of RNNs from a max-affine spline operators perspective."
      },
      {
            "data_id": "BJemQ209FQ",
            "paper_title": "Learning to Navigate the Web",
            "forum_link": "https://openreview.net/forum?id=BJemQ209FQ",
            "pdf_link": "https://openreview.net/pdf?id=BJemQ209FQ",
            "authors": [
                  "Izzeddin Gur",
                  "Ulrich Rueckert",
                  "Aleksandra Faust",
                  "Dilek Hakkani-Tur"
            ],
            "abstract": "Learning in environments with large state and action spaces, and sparse rewards, can hinder a Reinforcement Learning (RL) agent\u2019s learning through trial-and-error. For instance, following natural language instructions on the Web (such as booking a flight ticket) leads to RL settings where input vocabulary and number of actionable elements on a page can grow very large. Even though recent approaches improve the success rate on relatively simple environments with the help of human demonstrations to guide the exploration, they still fail in environments where the set of possible instructions can reach millions. We approach the aforementioned problems from a different perspective and propose guided RL approaches that can generate unbounded amount of experience for an agent to learn from. Instead of learning from a complicated instruction with a large vocabulary, we decompose it into multiple sub-instructions and schedule a curriculum in which an agent is tasked with a gradually increasing subset of these relatively easier sub-instructions. In addition, when the expert demonstrations are not available, we propose a novel meta-learning framework that generates new instruction following tasks and trains the agent more effectively. We train DQN, deep reinforcement learning agent, with Q-value function approximated with a novel QWeb neural network architecture on these smaller, synthetic instructions. We evaluate the ability of our agent to generalize to new instructions onWorld of Bits benchmark, on forms with up to 100 elements, supporting 14 million possible instructions. The QWeb agent outperforms the baseline without using any human demonstration achieving 100% success rate on several difficult environments.",
            "keywords": "navigating web pages, reinforcement learning, q learning, curriculum learning, meta training",
            "tl;dr": "We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages."
      },
      {
            "data_id": "BJfIVjAcKm",
            "paper_title": "Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability",
            "forum_link": "https://openreview.net/forum?id=BJfIVjAcKm",
            "pdf_link": "https://openreview.net/pdf?id=BJfIVjAcKm",
            "authors": [
                  "Kai Y. Xiao",
                  "Vincent Tjeng",
                  "Nur Muhammad (Mahi) Shafiullah",
                  "Aleksander Madry"
            ],
            "abstract": "We explore the concept of co-design in the context of neural network verification. Specifically, we aim to train deep neural networks that not only are robust to adversarial perturbations but also whose robustness can be verified more easily. To this end, we identify two properties of network models - weight sparsity and so-called ReLU stability - that turn out to significantly impact the complexity of the corresponding verification task. We demonstrate that improving weight sparsity alone already enables us to turn computationally intractable verification problems into tractable ones. Then, improving ReLU stability leads to an additional 4-13x speedup in verification times. An important feature of our methodology is its \"universality,\" in the sense that it can be used with a broad range of training procedures and verification approaches.",
            "keywords": "verification, adversarial robustness, adversarial examples, stability, deep learning, regularization",
            "tl;dr": "We develop methods to train deep neural models that are both robust to adversarial perturbations and whose robustness is significantly easier to verify."
      },
      {
            "data_id": "BJfOXnActQ",
            "paper_title": "Learning to Learn with Conditional Class Dependencies",
            "forum_link": "https://openreview.net/forum?id=BJfOXnActQ",
            "pdf_link": "https://openreview.net/pdf?id=BJfOXnActQ",
            "authors": [
                  "Xiang Jiang",
                  "Mohammad Havaei",
                  "Farshid Varno",
                  "Gabriel Chartrand",
                  "Nicolas Chapados",
                  "Stan Matwin"
            ],
            "abstract": "Neural networks can learn to extract statistical properties from data, but they seldom make use of structured information from the label space to help representation learning. Although some label structure can implicitly be obtained when training on huge amounts of data, in a few-shot learning context where little data is available, making explicit use of the label structure can inform the model to reshape the representation space to reflect a global sense of class dependencies.  We propose a meta-learning framework, Conditional class-Aware Meta-Learning (CAML), that conditionally transforms feature representations based on a metric space that is trained to capture inter-class dependencies. This enables a conditional modulation of the feature representations of the base-learner to impose regularities informed by the label space. Experiments show that the conditional transformation in CAML leads to more disentangled representations and achieves competitive results on the miniImageNet benchmark.",
            "keywords": "meta-learning, learning to learn, few-shot learning",
            "tl;dr": "CAML is an instance of MAML with conditional class dependencies."
      },
      {
            "data_id": "BJfYvo09Y7",
            "paper_title": "Hierarchical Visuomotor Control of Humanoids",
            "forum_link": "https://openreview.net/forum?id=BJfYvo09Y7",
            "pdf_link": "https://openreview.net/pdf?id=BJfYvo09Y7",
            "authors": [
                  "Josh Merel",
                  "Arun Ahuja",
                  "Vu Pham",
                  "Saran Tunyasuvunakool",
                  "Siqi Liu",
                  "Dhruva Tirumala",
                  "Nicolas Heess",
                  "Greg Wayne"
            ],
            "abstract": "We aim to build complex humanoid agents that integrate perception, motor control, and memory. In this work, we partly factor this problem into low-level motor control from proprioception and high-level coordination of the low-level skills informed by vision. We develop an architecture capable of surprisingly flexible, task-directed motor control of a relatively high-DoF humanoid body by combining pre-training of low-level motor controllers with a high-level, task-focused controller that switches among low-level sub-policies. The resulting system is able to control a physically-simulated humanoid body to solve tasks that require coupling visual perception from an unstabilized egocentric RGB camera during locomotion in the environment. Supplementary video link:  https://youtu.be/fBoir7PNxPk",
            "keywords": "hierarchical reinforcement learning, motor control, motion capture",
            "tl;dr": "Solve tasks involving vision-guided humanoid locomotion, reusing locomotion behavior from motion capture data."
      },
      {
            "data_id": "BJg4Z3RqF7",
            "paper_title": "Unsupervised Adversarial Image Reconstruction",
            "forum_link": "https://openreview.net/forum?id=BJg4Z3RqF7",
            "pdf_link": "https://openreview.net/pdf?id=BJg4Z3RqF7",
            "authors": [
                  "Arthur Pajot",
                  "Emmanuel de Bezenac",
                  "Patrick Gallinari"
            ],
            "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.",
            "keywords": "Deep Learning, Adversarial, MAP, GAN, neural networks"
      },
      {
            "data_id": "BJg9DoR9t7",
            "paper_title": "Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds",
            "forum_link": "https://openreview.net/forum?id=BJg9DoR9t7",
            "pdf_link": "https://openreview.net/pdf?id=BJg9DoR9t7",
            "authors": [
                  "Peng Cao*",
                  "Yilun Xu*",
                  "Yuqing Kong",
                  "Yizhou  Wang"
            ],
            "abstract": "Eliciting labels from crowds is a potential way to obtain large labeled data. Despite a variety of methods developed for learning from crowds, a key challenge remains unsolved: \\emph{learning from crowds without knowing the information structure among the crowds a priori, when some people of the crowds make highly correlated mistakes and some of them label effortlessly (e.g. randomly)}. We propose an information theoretic approach, Max-MIG, for joint learning from crowds, with a common assumption: the crowdsourced labels and the data are independent conditioning on the ground truth. Max-MIG simultaneously aggregates the crowdsourced labels and learns an accurate data classifier. Furthermore, we devise an accurate data-crowds forecaster that employs both the data and the crowdsourced labels to forecast the ground truth. To the best of our knowledge, this is the first algorithm that solves the aforementioned challenge of learning from crowds. In addition to the theoretical validation, we also empirically show that our algorithm achieves the new state-of-the-art results in most settings, including the real-world data, and is the first algorithm that is robust to various information structures. Codes are available at https://github.com/Newbeeer/Max-MIG .",
            "keywords": "crowdsourcing, information theory"
      },
      {
            "data_id": "BJgK6iA5KX",
            "paper_title": "AutoLoss: Learning Discrete Schedule for Alternate Optimization",
            "forum_link": "https://openreview.net/forum?id=BJgK6iA5KX",
            "pdf_link": "https://openreview.net/pdf?id=BJgK6iA5KX",
            "authors": [
                  "Haowen Xu",
                  "Hao Zhang",
                  "Zhiting Hu",
                  "Xiaodan Liang",
                  "Ruslan Salakhutdinov",
                  "Eric Xing"
            ],
            "abstract": "Many machine learning problems involve iteratively and alternately optimizing different task objectives with respect to different sets of parameters. Appropriately scheduling the optimization of a task objective or a set of parameters is usually crucial to the quality of convergence. In this paper, we present AutoLoss, a meta-learning framework that automatically learns and determines the optimization schedule. AutoLoss provides a generic way to represent and learn the discrete optimization schedule from metadata, allows for a dynamic and data-driven schedule in ML problems that involve alternating updates of different parameters or from different loss objectives.\n        \n        We apply AutoLoss on four ML tasks: d-ary quadratic regression, classification using a multi-layer perceptron (MLP), image generation using GANs, and multi-task neural machine translation (NMT). We show that the AutoLoss controller is able to capture the distribution of better optimization schedules that result in higher quality of convergence on all four tasks. The trained AutoLoss controller is generalizable -- it can guide and improve the learning of a new task model with different specifications, or on different datasets.",
            "keywords": "Meta Learning, AutoML, Optimization Schedule",
            "tl;dr": "We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules."
      },
      {
            "data_id": "BJgLg3R9KQ",
            "paper_title": "Learning what and where to attend",
            "forum_link": "https://openreview.net/forum?id=BJgLg3R9KQ",
            "pdf_link": "https://openreview.net/pdf?id=BJgLg3R9KQ",
            "authors": [
                  "Drew Linsley",
                  "Dan Shiebler",
                  "Sven Eberhardt",
                  "Thomas Serre"
            ],
            "abstract": "Most recent gains in visual recognition have originated from the inclusion of attention mechanisms in deep convolutional networks (DCNs). Because these networks are optimized for object recognition, they learn where to attend using only a weak form of supervision derived from image class labels. Here, we demonstrate the benefit of using stronger supervisory signals by teaching DCNs to attend to image regions that humans deem important for object recognition. We first describe a large-scale online experiment (ClickMe) used to supplement ImageNet with nearly half a million human-derived \"top-down\" attention maps. Using human psychophysics, we confirm that the identified top-down features from ClickMe are more diagnostic than \"bottom-up\" saliency features for rapid image categorization. As a proof of concept, we extend a state-of-the-art attention network and demonstrate that adding ClickMe supervision significantly improves its accuracy and yields visual features that are more interpretable and more similar to those used by human observers.",
            "keywords": "Attention models, human feature importance, object recognition, cognitive science",
            "tl;dr": "A large-scale dataset for training attention models for object recognition leads to more accurate, interpretable, and human-like object recognition."
      },
      {
            "data_id": "BJgRDjR9tQ",
            "paper_title": "ROBUST ESTIMATION VIA GENERATIVE ADVERSARIAL NETWORKS",
            "forum_link": "https://openreview.net/forum?id=BJgRDjR9tQ",
            "pdf_link": "https://openreview.net/pdf?id=BJgRDjR9tQ",
            "authors": [
                  "Chao GAO",
                  "jiyi LIU",
                  "Yuan YAO",
                  "Weizhi ZHU"
            ],
            "abstract": "Robust estimation under Huber's <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"7\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D716 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>\u03f5</mi></math></mjx-assistive-mml></mjx-container>-contamination model has become an important topic in statistics and theoretical computer science. Rate-optimal procedures such as Tukey's median and other estimators based on statistical depth functions are impractical because of their computational intractability. In this paper, we establish an intriguing connection between f-GANs and various depth functions through the lens of f-Learning. Similar to the derivation of f-GAN, we show that these depth functions that lead to rate-optimal robust estimators can all be viewed as variational lower bounds of the total variation distance in the framework of f-Learning. This connection opens the door of computing robust estimators using tools developed for training GANs. In particular, we show that a JS-GAN that uses a neural network discriminator with at least one hidden layer is able to achieve the minimax rate of robust mean estimation under Huber's <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"8\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D716 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>\u03f5</mi></math></mjx-assistive-mml></mjx-container>-contamination model. Interestingly, the hidden layers of the neural net structure in the discriminator class are shown to be necessary for robust estimation.",
            "keywords": "robust statistics, neural networks, minimax rate, data depth, contamination model, Tukey median, GAN",
            "tl;dr": "GANs are shown to provide us a new effective robust mean estimate against agnostic contaminations with both statistical optimality and practical tractability."
      },
      {
            "data_id": "BJg_roAcK7",
            "paper_title": "INVASE: Instance-wise Variable Selection using Neural Networks",
            "forum_link": "https://openreview.net/forum?id=BJg_roAcK7",
            "pdf_link": "https://openreview.net/pdf?id=BJg_roAcK7",
            "authors": [
                  "Jinsung Yoon",
                  "James Jordon",
                  "Mihaela van der Schaar"
            ],
            "abstract": "The advent of big data brings with it data with more and more dimensions and thus a growing need to be able to efficiently select which features to use for a variety of problems. While global feature selection has been a well-studied problem for quite some time, only recently has the paradigm of instance-wise feature selection been developed. In this paper, we propose a new instance-wise feature selection method, which we term INVASE. INVASE consists of 3 neural networks, a selector network, a predictor network and a baseline network which are used to train the selector network using the actor-critic methodology. Using this methodology, INVASE is capable of flexibly discovering feature subsets of a different size for each instance, which is a key limitation of existing state-of-the-art methods. We demonstrate through a mixture of synthetic and real data experiments that INVASE significantly outperforms state-of-the-art benchmarks.",
            "keywords": "Instance-wise feature selection, interpretability, actor-critic methodology"
      },
      {
            "data_id": "BJgklhAcK7",
            "paper_title": "Meta-Learning with Latent Embedding Optimization",
            "forum_link": "https://openreview.net/forum?id=BJgklhAcK7",
            "pdf_link": "https://openreview.net/pdf?id=BJgklhAcK7",
            "authors": [
                  "Andrei A. Rusu",
                  "Dushyant Rao",
                  "Jakub Sygnowski",
                  "Oriol Vinyals",
                  "Razvan Pascanu",
                  "Simon Osindero",
                  "Raia Hadsell"
            ],
            "abstract": "Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this low-dimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space.",
            "keywords": "meta-learning, few-shot, miniImageNet, tieredImageNet, hypernetworks, generative, latent embedding, optimization",
            "tl;dr": "Latent Embedding Optimization (LEO) is a novel gradient-based meta-learner with state-of-the-art performance on the challenging 5-way 1-shot and 5-shot miniImageNet and tieredImageNet classification tasks."
      },
      {
            "data_id": "BJgqqsAct7",
            "paper_title": "Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach",
            "forum_link": "https://openreview.net/forum?id=BJgqqsAct7",
            "pdf_link": "https://openreview.net/pdf?id=BJgqqsAct7",
            "authors": [
                  "Wenda Zhou",
                  "Victor Veitch",
                  "Morgane Austern",
                  "Ryan P. Adams",
                  "Peter Orbanz"
            ],
            "abstract": "Modern neural networks are highly overparameterized, with capacity to substantially overfit to training data. Nevertheless, these networks often generalize well in practice. It has also been observed that trained networks can often be ``compressed to much smaller representations. The purpose of this paper is to connect these two empirical observations. Our main technical result is a generalization bound for compressed networks based on the compressed size that, combined with off-the-shelf compression algorithms, leads to state-of-the-art generalization guarantees. In particular, we provide the first non-vacuous generalization guarantees for realistic architectures applied to the ImageNet classification problem. Additionally, we show that compressibility of models that tend to overfit is limited. Empirical results show that an increase in overfitting increases the number of bits required to describe a trained network.",
            "keywords": "generalization, deep-learning, pac-bayes",
            "tl;dr": "We obtain non-vacuous generalization bounds on ImageNet-scale deep neural networks by combining an original PAC-Bayes bound and an off-the-shelf neural network compression method."
      },
      {
            "data_id": "BJl6AjC5F7",
            "paper_title": "Learning to Represent Edits",
            "forum_link": "https://openreview.net/forum?id=BJl6AjC5F7",
            "pdf_link": "https://openreview.net/pdf?id=BJl6AjC5F7",
            "authors": [
                  "Pengcheng Yin",
                  "Graham Neubig",
                  "Miltiadis Allamanis",
                  "Marc Brockschmidt",
                  "Alexander L. Gaunt"
            ],
            "abstract": "We introduce the problem of learning distributed representations of edits. By combining a\n        \"neural editor\" with an \"edit encoder\", our models learn to represent the salient\n        information of an edit and can be used to apply edits to new inputs.\n        We experiment on natural language and source code edit data. Our evaluation yields\n        promising results that suggest that our neural network models learn to capture\n        the structure and semantics of edits. We hope that this interesting task and\n        data source will inspire other researchers to work further on this problem.",
            "keywords": "Representation Learning, Source Code, Natural Language, edit"
      },
      {
            "data_id": "BJl6TjRcY7",
            "paper_title": "Neural Probabilistic Motor Primitives for Humanoid Control",
            "forum_link": "https://openreview.net/forum?id=BJl6TjRcY7",
            "pdf_link": "https://openreview.net/pdf?id=BJl6TjRcY7",
            "authors": [
                  "Josh Merel",
                  "Leonard Hasenclever",
                  "Alexandre Galashov",
                  "Arun Ahuja",
                  "Vu Pham",
                  "Greg Wayne",
                  "Yee Whye Teh",
                  "Nicolas Heess"
            ],
            "abstract": "We focus on the problem of learning a single motor module that can flexibly express a range of behaviors for the control of high-dimensional physically simulated humanoids. To do this, we propose a motor architecture that has the general structure of an inverse model with a latent-variable bottleneck. We show that it is possible to train this model entirely offline to compress thousands of expert policies and learn a motor primitive embedding space. The trained neural probabilistic motor primitive system can perform one-shot imitation of whole-body humanoid behaviors, robustly mimicking unseen trajectories. Additionally, we demonstrate that it is also straightforward to train controllers to reuse the learned motor primitive space to solve tasks, and the resulting movements are relatively naturalistic. To support the training of our model, we compare two approaches for offline policy cloning, including an experience efficient method which we call linear feedback policy cloning. We encourage readers to view a supplementary video (https://youtu.be/CaDEf-QcKwA ) summarizing our results.",
            "keywords": "Motor Primitives, Distillation, Reinforcement Learning, Continuous Control, Humanoid Control, Motion Capture, One-Shot Imitation",
            "tl;dr": "Neural Probabilistic Motor Primitives compress motion capture tracking policies into one flexible model capable of one-shot imitation and reuse as a low-level controller."
      },
      {
            "data_id": "BJlgNh0qKQ",
            "paper_title": "Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder",
            "forum_link": "https://openreview.net/forum?id=BJlgNh0qKQ",
            "pdf_link": "https://openreview.net/pdf?id=BJlgNh0qKQ",
            "authors": [
                  "Caio Corro",
                  "Ivan Titov"
            ],
            "abstract": "Human annotation for syntactic parsing is expensive, and large resources are available only for a  fraction of languages. A question we ask is whether one can leverage abundant unlabeled texts to improve syntactic parsers, beyond just using the texts to obtain more generalisable lexical features (i.e. beyond word embeddings). To this end, we propose a novel latent-variable generative model for semi-supervised syntactic dependency parsing. As exact inference is intractable, we introduce a differentiable relaxation to obtain approximate samples and compute gradients with respect to the parser parameters. Our method (Differentiable Perturb-and-Parse) relies on differentiable dynamic programming over stochastically perturbed edge scores. We demonstrate effectiveness of our approach with experiments on English, French and Swedish.",
            "keywords": "differentiable dynamic programming, variational auto-encoder, dependency parsing, semi-supervised learning",
            "tl;dr": "Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE"
      },
      {
            "data_id": "BJluy2RcFm",
            "paper_title": "Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs",
            "forum_link": "https://openreview.net/forum?id=BJluy2RcFm",
            "pdf_link": "https://openreview.net/pdf?id=BJluy2RcFm",
            "authors": [
                  "Ryan L. Murphy",
                  "Balasubramaniam Srinivasan",
                  "Vinayak Rao",
                  "Bruno Ribeiro"
            ],
            "abstract": "We consider a simple and overarching representation for permutation-invariant functions of sequences (or set functions). Our approach, which we call Janossy pooling, expresses a permutation-invariant function as the average of a permutation-sensitive function applied to all reorderings of the input sequence. This allows us to leverage the rich and mature literature on permutation-sensitive functions to construct novel and flexible permutation-invariant functions. If carried out naively, Janossy pooling can be computationally prohibitive. To allow computational tractability, we consider three kinds of approximations: canonical orderings of sequences, functions with k-order interactions, and stochastic optimization algorithms with random permutations. Our framework unifies a variety of existing work in the literature, and suggests possible modeling and algorithmic extensions. We explore a few in our experiments, which demonstrate improved performance over current state-of-the-art methods.",
            "keywords": "representation learning, permutation invariance, set functions, feature pooling",
            "tl;dr": "We propose Janossy pooling, a method for learning deep permutation invariant functions designed to exploit relationships within the input sequence and tractable inference strategies such as a stochastic optimization procedure we call piSGD"
      },
      {
            "data_id": "BJlxm30cKm",
            "paper_title": "An Empirical Study of Example Forgetting during Deep Neural Network Learning",
            "forum_link": "https://openreview.net/forum?id=BJlxm30cKm",
            "pdf_link": "https://openreview.net/pdf?id=BJlxm30cKm",
            "authors": [
                  "Mariya Toneva*",
                  "Alessandro Sordoni*",
                  "Remi Tachet des Combes*",
                  "Adam Trischler",
                  "Yoshua Bengio",
                  "Geoffrey J. Gordon"
            ],
            "abstract": "Inspired by the phenomenon of catastrophic forgetting, we investigate the learning dynamics of neural networks as they train on single classification tasks. Our goal is to understand whether a related phenomenon occurs when data does not undergo a clear distributional shift. We define a ``forgetting event'' to have occurred when an individual training example transitions from being classified correctly to incorrectly over the course of learning. Across several benchmark data sets, we find that: (i) certain examples are forgotten with high frequency, and some not at all; (ii) a data set's (un)forgettable examples generalize across neural architectures; and (iii) based on forgetting dynamics, a significant fraction of examples can be omitted from the training data set while still maintaining state-of-the-art generalization performance.",
            "keywords": "catastrophic forgetting, sample weighting, deep generalization",
            "tl;dr": "We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization."
      },
      {
            "data_id": "BJx0sjC5FX",
            "paper_title": "RNNs implicitly implement tensor-product representations",
            "forum_link": "https://openreview.net/forum?id=BJx0sjC5FX",
            "pdf_link": "https://openreview.net/pdf?id=BJx0sjC5FX",
            "authors": [
                  "R. Thomas McCoy",
                  "Tal Linzen",
                  "Ewan Dunbar",
                  "Paul Smolensky"
            ],
            "abstract": "Recurrent neural networks (RNNs) can learn continuous vector representations of symbolic structures such as sequences and sentences; these representations often exhibit linear regularities (analogies).  Such regularities motivate our hypothesis that RNNs that show such regularities implicitly compile symbolic structures into tensor product representations (TPRs; Smolensky, 1990), which additively combine tensor products of vectors representing roles (e.g.,  sequence positions) and vectors representing fillers (e.g., particular words). To test this hypothesis, we introduce Tensor Product Decomposition Networks (TPDNs), which use TPRs to approximate existing vector representations. We demonstrate using synthetic data that TPDNs can successfully approximate linear and tree-based RNN autoencoder representations, suggesting that these representations exhibit interpretable compositional structure; we explore the settings that lead RNNs to induce such structure-sensitive representations.  By contrast, further TPDN experiments show that the representations of four models trained to encode naturally-occurring sentences can be largely approximated with a bag of words, with only marginal improvements from more sophisticated structures. We conclude that TPDNs provide a powerful method for interpreting vector representations, and that standard RNNs can induce compositional sequence representations that are remarkably well approximated byTPRs; at the same time, existing training tasks for sentence representation learning may not be sufficient for inducing robust structural representations",
            "keywords": "tensor-product representations, compositionality, neural network interpretability, recurrent neural networks",
            "tl;dr": "RNNs implicitly implement tensor-product representations, a principled and interpretable method for representing symbolic structures in continuous space."
      },
      {
            "data_id": "BJxgz2R9t7",
            "paper_title": "Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach",
            "forum_link": "https://openreview.net/forum?id=BJxgz2R9t7",
            "pdf_link": "https://openreview.net/pdf?id=BJxgz2R9t7",
            "authors": [
                  "Saeed Amizadeh",
                  "Sergiy Matusevych",
                  "Markus Weimer"
            ],
            "abstract": "Recent efforts to combine Representation Learning with Formal Methods, commonly known as the Neuro-Symbolic Methods, have given rise to a new trend of applying rich neural architectures to solve classical combinatorial optimization problems. In this paper, we propose a neural framework that can learn to solve the Circuit Satisfiability problem. Our framework is built upon two fundamental contributions: a rich embedding architecture that encodes the problem structure and an end-to-end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT problem. The experimental results show the superior out-of-sample generalization performance of our framework compared to the recently developed NeuroSAT method.",
            "keywords": "Neuro-Symbolic Methods, Circuit Satisfiability, Neural SAT Solver, Graph Neural Networks",
            "tl;dr": "We propose a neural framework that can learn to solve the Circuit Satisfiability problem from (unlabeled) circuit instances."
      },
      {
            "data_id": "BJxh2j0qYm",
            "paper_title": "Dynamic Channel Pruning: Feature Boosting and Suppression",
            "forum_link": "https://openreview.net/forum?id=BJxh2j0qYm",
            "pdf_link": "https://openreview.net/pdf?id=BJxh2j0qYm",
            "authors": [
                  "Xitong Gao",
                  "Yiren Zhao",
                  "\u0141ukasz Dudziak",
                  "Robert Mullins",
                  "Cheng-zhong Xu"
            ],
            "abstract": "Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources. In this paper, we reduce this cost by exploiting the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolutional layers. In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs. We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification. Experiments show that FBS can respectively provide 5\u00d7 and 2\u00d7 savings in compute on VGG-16 and ResNet-18, both with less than 0.6% top-5 accuracy loss.",
            "keywords": "dynamic network, faster CNNs, channel pruning",
            "tl;dr": "We make convolutional layers run faster by dynamically boosting and suppressing channels in feature computation."
      },
      {
            "data_id": "BJxhijAcY7",
            "paper_title": "signSGD with Majority Vote is Communication Efficient and Fault Tolerant",
            "forum_link": "https://openreview.net/forum?id=BJxhijAcY7",
            "pdf_link": "https://openreview.net/pdf?id=BJxhijAcY7",
            "authors": [
                  "Jeremy Bernstein",
                  "Jiawei Zhao",
                  "Kamyar Azizzadenesheli",
                  "Anima Anandkumar"
            ],
            "abstract": "Training neural networks on large datasets can be accelerated by distributing the workload over a network of machines. As datasets grow ever larger, networks of hundreds or thousands of machines become economically viable. The time cost of communicating gradients limits the effectiveness of using such large machine counts, as may the increased chance of network faults. We explore a particularly simple algorithm for robust, communication-efficient learning---signSGD. Workers transmit only the sign of their gradient vector to a server, and the overall update is decided by a majority vote. This algorithm uses 32x less communication per iteration than full-precision, distributed SGD. Under natural conditions verified by experiment, we prove that signSGD converges in the large and mini-batch settings, establishing convergence for a parameter regime of Adam as a byproduct. Aggregating sign gradients by majority vote means that no individual worker has too much power. We prove that unlike SGD, majority vote is robust when up to 50% of workers behave adversarially. The class of adversaries we consider includes as special cases those that invert or randomise their gradient estimate. On the practical side, we built our distributed training system in Pytorch. Benchmarking against the state of the art collective communications library (NCCL), our framework---with the parameter server housed entirely on one machine---led to a 25% reduction in time for training resnet50 on Imagenet when using 15 AWS p3.2xlarge machines.",
            "keywords": "large-scale learning, distributed systems, communication efficiency, convergence rate analysis, robust optimisation",
            "tl;dr": "Workers send gradient signs to the server, and the update is decided by majority vote. We show that this algorithm is convergent, communication efficient and fault tolerant, both in theory and in practice."
      }
]