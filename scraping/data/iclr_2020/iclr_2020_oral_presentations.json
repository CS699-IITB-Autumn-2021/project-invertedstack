[
      {
            "data_id": "HJgzt2VKPB",
            "paper_title": "CATER: A diagnostic dataset for Compositional Actions &amp; TEmporal Reasoning",
            "forum_link": "https://openreview.net/forum?id=HJgzt2VKPB",
            "pdf_link": "https://openreview.net/pdf?id=HJgzt2VKPB",
            "authors": [
                  "Rohit Girdhar",
                  "Deva Ramanan"
            ],
            "keywords": "Video Understanding, Temporal Reasoning",
            "tl;dr": "We propose a new video understanding benchmark, with tasks that by-design require temporal reasoning to be solved, unlike most existing video datasets.",
            "abstract": "Computer vision has undergone a dramatic revolution in performance, driven in large part through deep features trained on large-scale supervised datasets. However, much of these improvements have focused on static image analysis; video understanding has seen rather modest improvements. Even though new datasets and spatiotemporal models have been proposed, simple frame-by-frame classification methods often still remain competitive. We posit that current video datasets are plagued with implicit biases over scene and object structure that can dwarf variations in temporal structure. In this work, we build a video dataset with fully observable and controllable object and scene bias, and which truly requires spatiotemporal understanding in order to be solved. Our dataset, named CATER, is rendered synthetically using a library of standard 3D objects, and tests the ability to recognize compositions of object movements that require long-term reasoning. In addition to being a challenging dataset, CATER also provides a plethora of diagnostic tools to analyze modern spatiotemporal video architectures by being completely observable and controllable. Using CATER, we provide insights into some of the most recent state of the art deep video architectures.",
            "code": "<a href=\"http://rohitgirdhar.github.io/CATER\" target=\"_blank\" rel=\"nofollow noreferrer\">http://rohitgirdhar.github.io/CATER</a>",
            "original-pdf": "<a href=\"/attachment?id=HJgzt2VKPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJlrF24twB",
            "paper_title": "BackPACK: Packing more into Backprop",
            "forum_link": "https://openreview.net/forum?id=BJlrF24twB",
            "pdf_link": "https://openreview.net/pdf?id=BJlrF24twB",
            "authors": [
                  "Felix Dangel",
                  "Frederik Kunstner",
                  "Philipp Hennig"
            ],
            "abstract": "Automatic differentiation frameworks are optimized for exactly one thing: computing the average mini-batch gradient. Yet, other quantities such as the variance of the mini-batch gradients or many approximations to the Hessian can, in theory, be computed efficiently, and at the same time as the gradient. While these quantities are of great interest to researchers and practitioners, current deep learning software  does  not  support  their  automatic  calculation.  Manually  implementing them is burdensome, inefficient if done naively, and the resulting code is rarely shared.  This hampers  progress  in  deep learning,  and  unnecessarily  narrows  research  to  focus  on  gradient  descent  and  its  variants;  it  also  complicates  replication studies and comparisons between newly developed methods that require those quantities, to the point of impossibility. To address this problem, we introduce  BackPACK, an efficient framework built on top of  PyTorch, that extends the backpropagation algorithm to extract additional information from first-and second-order derivatives. Its capabilities are illustrated by benchmark reports for computing additional quantities on deep neural networks, and an example application by testing several recent curvature approximations for optimization.",
            "code": "<a href=\"https://toiaydcdyywlhzvlob.github.io/backpack/\" target=\"_blank\" rel=\"nofollow noreferrer\">https://toiaydcdyywlhzvlob.github.io/backpack/</a>",
            "original-pdf": "<a href=\"/attachment?id=BJlrF24twB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HkxlcnVFwB",
            "paper_title": "GenDICE: Generalized Offline Estimation of Stationary Values",
            "forum_link": "https://openreview.net/forum?id=HkxlcnVFwB",
            "pdf_link": "https://openreview.net/pdf?id=HkxlcnVFwB",
            "authors": [
                  "Ruiyi Zhang*",
                  "Bo Dai*",
                  "Lihong Li",
                  "Dale Schuurmans"
            ],
            "tl;dr": "In this paper, we proposed a novel algorithm, GenDICE, for general stationary distribution correction estimation, which can handle both discounted and average off-policy evaluation on multiple behavior-agnostic samples.",
            "abstract": "An important problem that arises in reinforcement learning and Monte Carlo methods is estimating quantities defined by the stationary distribution of a Markov chain. In many real-world applications, access to the underlying transition operator is limited to a fixed set of data that has already been collected, without additional interaction with the environment being available. We show that consistent estimation remains possible in this scenario, and that effective estimation can still be achieved in important applications. Our approach is based on estimating a ratio that corrects for the discrepancy between the stationary and empirical distributions, derived from fundamental properties of the stationary distribution, and exploiting constraint reformulations based on variational divergence minimization. The resulting algorithm, GenDICE, is straightforward and effective. We prove the consistency of the method under general conditions, provide a detailed error analysis, and demonstrate strong empirical performance on benchmark tasks, including off-line PageRank and off-policy policy evaluation.",
            "keywords": "Off-policy Policy Evaluation, Reinforcement Learning, Stationary Distribution Correction Estimation, Fenchel Dual",
            "original-pdf": "<a href=\"/attachment?id=HkxlcnVFwB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "H1lma24tPB",
            "paper_title": "Principled Weight Initialization for Hypernetworks",
            "forum_link": "https://openreview.net/forum?id=H1lma24tPB",
            "pdf_link": "https://openreview.net/pdf?id=H1lma24tPB",
            "authors": [
                  "Oscar Chang",
                  "Lampros Flokas",
                  "Hod Lipson"
            ],
            "abstract": "Hypernetworks are meta neural networks that generate weights for a main neural network in an end-to-end differentiable manner. Despite extensive applications ranging from multi-task learning to Bayesian deep learning, the problem of optimizing hypernetworks has not been studied to date. We observe that classical weight initialization methods like Glorot &amp; Bengio (2010) and He et al. (2015), when applied directly on a hypernet, fail to produce weights for the mainnet in the correct scale. We develop principled techniques for weight initialization in hypernets, and show that they lead to more stable mainnet weights, lower training loss, and faster convergence.",
            "keywords": "hypernetworks, initialization, optimization, meta-learning",
            "tl;dr": "The first principled weight initialization method for hypernetworks",
            "original-pdf": "<a href=\"/attachment?id=H1lma24tPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HJxNAnVtDS",
            "paper_title": "On the Convergence of FedAvg on Non-IID Data",
            "forum_link": "https://openreview.net/forum?id=HJxNAnVtDS",
            "pdf_link": "https://openreview.net/pdf?id=HJxNAnVtDS",
            "authors": [
                  "Xiang Li",
                  "Kaixuan Huang",
                  "Wenhao Yang",
                  "Shusen Wang",
                  "Zhihua Zhang"
            ],
            "keywords": "Federated Learning, stochastic optimization, Federated Averaging",
            "abstract": "Federated learning enables a large amount of edge computing devices to jointly learn a model without data sharing. As a leading algorithm in this setting, Federated Averaging (\\texttt{FedAvg}) runs Stochastic Gradient Descent (SGD) in parallel on a small subset of the total devices and averages the sequences only once in a while. Despite its simplicity, it lacks theoretical guarantees under realistic settings. In this paper, we analyze the convergence of \\texttt{FedAvg} on non-iid data and establish a convergence rate of <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"0\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-texatom texclass=\"ORD\"><mjx-mi class=\"mjx-cal mjx-i\"><mjx-c class=\"mjx-c4F TEX-C\"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn class=\"mjx-n\" size=\"s\"><mjx-c class=\"mjx-c31\"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class=\"mjx-i\" size=\"s\"><mjx-c class=\"mjx-c1D447 TEX-I\"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow><mi data-mjx-variant=\"-tex-calligraphic\" mathvariant=\"script\">O</mi></mrow><mo stretchy=\"false\">(</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><mo stretchy=\"false\">)</mo></math></mjx-assistive-mml></mjx-container> for strongly convex and smooth problems, where <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"1\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D447 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi></math></mjx-assistive-mml></mjx-container> is the number of SGDs. Importantly, our bound demonstrates a trade-off between communication-efficiency and convergence rate. As user devices may be disconnected from the server, we relax the assumption of full device participation to partial device participation and study different averaging schemes; low device participation rate can be achieved without severely slowing down the learning.  Our results indicate that heterogeneity of data slows down the convergence, which matches empirical observations. Furthermore, we provide a necessary condition for \\texttt{FedAvg} on non-iid data: the learning rate <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"2\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D702 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>\u03b7</mi></math></mjx-assistive-mml></mjx-container> must decay, even if full-gradient is used; otherwise, the solution will be <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"3\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-n\"><mjx-c class=\"mjx-c3A9\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D702 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi mathvariant=\"normal\">\u03a9</mi><mo stretchy=\"false\">(</mo><mi>\u03b7</mi><mo stretchy=\"false\">)</mo></math></mjx-assistive-mml></mjx-container> away from the optimal.",
            "code": "<a href=\"https://github.com/lx10077/fedavgpy\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/lx10077/fedavgpy</a>",
            "original-pdf": "<a href=\"/attachment?id=HJxNAnVtDS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1efxTVYDr",
            "paper_title": "Data-dependent Gaussian Prior Objective for Language Generation",
            "forum_link": "https://openreview.net/forum?id=S1efxTVYDr",
            "pdf_link": "https://openreview.net/pdf?id=S1efxTVYDr",
            "authors": [
                  "Zuchao Li",
                  "Rui Wang",
                  "Kehai Chen",
                  "Masso Utiyama",
                  "Eiichiro Sumita",
                  "Zhuosheng Zhang",
                  "Hai Zhao"
            ],
            "tl;dr": "We introduce an extra data-dependent Gaussian prior objective to augment the current MLE training, which is designed to capture the prior knowledge in the ground-truth data.",
            "abstract": "For typical sequence prediction problems such as language generation, maximum likelihood estimation (MLE) has commonly been adopted as it encourages the predicted sequence most consistent with the ground-truth sequence to have the highest probability of occurring. However, MLE focuses on once-to-all matching between the predicted sequence and gold-standard, consequently treating all incorrect predictions as being equally incorrect. We refer to this drawback as {\\it negative diversity ignorance} in this paper. Treating all incorrect predictions as equal unfairly downplays the nuance of these sequences' detailed token-wise structure. To counteract this, we augment the MLE loss by introducing an extra Kullback--Leibler divergence term derived by comparing a data-dependent Gaussian prior and the detailed training prediction. The proposed data-dependent Gaussian prior objective (D2GPo) is defined over a prior topological order of tokens and is poles apart from the data-independent Gaussian prior (L2 regularization) commonly adopted in smoothing the training of MLE. Experimental results show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical language generation tasks, including supervised and unsupervised machine translation, text summarization, storytelling, and image captioning.",
            "code": "<a href=\"https://drive.google.com/file/d/1q8PqhF9eOLOHOcOCGVKXtA_OlP6qq2mn\" target=\"_blank\" rel=\"nofollow noreferrer\">https://drive.google.com/file/d/1q8PqhF9eOLOHOcOCGVKXtA_OlP6qq2mn</a>",
            "keywords": "Gaussian Prior Objective, Language Generation",
            "original-pdf": "<a href=\"/attachment?id=S1efxTVYDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "H1gax6VtDB",
            "paper_title": "Contrastive Learning of Structured World Models",
            "forum_link": "https://openreview.net/forum?id=H1gax6VtDB",
            "pdf_link": "https://openreview.net/pdf?id=H1gax6VtDB",
            "authors": [
                  "Thomas Kipf",
                  "Elise van der Pol",
                  "Max Welling"
            ],
            "keywords": "state representation learning, graph neural networks, model-based reinforcement learning, relational learning, object discovery",
            "tl;dr": "Contrastively-trained Structured World Models (C-SWMs) learn object-oriented state representations and a relational model of an environment from raw pixel input.",
            "abstract": "A structured understanding of our world in terms of objects, relations, and hierarchies is an important component of human cognition. Learning such a structured world model from raw sensory data remains a challenge. As a step towards this goal, we introduce Contrastively-trained Structured World Models (C-SWMs). C-SWMs utilize a contrastive approach for representation learning in environments with compositional structure. We structure each state embedding as a set of object representations and their relations, modeled by a graph neural network. This allows objects to be discovered from raw pixel observations without direct supervision as part of the learning process. We evaluate C-SWMs on compositional environments involving multiple interacting objects that can be manipulated independently by an agent, simple Atari games, and a multi-object physics simulation. Our experiments demonstrate that C-SWMs can overcome limitations of models based on pixel reconstruction and outperform typical representatives of this model class in highly structured environments, while learning interpretable object-based representations.",
            "code": "<a href=\"https://github.com/tkipf/c-swm\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/tkipf/c-swm</a>",
            "original-pdf": "<a href=\"/attachment?id=H1gax6VtDB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "B1evfa4tPB",
            "paper_title": "Neural Network Branching for Neural Network Verification",
            "forum_link": "https://openreview.net/forum?id=B1evfa4tPB",
            "pdf_link": "https://openreview.net/pdf?id=B1evfa4tPB",
            "authors": [
                  "Jingyue Lu",
                  "M. Pawan Kumar"
            ],
            "keywords": "Neural Network Verification, Branch and Bound, Graph Neural Network, Learning to branch",
            "tl;dr": "We propose a novel learning to branch framework using graph neural networks to improve branch and bound based neural network verification methods.",
            "abstract": "Formal verification of neural networks is essential for their deployment in safety-critical areas. Many available formal verification methods have been shown to be instances of a unified Branch and Bound (BaB) formulation. We propose a novel framework for designing an effective branching strategy for BaB. Specifically, we learn a graph neural network (GNN) to imitate the strong branching heuristic behaviour. Our framework differs from previous methods for learning to branch in two main aspects. Firstly, our framework directly treats the neural network we want to verify as a graph input for the GNN. Secondly, we develop an intuitive forward and backward embedding update schedule. Empirically, our framework achieves roughly <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"4\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c35\"></mjx-c><mjx-c class=\"mjx-c30\"></mjx-c></mjx-mn><mjx-mi class=\"mjx-n\"><mjx-c class=\"mjx-c25\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>50</mn><mi mathvariant=\"normal\">%</mi></math></mjx-assistive-mml></mjx-container> reduction in both the number of branches and the time required for verification on various convolutional networks when compared to the best available hand-designed branching strategy. In addition, we show that our GNN model enjoys both horizontal and vertical transferability. Horizontally, the model trained on easy properties performs well on properties of increased difficulty levels. Vertically, the model trained on small neural networks achieves similar performance on large neural networks.",
            "original-pdf": "<a href=\"/attachment?id=B1evfa4tPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJgnXpVYwS",
            "paper_title": "Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity",
            "forum_link": "https://openreview.net/forum?id=BJgnXpVYwS",
            "pdf_link": "https://openreview.net/pdf?id=BJgnXpVYwS",
            "authors": [
                  "Jingzhao Zhang",
                  "Tianxing He",
                  "Suvrit Sra",
                  "Ali Jadbabaie"
            ],
            "tl;dr": "Gradient clipping provably accelerates gradient descent for non-smooth non-convex functions.",
            "abstract": "We provide a theoretical explanation for the effectiveness of gradient clipping in training deep neural networks. The key ingredient is a new smoothness condition derived from practical neural network training examples. We observe that gradient smoothness, a concept central to the analysis of first-order optimization algorithms that is often assumed to be a constant, demonstrates significant variability along the training trajectory of deep neural networks. Further, this smoothness positively correlates with the gradient norm, and contrary to standard assumptions in the literature, it can grow with the norm of the gradient. These empirical observations limit the applicability of existing theoretical analyses of algorithms that rely on a fixed bound on smoothness. These observations motivate us to introduce a novel relaxation of gradient smoothness that is weaker than the commonly used Lipschitz smoothness assumption. Under the new condition, we prove that two popular methods, namely, gradient clipping and normalized gradient, converge arbitrarily faster than gradient descent with fixed stepsize. We further explain why such adaptively scaled gradient methods can accelerate empirical convergence and verify our results empirically in popular neural network training settings.",
            "keywords": "Adaptive methods, optimization, deep learning",
            "code": "<a href=\"https://github.com/JingzhaoZhang/why-clipping-accelerates\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/JingzhaoZhang/why-clipping-accelerates</a>",
            "original-pdf": "<a href=\"/attachment?id=BJgnXpVYwS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Syg-ET4FPS",
            "paper_title": "Posterior sampling for multi-agent reinforcement learning: solving extensive games with imperfect information",
            "forum_link": "https://openreview.net/forum?id=Syg-ET4FPS",
            "pdf_link": "https://openreview.net/pdf?id=Syg-ET4FPS",
            "authors": [
                  "Yichi Zhou",
                  "Jialian Li",
                  "Jun Zhu"
            ],
            "abstract": "Posterior sampling for reinforcement learning (PSRL) is a useful framework for making decisions in an unknown environment.  PSRL maintains a posterior distribution of the environment and then makes planning on the environment sampled from the posterior distribution. Though PSRL works well on single-agent reinforcement learning problems, how to apply PSRL to multi-agent reinforcement learning problems is relatively unexplored. In this work, we extend PSRL to two-player zero-sum extensive-games with imperfect information (TEGI), which is a class of multi-agent systems. More specifically, we combine PSRL with counterfactual regret minimization (CFR), which is the leading algorithm for TEGI with a known environment. Our main contribution is a novel design of interaction strategies. With our interaction strategies, our algorithm provably converges to the Nash Equilibrium at a rate of <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"5\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D442 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class=\"mjx-sop\"><mjx-c class=\"mjx-c221A TEX-S1\"></mjx-c></mjx-mo></mjx-surd><mjx-box style=\"padding-top: 0.107em;\"><mjx-mi class=\"mjx-n\"><mjx-c class=\"mjx-c6C\"></mjx-c><mjx-c class=\"mjx-c6F\"></mjx-c><mjx-c class=\"mjx-c67\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2061\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\" space=\"2\"><mjx-c class=\"mjx-c1D447 TEX-I\"></mjx-c></mjx-mi><mjx-texatom texclass=\"ORD\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2F\"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D447 TEX-I\"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msqrt><mi>log</mi><mo data-mjx-texclass=\"NONE\">\u2061</mo><mi>T</mi><mrow><mo>/</mo></mrow><mi>T</mi></msqrt><mo stretchy=\"false\">)</mo></math></mjx-assistive-mml></mjx-container>. Empirical results show that our algorithm works well.",
            "original-pdf": "<a href=\"/attachment?id=Syg-ET4FPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJe5P6EYvS",
            "paper_title": "Mogrifier LSTM",
            "forum_link": "https://openreview.net/forum?id=SJe5P6EYvS",
            "pdf_link": "https://openreview.net/pdf?id=SJe5P6EYvS",
            "authors": [
                  "G\u00e1bor Melis",
                  "Tom\u00e1\u0161 Ko\u010disk\u00fd",
                  "Phil Blunsom"
            ],
            "keywords": "lstm, language modelling",
            "tl;dr": "An LSTM extension with state-of-the-art language modelling results.",
            "abstract": "Many advances in Natural Language Processing have been based upon more expressive models for how inputs interact with the context in which they occur. Recurrent networks, which have enjoyed a modicum of success, still lack the generalization and systematicity ultimately required for modelling language. In this work, we propose an extension to the venerable Long Short-Term Memory in the form of mutual gating of the current input and the previous output. This mechanism affords the modelling of a richer space of interactions between inputs and their context. Equivalently, our model can be viewed as making the transition function given by the LSTM context-dependent. Experiments demonstrate markedly improved generalization on language modelling in the range of 3\u20134 perplexity points on Penn Treebank and Wikitext-2, and 0.01\u20130.05 bpc on four character-based datasets. We establish a new state of the art on all datasets with the exception of Enwik8, where we close a large gap between the LSTM and Transformer models.",
            "original-pdf": "<a href=\"/attachment?id=SJe5P6EYvS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "B1elCp4KwH",
            "paper_title": "Learning Hierarchical Discrete Linguistic Units from Visually-Grounded Speech",
            "forum_link": "https://openreview.net/forum?id=B1elCp4KwH",
            "pdf_link": "https://openreview.net/pdf?id=B1elCp4KwH",
            "authors": [
                  "David Harwath*",
                  "Wei-Ning Hsu*",
                  "James Glass"
            ],
            "tl;dr": "Vector quantization layers incorporated into a self-supervised neural model of speech audio learn hierarchical and discrete linguistic units (phone-like, word-like) when trained with a visual-grounding objective.",
            "abstract": "In this paper, we present a method for learning discrete linguistic units by incorporating vector quantization layers into neural models of visually grounded speech. We show that our method is capable of capturing both word-level and sub-word units, depending on how it is configured. What differentiates this paper from prior work on speech unit learning is the choice of training objective. Rather than using a reconstruction-based loss, we use a discriminative, multimodal grounding objective which forces the learned units to be useful for semantic image retrieval. We evaluate the sub-word units on the ZeroSpeech 2019 challenge, achieving a 27.3% reduction in ABX error rate over the top-performing submission, while keeping the bitrate approximately the same. We also present experiments demonstrating the noise robustness of these units. Finally, we show that a model with multiple quantizers can simultaneously learn phone-like detectors at a lower layer and word-like detectors at a higher layer. We show that these detectors are highly accurate, discovering 279 words with an F1 score of greater than 0.5.",
            "keywords": "visually-grounded speech, self-supervised learning, discrete representation learning, vision and language, vision and speech, hierarchical representation learning",
            "code": "<a href=\"https://github.com/wnhsu/ResDAVEnet-VQ\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/wnhsu/ResDAVEnet-VQ</a>",
            "original-pdf": "<a href=\"/attachment?id=B1elCp4KwH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HkxQRTNYPH",
            "paper_title": "Mirror-Generative Neural Machine Translation",
            "forum_link": "https://openreview.net/forum?id=HkxQRTNYPH",
            "pdf_link": "https://openreview.net/pdf?id=HkxQRTNYPH",
            "authors": [
                  "Zaixiang Zheng",
                  "Hao Zhou",
                  "Shujian Huang",
                  "Lei Li",
                  "Xin-Yu Dai",
                  "Jiajun Chen"
            ],
            "abstract": "Training neural machine translation models (NMT) requires a large amount of parallel corpus, which is scarce for many language pairs. However, raw non-parallel corpora are often easy to obtain. Existing approaches have not exploited the full potential of non-parallel bilingual data either in training or decoding. In this paper, we propose the mirror-generative NMT (MGNMT), a single unified architecture that simultaneously integrates the source to target translation model, the target to source translation model, and two language models. Both translation models and language models share the same latent semantic space, therefore both translation directions can learn from non-parallel data more effectively. Besides, the translation models and language models can collaborate together during decoding. Our experiments show that the proposed MGNMT consistently outperforms existing approaches in a variety of scenarios and language pairs, including resource-rich and low-resource situations.",
            "keywords": "neural machine translation, generative model, mirror",
            "code": "<a href=\"https://github.com/zhengzx-nlp/MGNMT\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/zhengzx-nlp/MGNMT</a>",
            "original-pdf": "<a href=\"/attachment?id=HkxQRTNYPH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rkeS1RVtPS",
            "paper_title": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning",
            "forum_link": "https://openreview.net/forum?id=rkeS1RVtPS",
            "pdf_link": "https://openreview.net/pdf?id=rkeS1RVtPS",
            "authors": [
                  "Ruqi Zhang",
                  "Chunyuan Li",
                  "Jianyi Zhang",
                  "Changyou Chen",
                  "Andrew Gordon Wilson"
            ],
            "abstract": "The posteriors over neural network weights are high dimensional and multimodal. Each mode typically characterizes a meaningfully different representation of the data. We develop Cyclical Stochastic Gradient MCMC (SG-MCMC) to automatically explore such distributions. In particular, we propose a cyclical stepsize schedule, where larger steps discover new modes, and smaller steps characterize each mode. We prove non-asymptotic convergence theory of our proposed algorithm. Moreover, we provide extensive experimental results, including ImageNet, to demonstrate the effectiveness of cyclical SG-MCMC in learning complex multimodal distributions, especially for fully Bayesian inference with modern deep neural networks.",
            "original-pdf": "<a href=\"/attachment?id=rkeS1RVtPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Hkxzx0NtDB",
            "paper_title": "Your classifier is secretly an energy based model and you should treat it like one",
            "forum_link": "https://openreview.net/forum?id=Hkxzx0NtDB",
            "pdf_link": "https://openreview.net/pdf?id=Hkxzx0NtDB",
            "authors": [
                  "Will Grathwohl",
                  "Kuan-Chieh Wang",
                  "Joern-Henrik Jacobsen",
                  "David Duvenaud",
                  "Mohammad Norouzi",
                  "Kevin Swersky"
            ],
            "keywords": "energy based models, adversarial robustness, generative models, out of distribution detection, outlier detection, hybrid models, robustness, calibration",
            "tl;dr": "We show that there is a hidden generative model inside of every classifier. We demonstrate how to train this model and show the many benefits of doing so.",
            "abstract": "We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x, y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may be used and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, and out-of-distribution detection while also enabling our models to generate samples rivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and present an approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-art in both generative and discriminative learning within one hybrid model.",
            "code": "<a href=\"https://wgrathwohl.github.io/JEM/\" target=\"_blank\" rel=\"nofollow noreferrer\">https://wgrathwohl.github.io/JEM/</a>",
            "original-pdf": "<a href=\"/attachment?id=Hkxzx0NtDB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HJgLZR4KvH",
            "paper_title": "Dynamics-Aware Unsupervised Discovery of Skills",
            "forum_link": "https://openreview.net/forum?id=HJgLZR4KvH",
            "pdf_link": "https://openreview.net/pdf?id=HJgLZR4KvH",
            "authors": [
                  "Archit Sharma",
                  "Shixiang Gu",
                  "Sergey Levine",
                  "Vikash Kumar",
                  "Karol Hausman"
            ],
            "keywords": "reinforcement learning, unsupervised learning, model-based learning, deep learning, hierarchical reinforcement learning",
            "tl;dr": "We propose an unsupervised skill discovery which enables model-based planning for hierarchical reinforcement learning.",
            "abstract": "Conventionally, model-based reinforcement learning (MBRL) aims to learn a global model for the dynamics of the environment. A good model can potentially enable planning algorithms to generate a large variety of behaviors and solve diverse tasks. However, learning an accurate model for complex dynamical systems is difficult, and even then, the model might not generalize well outside the distribution of states on which it was trained. In this work, we combine model-based learning with model-free learning of primitives that make model-based planning easy. To that end, we aim to answer the question: how can we discover skills whose outcomes are easy to predict? We propose an unsupervised learning algorithm, Dynamics-Aware Discovery of Skills (DADS), which simultaneously discovers predictable behaviors and learns their dynamics. Our method can leverage continuous skill spaces, theoretically, allowing us to learn infinitely many behaviors even for high-dimensional state-spaces. We demonstrate that zero-shot planning in the learned latent space significantly outperforms standard MBRL and model-free goal-conditioned RL, can handle sparse-reward tasks, and substantially improves over prior hierarchical RL methods for unsupervised skill discovery.",
            "code": "<a href=\"https://github.com/google-research/dads\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/google-research/dads</a>",
            "original-pdf": "<a href=\"/attachment?id=HJgLZR4KvH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BkgzMCVtPB",
            "paper_title": "Optimal Strategies Against Generative Attacks",
            "forum_link": "https://openreview.net/forum?id=BkgzMCVtPB",
            "pdf_link": "https://openreview.net/pdf?id=BkgzMCVtPB",
            "authors": [
                  "Roy Mor",
                  "Erez Peterfreund",
                  "Matan Gavish",
                  "Amir Globerson"
            ],
            "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.",
            "code": "<a href=\"https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks</a>",
            "original-pdf": "<a href=\"/attachment?id=BkgzMCVtPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1lGO0EKDH",
            "paper_title": "GraphZoom: A Multi-level Spectral Approach for Accurate and Scalable Graph Embedding",
            "forum_link": "https://openreview.net/forum?id=r1lGO0EKDH",
            "pdf_link": "https://openreview.net/pdf?id=r1lGO0EKDH",
            "authors": [
                  "Chenhui Deng",
                  "Zhiqiang Zhao",
                  "Yongyu Wang",
                  "Zhiru Zhang",
                  "Zhuo Feng"
            ],
            "tl;dr": "A multi-level spectral approach to improving the quality and scalability of unsupervised graph embedding.",
            "abstract": "Graph embedding techniques have been increasingly deployed in a multitude of different applications that involve learning on non-Euclidean data. However, existing graph embedding models either fail to incorporate node attribute information during training or suffer from node attribute noise, which compromises the accuracy. Moreover, very few of them scale to large graphs due to their high computational complexity and memory usage. In this paper we propose GraphZoom, a multi-level framework for improving both accuracy and scalability of unsupervised graph embedding algorithms. GraphZoom first performs graph fusion to generate a new graph that effectively encodes the topology of the original graph and the node attribute information. This fused graph is then repeatedly coarsened into much smaller graphs by merging nodes with high spectral similarities. GraphZoom allows any existing embedding methods to be applied to the coarsened graph, before it progressively refine the embeddings obtained at the coarsest level to increasingly finer graphs. We have evaluated our approach on a number of popular graph datasets for both transductive and inductive tasks. Our experiments show that GraphZoom can substantially increase the classification accuracy and significantly accelerate the entire graph embedding process by up to <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"6\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c34\"></mjx-c><mjx-c class=\"mjx-c30\"></mjx-c><mjx-c class=\"mjx-c2E\"></mjx-c><mjx-c class=\"mjx-c38\"></mjx-c></mjx-mn><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-cD7\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>40.8</mn><mo>\u00d7</mo></math></mjx-assistive-mml></mjx-container>, when compared to the  state-of-the-art unsupervised embedding methods.",
            "code": "<a href=\"https://github.com/cornell-zhang/GraphZoom\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/cornell-zhang/GraphZoom</a>",
            "keywords": "graph embedding, unsupervised learning, multi-level optimization, spectral graph theory",
            "original-pdf": "<a href=\"/attachment?id=r1lGO0EKDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rklHqRVKvH",
            "paper_title": "Harnessing Structures for Value-Based Planning and Reinforcement Learning",
            "forum_link": "https://openreview.net/forum?id=rklHqRVKvH",
            "pdf_link": "https://openreview.net/pdf?id=rklHqRVKvH",
            "authors": [
                  "Yuzhe Yang",
                  "Guo Zhang",
                  "Zhi Xu",
                  "Dina Katabi"
            ],
            "keywords": "Deep reinforcement learning, value-based reinforcement learning",
            "tl;dr": "We propose a generic framework that allows for exploiting the low-rank structure in both planning and deep reinforcement learning.",
            "abstract": "Value-based methods constitute a fundamental methodology in planning and deep reinforcement learning (RL). In this paper, we propose to exploit the underlying structures of the state-action value function, i.e., Q function, for both planning and deep RL. In particular, if the underlying system dynamics lead to some global structures of the Q function, one should be capable of inferring the function better by leveraging such structures. Specifically, we investigate the low-rank structure, which widely exists for big data matrices. We verify empirically the existence of low-rank Q functions in the context of control and deep RL tasks. As our key contribution, by leveraging Matrix Estimation (ME) techniques, we propose a general framework to exploit the underlying low-rank structure in Q functions. This leads to a more efficient planning procedure for classical control, and additionally, a simple scheme that can be applied to value-based RL techniques to consistently achieve better performance on \"low-rank\" tasks. Extensive experiments on control tasks and Atari games confirm the efficacy of our approach.",
            "code": "<a href=\"https://github.com/YyzHarry/SV-RL\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/YyzHarry/SV-RL</a>",
            "original-pdf": "<a href=\"/attachment?id=rklHqRVKvH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1gSj0NKvB",
            "paper_title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning",
            "forum_link": "https://openreview.net/forum?id=S1gSj0NKvB",
            "pdf_link": "https://openreview.net/pdf?id=S1gSj0NKvB",
            "authors": [
                  "Alex Renda",
                  "Jonathan Frankle",
                  "Michael Carbin"
            ],
            "tl;dr": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.",
            "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.",
            "code": "<a href=\"https://github.com/lottery-ticket/rewinding-iclr20-public\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/lottery-ticket/rewinding-iclr20-public</a>",
            "keywords": "pruning, sparsity, fine-tuning, lottery ticket",
            "original-pdf": "<a href=\"/attachment?id=S1gSj0NKvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJeD3CEFPH",
            "paper_title": "Meta-Q-Learning",
            "forum_link": "https://openreview.net/forum?id=SJeD3CEFPH",
            "pdf_link": "https://openreview.net/pdf?id=SJeD3CEFPH",
            "authors": [
                  "Rasool Fakoor",
                  "Pratik Chaudhari",
                  "Stefano Soatto",
                  "Alexander J. Smola"
            ],
            "keywords": "meta reinforcement learning, propensity estimation, off-policy",
            "tl;dr": "MQL is a simple off-policy meta-RL algorithm that recycles data from the meta-training replay buffer to adapt to new tasks.",
            "abstract": "This paper introduces Meta-Q-Learning (MQL), a new off-policy algorithm for meta-Reinforcement Learning (meta-RL). MQL builds upon three simple ideas. First, we show that Q-learning is competitive with state-of-the-art meta-RL algorithms if given access to a context variable that is a representation of the past trajectory. Second, a multi-task objective to maximize the average reward across the training tasks is an effective method to meta-train RL policies. Third, past data from the meta-training replay buffer can be recycled to adapt the policy on a new task using off-policy updates. MQL draws upon ideas in propensity estimation to do so and thereby amplifies the amount of available data for adaptation. Experiments on standard continuous-control benchmarks suggest that MQL compares favorably with the state of the art in meta-RL.",
            "original-pdf": "<a href=\"/attachment?id=SJeD3CEFPH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Ske31kBtPr",
            "paper_title": "Mathematical Reasoning in Latent Space",
            "forum_link": "https://openreview.net/forum?id=Ske31kBtPr",
            "pdf_link": "https://openreview.net/pdf?id=Ske31kBtPr",
            "authors": [
                  "Dennis Lee",
                  "Christian Szegedy",
                  "Markus Rabe",
                  "Sarah Loos",
                  "Kshitij Bansal"
            ],
            "keywords": "machine learning, formal reasoning",
            "tl;dr": "Learning to reason about higher order logic formulas in the latent space.",
            "abstract": "We design and conduct a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. The set of rewrites (i.e. transformations) that can be successfully performed on a statement represents essential semantic features of the statement. We can compress this information by embedding the formula in a vector space, such that the vector associated with a statement can be used to predict whether a statement can be rewritten by other theorems. Predicting the embedding of a formula generated by some rewrite rule is naturally viewed as approximate reasoning in the latent space. In order to measure the effectiveness of this reasoning, we perform approximate deduction sequences in the latent space and use the resulting embedding to inform the semantic features of the corresponding formal statement (which is obtained by performing the corresponding rewrite sequence using real formulas). Our experiments show that graph neural networks can make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representations for several steps. Since our corpus of mathematical formulas includes a wide variety of mathematical disciplines, this experiment is a strong indicator for the feasibility of deduction in latent space in general.",
            "original-pdf": "<a href=\"/attachment?id=Ske31kBtPr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1eBeyHFDH",
            "paper_title": "A Theory of Usable Information under Computational Constraints",
            "forum_link": "https://openreview.net/forum?id=r1eBeyHFDH",
            "pdf_link": "https://openreview.net/pdf?id=r1eBeyHFDH",
            "authors": [
                  "Yilun Xu",
                  "Shengjia Zhao",
                  "Jiaming Song",
                  "Russell Stewart",
                  "Stefano Ermon"
            ],
            "abstract": "We propose a new framework for reasoning about information in complex systems. Our foundation is based on a variational extension of Shannon\u2019s information theory that takes into account the modeling power and computational constraints of the observer. The resulting predictive V-information encompasses mutual information and other notions of informativeness such as the coefficient of determination. Unlike Shannon\u2019s mutual information and in violation of the data processing inequality, V-information can be created through computation. This is consistent with deep neural networks extracting hierarchies of progressively more informative features in representation learning. Additionally, we show that by incorporating computational constraints, V-information can be reliably estimated from data even in high dimensions with PAC-style guarantees. Empirically, we demonstrate predictive V-information is more effective than mutual information for structure learning and fair representation learning. Codes are available at https://github.com/Newbeeer/V-information .",
            "code": "<a href=\"https://github.com/Newbeeer/V-information\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/Newbeeer/V-information</a>",
            "original-pdf": "<a href=\"/attachment?id=r1eBeyHFDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rygixkHKDH",
            "paper_title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning",
            "forum_link": "https://openreview.net/forum?id=rygixkHKDH",
            "pdf_link": "https://openreview.net/pdf?id=rygixkHKDH",
            "authors": [
                  "Qing Qu",
                  "Yuexiang Zhai",
                  "Xiao Li",
                  "Yuqian Zhang",
                  "Zhihui Zhu"
            ],
            "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"7\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-msup><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c2113\"></mjx-c></mjx-mi><mjx-script style=\"vertical-align: 0.363em;\"><mjx-mn class=\"mjx-n\" size=\"s\"><mjx-c class=\"mjx-c34\"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>\u2113</mi><mn>4</mn></msup></math></mjx-assistive-mml></mjx-container>-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.",
            "keywords": "dictionary learning, sparse representations, nonconvex optimization",
            "original-pdf": "<a href=\"/attachment?id=rygixkHKDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "ryghZJBKPS",
            "paper_title": "Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds",
            "forum_link": "https://openreview.net/forum?id=ryghZJBKPS",
            "pdf_link": "https://openreview.net/pdf?id=ryghZJBKPS",
            "authors": [
                  "Jordan T. Ash",
                  "Chicheng Zhang",
                  "Akshay Krishnamurthy",
                  "John Langford",
                  "Alekh Agarwal"
            ],
            "tl;dr": "We introduce a new batch active learning algorithm that's robust to model architecture, batch size, and dataset.",
            "abstract": "We design a new algorithm for batch active learning with deep neural network models. Our algorithm, Batch Active learning by Diverse Gradient Embeddings (BADGE), samples groups of points that are disparate and high-magnitude when represented in a hallucinated gradient space, a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between diversity and uncertainty without requiring any hand-tuned hyperparameters. While other approaches sometimes succeed for particular batch sizes or architectures, BADGE consistently performs as well or better, making it a useful option for real world active learning problems.",
            "keywords": "deep learning, active learning, batch active learning",
            "original-pdf": "<a href=\"/attachment?id=ryghZJBKPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "H1gDNyrKDS",
            "paper_title": "Understanding and Robustifying Differentiable Architecture Search",
            "forum_link": "https://openreview.net/forum?id=H1gDNyrKDS",
            "pdf_link": "https://openreview.net/pdf?id=H1gDNyrKDS",
            "authors": [
                  "Arber Zela",
                  "Thomas Elsken",
                  "Tonmoy Saikia",
                  "Yassine Marrakchi",
                  "Thomas Brox",
                  "Frank Hutter"
            ],
            "keywords": "Neural Architecture Search, AutoML, AutoDL, Deep Learning, Computer Vision",
            "tl;dr": "We study the failure modes of DARTS (Differentiable Architecture Search) by looking at the eigenvalues of the Hessian of validation loss w.r.t. the architecture and propose robustifications based on our analysis.",
            "abstract": "Differentiable Architecture Search (DARTS) has attracted a lot of attention due to its simplicity and small search costs achieved by a continuous relaxation and an approximation of the resulting bi-level optimization problem.  However, DARTS does not work robustly for new problems: we identify a wide range of search spaces for which DARTS yields degenerate architectures with very poor test performance. We study this failure mode and show that, while DARTS successfully minimizes validation loss, the found solutions generalize poorly when they coincide with high validation loss curvature in the  architecture space. We show that by adding one of various types of regularization we can robustify DARTS to find solutions with less curvature and better generalization properties. Based on these observations, we propose several simple variations of DARTS that perform substantially more robustly in practice.  Our observations are robust across five search spaces on three image classification tasks and also hold for the very different domains of disparity estimation (a dense regression task) and language modelling.",
            "code": "<a href=\"https://github.com/automl/RobustDARTS\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/automl/RobustDARTS</a>",
            "original-pdf": "<a href=\"/attachment?id=H1gDNyrKDS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "ryxdEkHtPS",
            "paper_title": "A Closer Look at Deep Policy Gradients",
            "forum_link": "https://openreview.net/forum?id=ryxdEkHtPS",
            "pdf_link": "https://openreview.net/pdf?id=ryxdEkHtPS",
            "authors": [
                  "Andrew Ilyas",
                  "Logan Engstrom",
                  "Shibani Santurkar",
                  "Dimitris Tsipras",
                  "Firdaus Janoos",
                  "Larry Rudolph",
                  "Aleksander Madry"
            ],
            "keywords": "deep policy gradient methods, deep reinforcement learning, trpo, ppo",
            "abstract": "We study how the behavior of deep policy gradient algorithms reflects the conceptual framework motivating their development. To this end, we propose a fine-grained analysis of state-of-the-art methods based on key elements of this framework: gradient estimation, value prediction, and optimization landscapes. Our results show that the behavior of deep policy gradient algorithms often deviates from what their motivating framework would predict: surrogate rewards do not match the true reward landscape, learned value estimators fail to fit the true value function, and gradient estimates poorly correlate with the \"true\" gradient. The mismatch between predicted and empirical behavior we uncover highlights our poor understanding of current methods, and indicates the need to move beyond current benchmark-centric evaluation methods.",
            "original-pdf": "<a href=\"/attachment?id=ryxdEkHtPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1etN1rtPB",
            "paper_title": "Implementation Matters in Deep RL: A Case Study on PPO and TRPO",
            "forum_link": "https://openreview.net/forum?id=r1etN1rtPB",
            "pdf_link": "https://openreview.net/pdf?id=r1etN1rtPB",
            "authors": [
                  "Logan Engstrom",
                  "Andrew Ilyas",
                  "Shibani Santurkar",
                  "Dimitris Tsipras",
                  "Firdaus Janoos",
                  "Larry Rudolph",
                  "Aleksander Madry"
            ],
            "keywords": "deep policy gradient methods, deep reinforcement learning, trpo, ppo",
            "abstract": "We study the roots of algorithmic progress in deep policy gradient algorithms through a case study on two popular algorithms: Proximal Policy Optimization (PPO) and Trust Region Policy Optimization (TRPO). Specifically, we investigate the consequences of \"code-level optimizations:\" algorithm augmentations found only in implementations or described as auxiliary details to the core algorithm. Seemingly of secondary importance, such optimizations turn out to have a major impact on agent behavior. Our results show that they (a) are responsible for most of PPO's gain in cumulative reward over TRPO, and (b) fundamentally change how RL methods function. These insights show the difficulty, and importance, of attributing performance gains in deep reinforcement learning.",
            "code": "<a href=\"https://github.com/implementation-matters/code-for-paper\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/implementation-matters/code-for-paper</a>",
            "original-pdf": "<a href=\"/attachment?id=r1etN1rtPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJeAHkrYDS",
            "paper_title": "Fast Task Inference with Variational Intrinsic Successor Features",
            "forum_link": "https://openreview.net/forum?id=BJeAHkrYDS",
            "pdf_link": "https://openreview.net/pdf?id=BJeAHkrYDS",
            "authors": [
                  "Steven Hansen",
                  "Will Dabney",
                  "Andre Barreto",
                  "David Warde-Farley",
                  "Tom Van de Wiele",
                  "Volodymyr Mnih"
            ],
            "tl;dr": "We introduce Variational Intrinsic Successor FeatuRes (VISR), a novel algorithm which learns controllable features that can be leveraged to provide fast task inference through the successor features framework.",
            "abstract": "It has been established that diverse behaviors spanning the controllable subspace of a Markov decision process can be trained by rewarding a policy for being distinguishable from other policies. However, one limitation of this formulation is the difficulty to generalize beyond the finite set of behaviors being explicitly learned, as may be needed in subsequent tasks. Successor features provide an appealing solution to this generalization problem, but require defining the reward function as linear in some grounded feature space. In this paper, we show that these two techniques can be combined, and that each method solves the other's primary limitation. To do so we introduce Variational Intrinsic Successor FeatuRes (VISR), a novel algorithm which learns controllable features that can be leveraged to provide enhanced generalization and fast task inference through the successor features framework. We empirically validate VISR on the full Atari suite, in a novel setup wherein the rewards are only exposed briefly after a long unsupervised phase. Achieving human-level performance on 12 games and beating all baselines, we believe VISR represents a step towards agents that rapidly learn from limited feedback.",
            "keywords": "Reinforcement Learning, Variational Intrinsic Control, Successor Features",
            "original-pdf": "<a href=\"/attachment?id=BJeAHkrYDS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rkeZIJBYvr",
            "paper_title": "Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks",
            "forum_link": "https://openreview.net/forum?id=rkeZIJBYvr",
            "pdf_link": "https://openreview.net/pdf?id=rkeZIJBYvr",
            "authors": [
                  "Hae Beom Lee",
                  "Hayeon Lee",
                  "Donghyun Na",
                  "Saehoon Kim",
                  "Minseop Park",
                  "Eunho Yang",
                  "Sung Ju Hwang"
            ],
            "keywords": "meta-learning, few-shot learning, Bayesian neural network, variational inference, learning to learn, imbalanced and out-of-distribution tasks for few-shot learning",
            "tl;dr": "A novel meta-learning model that adaptively balances the effect of the meta-learning and task-specific learning, and also class-specific learning within each task.",
            "abstract": "While tasks could come with varying the number of instances and classes in realistic settings, the existing meta-learning approaches for few-shot classification assume that number of instances per task and class is fixed. Due to such restriction, they learn to equally utilize the meta-knowledge across all the tasks, even when the number of instances per task and class largely varies. Moreover, they do not consider distributional difference in unseen tasks, on which the meta-knowledge may have less usefulness depending on the task relatedness. To overcome these limitations, we propose a novel meta-learning model that adaptively balances the effect of the meta-learning and task-specific learning within each task. Through the learning of the balancing variables, we can decide whether to obtain a solution by relying on the meta-knowledge or task-specific learning. We formulate this objective into a Bayesian inference framework and tackle it using variational inference. We validate our Bayesian Task-Adaptive Meta-Learning (Bayesian TAML) on two realistic task- and class-imbalanced datasets, on which it significantly outperforms existing meta-learning approaches. Further ablation study confirms the effectiveness of each balancing component and the Bayesian learning framework.",
            "code": "<a href=\"https://github.com/haebeom-lee/l2b\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/haebeom-lee/l2b</a>",
            "original-pdf": "<a href=\"/attachment?id=rkeZIJBYvr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1eALyrYDH",
            "paper_title": "RNA Secondary Structure Prediction By Learning Unrolled Algorithms",
            "forum_link": "https://openreview.net/forum?id=S1eALyrYDH",
            "pdf_link": "https://openreview.net/pdf?id=S1eALyrYDH",
            "authors": [
                  "Xinshi Chen",
                  "Yu Li",
                  "Ramzan Umarov",
                  "Xin Gao",
                  "Le Song"
            ],
            "tl;dr": "A DL model for RNA secondary structure prediction, which uses an unrolled algorithm in the architecture to enforce constraints.",
            "abstract": "In this paper, we propose an end-to-end deep learning model, called E2Efold, for RNA secondary structure prediction which can effectively take into account the inherent constraints in the problem. The key idea of E2Efold is to directly predict the RNA base-pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. With comprehensive experiments on benchmark datasets, we demonstrate the superior performance of E2Efold: it predicts significantly better structures compared to previous SOTA (especially for pseudoknotted structures), while being as efficient as the fastest algorithms in terms of inference time.",
            "keywords": "RNA secondary structure prediction, learning algorithm, deep architecture design, computational biology",
            "code": "<a href=\"https://github.com/ml4bio/e2efold\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/ml4bio/e2efold</a>",
            "original-pdf": "<a href=\"/attachment?id=S1eALyrYDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJlQtJSKDB",
            "paper_title": "Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search",
            "forum_link": "https://openreview.net/forum?id=BJlQtJSKDB",
            "pdf_link": "https://openreview.net/pdf?id=BJlQtJSKDB",
            "authors": [
                  "Anji Liu",
                  "Jianshu Chen",
                  "Mingze Yu",
                  "Yu Zhai",
                  "Xuewen Zhou",
                  "Ji Liu"
            ],
            "tl;dr": "We developed an effective parallel UCT algorithm that achieves linear speedup and suffers negligible performance loss.",
            "abstract": "Monte Carlo Tree Search (MCTS) algorithms have achieved great success on many challenging benchmarks (e.g., Computer Go). However, they generally require a large number of rollouts, making their applications costly. Furthermore, it is also extremely challenging to parallelize MCTS due to its inherent sequential nature: each rollout heavily relies on the statistics (e.g., node visitation counts) estimated from previous simulations to achieve an effective exploration-exploitation tradeoff. In spite of these difficulties, we develop an algorithm, WU-UCT, to effectively parallelize MCTS, which achieves linear speedup and exhibits only limited performance loss with an increasing number of workers. The key idea in WU-UCT is a set of statistics that we introduce to track the number of on-going yet incomplete simulation queries (named as unobserved samples). These statistics are used to modify the UCT tree policy in the selection steps in a principled manner to retain effective exploration-exploitation tradeoff when we parallelize the most time-consuming expansion and simulation steps. Experiments on a proprietary benchmark and the Atari Game benchmark demonstrate the linear speedup and the superior performance of WU-UCT comparing to existing techniques.",
            "keywords": "parallel Monte Carlo Tree Search (MCTS), Upper Confidence bound for Trees (UCT), Reinforcement Learning (RL)",
            "original-pdf": "<a href=\"/attachment?id=BJlQtJSKDB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BygXFkSYDH",
            "paper_title": "Target-Embedding Autoencoders for Supervised Representation Learning",
            "forum_link": "https://openreview.net/forum?id=BygXFkSYDH",
            "pdf_link": "https://openreview.net/pdf?id=BygXFkSYDH",
            "authors": [
                  "Daniel Jarrett",
                  "Mihaela van der Schaar"
            ],
            "abstract": "Autoencoder-based learning has emerged as a staple for disciplining representations in unsupervised and semi-supervised settings. This paper analyzes a framework for improving generalization in a purely supervised setting, where the target space is high-dimensional. We motivate and formalize the general framework of target-embedding autoencoders (TEA) for supervised prediction, learning intermediate latent representations jointly optimized to be both predictable from features as well as predictive of targets---encoding the prior that variations in targets are driven by a compact set of underlying factors. As our theoretical contribution, we provide a guarantee of generalization for linear TEAs by demonstrating uniform stability, interpreting the benefit of the auxiliary reconstruction task as a form of regularization. As our empirical contribution, we extend validation of this approach beyond existing static classification applications to multivariate sequence forecasting, verifying their advantage on both linear and nonlinear recurrent architectures---thereby underscoring the further generality of this framework beyond feedforward instantiations.",
            "keywords": "autoencoders, supervised learning, representation learning, target-embedding, label-embedding",
            "original-pdf": "<a href=\"/attachment?id=BygXFkSYDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rkgNKkHtvB",
            "paper_title": "Reformer: The Efficient Transformer",
            "forum_link": "https://openreview.net/forum?id=rkgNKkHtvB",
            "pdf_link": "https://openreview.net/pdf?id=rkgNKkHtvB",
            "authors": [
                  "Nikita Kitaev",
                  "Lukasz Kaiser",
                  "Anselm Levskaya"
            ],
            "keywords": "attention, locality sensitive hashing, reversible layers",
            "tl;dr": "Efficient Transformer with locality-sensitive hashing and reversible layers",
            "abstract": "Large Transformer models routinely achieve state-of-the-art results on\n        a number of tasks but training these models can be prohibitively costly,\n        especially on long sequences. We introduce two techniques to improve\n        the efficiency of Transformers. For one, we replace dot-product attention\n        by one that uses locality-sensitive hashing, changing its complexity\n        from O(<mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"8\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-msup><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-script style=\"vertical-align: 0.363em;\"><mjx-mn class=\"mjx-n\" size=\"s\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>L</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container>) to O(<mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"9\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mi class=\"mjx-n\" space=\"2\"><mjx-c class=\"mjx-c6C\"></mjx-c><mjx-c class=\"mjx-c6F\"></mjx-c><mjx-c class=\"mjx-c67\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2061\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\" space=\"2\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mi>log</mi><mo data-mjx-texclass=\"NONE\">\u2061</mo><mi>L</mi></math></mjx-assistive-mml></mjx-container>), where <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"10\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></mjx-assistive-mml></mjx-container> is the length of the sequence.\n        Furthermore, we use reversible residual layers instead of the standard\n        residuals, which allows storing activations only once in the training\n        process instead of N times, where N is the number of layers.\n        The resulting model, the Reformer, performs on par with Transformer models\n        while being much more memory-efficient and much faster on long sequences.",
            "code": "<a href=\"https://github.com/google/trax/tree/master/trax/models/reformer\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/google/trax/tree/master/trax/models/reformer</a>",
            "original-pdf": "<a href=\"/attachment?id=rkgNKkHtvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rklr9kHFDB",
            "paper_title": "Rotation-invariant clustering of neuronal responses in primary visual cortex",
            "forum_link": "https://openreview.net/forum?id=rklr9kHFDB",
            "pdf_link": "https://openreview.net/pdf?id=rklr9kHFDB",
            "authors": [
                  "Ivan Ustyuzhaninov",
                  "Santiago A. Cadena",
                  "Emmanouil Froudarakis",
                  "Paul G. Fahey",
                  "Edgar Y. Walker",
                  "Erick Cobos",
                  "Jacob Reimer",
                  "Fabian H. Sinz",
                  "Andreas S. Tolias",
                  "Matthias Bethge",
                  "Alexander S. Ecker"
            ],
            "tl;dr": "We classify mouse V1 neurons into putative functional cell types based on their representations in a CNN predicting neural responses",
            "abstract": "Similar to a convolutional neural network (CNN), the mammalian retina encodes visual information into several dozen nonlinear feature maps, each formed by one ganglion cell type that tiles the visual space in an approximately shift-equivariant manner. Whether such organization into distinct cell types is maintained at the level of cortical image processing is an open question. Predictive models building upon convolutional features have been shown to provide state-of-the-art performance, and have recently been extended to include rotation equivariance in order to account for the orientation selectivity of V1 neurons. However, generally no direct correspondence between CNN feature maps and groups of individual neurons emerges in these models, thus rendering it an open question whether V1 neurons form distinct functional clusters. Here we build upon the rotation-equivariant representation of a CNN-based V1 model and propose a methodology for clustering the representations of neurons in this model to find functional cell types independent of preferred orientations of the neurons. We apply this method to a dataset of 6000 neurons and visualize the preferred stimuli of the resulting clusters. Our results highlight the range of non-linear computations in mouse V1.",
            "keywords": "computational neuroscience, neural system identification, functional cell types, deep learning, rotational equivariance",
            "original-pdf": "<a href=\"/attachment?id=rklr9kHFDB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1g2skStPB",
            "paper_title": "Causal Discovery with Reinforcement Learning",
            "forum_link": "https://openreview.net/forum?id=S1g2skStPB",
            "pdf_link": "https://openreview.net/pdf?id=S1g2skStPB",
            "authors": [
                  "Shengyu Zhu",
                  "Ignavier Ng",
                  "Zhitang Chen"
            ],
            "keywords": "causal discovery, structure learning, reinforcement learning, directed acyclic graph",
            "tl;dr": "We apply reinforcement learning to score-based causal discovery and achieve promising results on both synthetic and real datasets",
            "abstract": "Discovering causal structure among a set of variables is a fundamental problem in many empirical sciences. Traditional score-based casual discovery methods rely on various local heuristics to search for a Directed Acyclic Graph (DAG) according to a predefined score function. While these methods, e.g., greedy equivalence search, may have attractive results with infinite samples and certain model assumptions, they are less satisfactory in practice due to finite data and possible violation of assumptions. Motivated by recent advances in neural combinatorial optimization, we propose to use Reinforcement Learning (RL) to search for the DAG with the best scoring. Our encoder-decoder model takes observable data as input and generates graph adjacency matrices that are used to compute rewards. The reward incorporates both the predefined score function and two penalty terms for enforcing acyclicity. In contrast with typical RL applications where the goal is to learn a policy, we use RL as a search strategy and our final output would be the graph, among all graphs generated during training, that achieves the best reward. We conduct experiments on both synthetic and real datasets, and show that the proposed approach not only has an improved search ability but also allows for a flexible score function under the acyclicity constraint.",
            "original-pdf": "<a href=\"/attachment?id=S1g2skStPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rkg6sJHYDr",
            "paper_title": "Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems",
            "forum_link": "https://openreview.net/forum?id=rkg6sJHYDr",
            "pdf_link": "https://openreview.net/pdf?id=rkg6sJHYDr",
            "authors": [
                  "Chris Reinke",
                  "Mayalen Etcheverry",
                  "Pierre-Yves Oudeyer"
            ],
            "tl;dr": "We study how an unsupervised exploration and feature learning approach addresses efficiently a new problem: automatic discovery of diverse self-organized patterns in high-dim complex systems such as the game of life.",
            "abstract": "In many complex dynamical systems, artificial or natural, one can observe self-organization of patterns emerging from local rules. Cellular automata, like the Game of Life (GOL), have been widely used as abstract models enabling the study of various aspects of self-organization and morphogenesis, such as the emergence of spatially localized patterns. However, findings of self-organized patterns in such models have so far relied on manual tuning of parameters and initial states, and on the human eye to identify interesting patterns. In this paper, we formulate the problem of automated discovery of diverse self-organized patterns in such high-dimensional complex dynamical systems, as well as a framework for experimentation and evaluation. Using a continuous GOL as a testbed, we show that recent intrinsically-motivated machine learning algorithms (POP-IMGEPs), initially developed for learning of inverse models in robotics, can be transposed and used in this novel application area. These algorithms combine intrinsically-motivated goal exploration and unsupervised learning of goal space representations. Goal space representations describe the interesting features of patterns for which diverse variations should be discovered. In particular, we compare various approaches to define and learn goal space representations from the perspective of discovering diverse spatially localized patterns. Moreover, we introduce an extension of a state-of-the-art POP-IMGEP algorithm which incrementally learns a goal representation using a deep auto-encoder, and the use of CPPN primitives for generating initialization parameters. We show that it is more efficient than several baselines and equally efficient as a system pre-trained on a hand-made database of patterns identified by human experts.",
            "code": "<a href=\"https://automated-discovery.github.io/\" target=\"_blank\" rel=\"nofollow noreferrer\">https://automated-discovery.github.io/</a>",
            "keywords": "deep learning, unsupervised Learning, self-organization, game-of-life",
            "original-pdf": "<a href=\"/attachment?id=rkg6sJHYDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1xWh1rYwB",
            "paper_title": "Restricting the Flow: Information Bottlenecks for Attribution",
            "forum_link": "https://openreview.net/forum?id=S1xWh1rYwB",
            "pdf_link": "https://openreview.net/pdf?id=S1xWh1rYwB",
            "authors": [
                  "Karl Schulz",
                  "Leon Sixt",
                  "Federico Tombari",
                  "Tim Landgraf"
            ],
            "tl;dr": "We apply the informational bottleneck concept to attribution.",
            "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision.",
            "code": "<a href=\"https://github.com/BioroboticsLab/IBA-paper-code\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/BioroboticsLab/IBA-paper-code</a>",
            "keywords": "Attribution, Informational Bottleneck, Interpretable Machine Learning, Explainable AI",
            "original-pdf": "<a href=\"/attachment?id=S1xWh1rYwB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJgNJgSFPS",
            "paper_title": "Building Deep Equivariant Capsule Networks",
            "forum_link": "https://openreview.net/forum?id=BJgNJgSFPS",
            "pdf_link": "https://openreview.net/pdf?id=BJgNJgSFPS",
            "authors": [
                  "Sai Raam Venkataraman",
                  "S. Balasubramanian",
                  "R. Raghunatha Sarma"
            ],
            "keywords": "Capsule networks, equivariance",
            "tl;dr": "A new scalable, group-equivariant model for capsule networks that preserves compositionality under transformations, and is empirically more transformation-robust to older capsule network models.",
            "abstract": "Capsule networks are constrained by the parameter-expensive nature of their layers, and the general lack of provable equivariance guarantees. We present a variation of capsule networks that aims to remedy this. We identify that learning all pair-wise part-whole relationships between capsules of successive layers is inefficient. Further, we also realise that the choice of prediction networks and the routing mechanism are both key to equivariance. Based on these, we propose an alternative framework for capsule networks that learns to projectively encode the manifold of pose-variations, termed the space-of-variation (SOV), for every capsule-type of each layer. This is done using a trainable, equivariant function defined over a grid of group-transformations. Thus, the prediction-phase of routing involves projection into the SOV of a deeper capsule using the corresponding function. As a specific instantiation of this idea, and also in order to reap the benefits of increased parameter-sharing, we use type-homogeneous group-equivariant convolutions of shallower capsules in this phase. We also introduce an equivariant routing mechanism based on degree-centrality. We show that this particular instance of our general model is equivariant, and hence preserves the compositional representation of an input under transformations. We conduct several experiments on standard object-classification datasets that showcase the increased transformation-robustness, as well as general performance, of our model to several capsule baselines.",
            "code": "<a href=\"https://github.com/AnonymousCapsuleSOVNET/SOVNET\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/AnonymousCapsuleSOVNET/SOVNET</a>",
            "original-pdf": "<a href=\"/attachment?id=BJgNJgSFPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Bkl5kxrKDr",
            "paper_title": "A Generalized Training Approach for Multiagent Learning",
            "forum_link": "https://openreview.net/forum?id=Bkl5kxrKDr",
            "pdf_link": "https://openreview.net/pdf?id=Bkl5kxrKDr",
            "authors": [
                  "Paul Muller",
                  "Shayegan Omidshafiei",
                  "Mark Rowland",
                  "Karl Tuyls",
                  "Julien Perolat",
                  "Siqi Liu",
                  "Daniel Hennes",
                  "Luke Marris",
                  "Marc Lanctot",
                  "Edward Hughes",
                  "Zhe Wang",
                  "Guy Lever",
                  "Nicolas Heess",
                  "Thore Graepel",
                  "Remi Munos"
            ],
            "keywords": "multiagent learning, game theory, training, games",
            "abstract": "This paper investigates a population-based training regime based on game-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is general in the sense that it (1) encompasses well-known algorithms such as fictitious play and double oracle as special cases, and (2) in principle applies to general-sum, many-player games. Despite this, prior studies of PSRO have been focused on two-player zero-sum games, a regime where in Nash equilibria are tractably computable. In moving from two-player zero-sum games to more general settings, computation of Nash equilibria quickly becomes infeasible.  Here, we extend the theoretical underpinnings of PSRO by considering an alternative solution concept, \u03b1-Rank, which is unique (thus faces no equilibrium selection issues, unlike Nash) and applies readily to general-sum, many-player settings. We establish convergence guarantees in several games classes, and identify links between Nash equilibria and \u03b1-Rank. We demonstrate the competitive performance of \u03b1-Rank-based PSRO against an exact Nash solver-based PSRO in 2-player Kuhn and Leduc Poker. We then go beyond the reach of prior PSRO applications by considering 3- to 5-player poker games, yielding instances where \u03b1-Rank achieves faster convergence than approximate Nash solvers, thus establishing it as a favorable general games solver. We also carry out an initial empirical validation in MuJoCo soccer, illustrating the feasibility of the proposed approach in another complex domain.",
            "original-pdf": "<a href=\"/attachment?id=Bkl5kxrKDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1gfQgSFDr",
            "paper_title": "High Fidelity Speech Synthesis with Adversarial Networks",
            "forum_link": "https://openreview.net/forum?id=r1gfQgSFDr",
            "pdf_link": "https://openreview.net/pdf?id=r1gfQgSFDr",
            "authors": [
                  "Miko\u0142aj Bi\u0144kowski",
                  "Jeff Donahue",
                  "Sander Dieleman",
                  "Aidan Clark",
                  "Erich Elsen",
                  "Norman Casagrande",
                  "Luis C. Cobo",
                  "Karen Simonyan"
            ],
            "tl;dr": "We introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech, which achieves Mean Opinion Score (MOS) 4.2.",
            "abstract": "Generative adversarial networks have seen rapid development in recent years and have led to remarkable improvements in generative modelling of images. However, their application in the audio domain has received limited attention,\n        and autoregressive models, such as WaveNet, remain the state of the art in generative modelling of audio signals such as human speech. To address this paucity, we introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech.\n        Our architecture is composed of a conditional feed-forward generator producing raw speech audio, and an ensemble of discriminators which operate on random windows of different sizes. The discriminators analyse the audio both in terms of general realism, as well as how well the audio corresponds to the utterance that should be pronounced.  To measure the performance of GAN-TTS, we employ both subjective human evaluation (MOS - Mean Opinion Score), as well as novel quantitative metrics (Fr\u00e9chet DeepSpeech Distance and Kernel DeepSpeech Distance), which we find to be well correlated with MOS. We show that GAN-TTS is capable of generating high-fidelity speech with naturalness comparable to the state-of-the-art models, and unlike autoregressive models, it is highly parallelisable thanks to an efficient feed-forward generator. Listen to GAN-TTS reading this abstract at https://storage.googleapis.com/deepmind-media/research/abstract.wav",
            "keywords": "texttospeech, speechsynthesis, audiosynthesis, gans, generativeadversarialnetworks, implicitgenerativemodels",
            "code": "<a href=\"https://github.com/mbinkowski/DeepSpeechDistances\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/mbinkowski/DeepSpeechDistances</a>",
            "original-pdf": "<a href=\"/attachment?id=r1gfQgSFDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rkgvXlrKwH",
            "paper_title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference",
            "forum_link": "https://openreview.net/forum?id=rkgvXlrKwH",
            "pdf_link": "https://openreview.net/pdf?id=rkgvXlrKwH",
            "authors": [
                  "Lasse Espeholt",
                  "Rapha\u00ebl Marinier",
                  "Piotr Stanczyk",
                  "Ke Wang",
                  "Marcin Michalski\u200e"
            ],
            "tl;dr": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second.",
            "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.",
            "code": "<a href=\"https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing\" target=\"_blank\" rel=\"nofollow noreferrer\">https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing</a>",
            "keywords": "machine learning, reinforcement learning, scalability, distributed, DeepMind Lab, ALE, Atari-57, Google Research Football",
            "original-pdf": "<a href=\"/attachment?id=rkgvXlrKwH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rkeiQlBFPB",
            "paper_title": "Meta-Learning with Warped Gradient Descent",
            "forum_link": "https://openreview.net/forum?id=rkeiQlBFPB",
            "pdf_link": "https://openreview.net/pdf?id=rkeiQlBFPB",
            "authors": [
                  "Sebastian Flennerhag",
                  "Andrei A. Rusu",
                  "Razvan Pascanu",
                  "Francesco Visin",
                  "Hujun Yin",
                  "Raia Hadsell"
            ],
            "tl;dr": "We propose a novel framework for meta-learning a gradient-based update rule that scales to beyond few-shot learning and is applicable to any form of learning, including continual learning.",
            "abstract": "Learning an efficient update rule from data that promotes rapid learning of new tasks from the same distribution remains an open problem in meta-learning. Typically, previous works have approached this issue either by attempting to train a neural network that directly produces updates or by attempting to learn better initialisations or scaling factors for a gradient-based update rule. Both of these approaches pose challenges. On one hand, directly producing an update forgoes a useful inductive bias and can easily lead to non-converging behaviour. On the other hand, approaches that try to control a gradient-based update rule typically resort to computing gradients through the learning process to obtain their meta-gradients, leading to methods that can not scale beyond few-shot task adaptation. In this work, we propose Warped Gradient Descent (WarpGrad), a method that intersects these approaches to mitigate their limitations. WarpGrad meta-learns an efficiently parameterised preconditioning matrix that facilitates gradient descent across the task distribution. Preconditioning arises by interleaving non-linear layers, referred to as warp-layers, between the layers of a task-learner. Warp-layers are meta-learned without backpropagating through the task training process in a manner similar to methods that learn to directly produce updates. WarpGrad is computationally efficient, easy to implement, and can scale to arbitrarily large meta-learning problems. We provide a geometrical interpretation of the approach and evaluate its effectiveness in a variety of settings, including few-shot, standard supervised, continual and reinforcement learning.",
            "keywords": "meta-learning, transfer learning",
            "code": "<a href=\"https://github.com/flennerhag/warpgrad\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/flennerhag/warpgrad</a>",
            "original-pdf": "<a href=\"/attachment?id=rkeiQlBFPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Skey4eBYPS",
            "paper_title": "Convolutional Conditional Neural Processes",
            "forum_link": "https://openreview.net/forum?id=Skey4eBYPS",
            "pdf_link": "https://openreview.net/pdf?id=Skey4eBYPS",
            "authors": [
                  "Jonathan Gordon",
                  "Wessel P. Bruinsma",
                  "Andrew Y. K. Foong",
                  "James Requeima",
                  "Yann Dubois",
                  "Richard E. Turner"
            ],
            "tl;dr": "We extend deep sets to functional embeddings and Neural Processes to include translation equivariant members",
            "abstract": "We introduce the Convolutional Conditional Neural Process (ConvCNP), a new member of the Neural Process family that models translation equivariance in the data. Translation equivariance is an important inductive bias for many learning problems including time series modelling, spatial data, and images. The model embeds data sets into an infinite-dimensional function space, as opposed to finite-dimensional vector spaces. To formalize this notion, we extend the theory of neural representations of sets to include functional representations, and demonstrate that any translation-equivariant embedding can be represented using a convolutional deep-set. We evaluate ConvCNPs in several settings, demonstrating that they achieve state-of-the-art performance compared to existing NPs. We demonstrate that building in translation equivariance enables zero-shot generalization to challenging, out-of-domain tasks.",
            "keywords": "Neural Processes, Deep Sets, Translation Equivariance",
            "code": "<a href=\"https://github.com/cambridge-mlg/convcnp\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/cambridge-mlg/convcnp</a>",
            "original-pdf": "<a href=\"/attachment?id=Skey4eBYPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJeLIgBKPS",
            "paper_title": "Gradient Descent Maximizes the Margin of Homogeneous Neural Networks",
            "forum_link": "https://openreview.net/forum?id=SJeLIgBKPS",
            "pdf_link": "https://openreview.net/pdf?id=SJeLIgBKPS",
            "authors": [
                  "Kaifeng Lyu",
                  "Jian Li"
            ],
            "tl;dr": "We study the implicit bias of gradient descent and prove under a minimal set of assumptions that the parameter direction of homogeneous models converges to KKT points of a natural margin maximization problem.",
            "abstract": "In this paper, we study the implicit regularization of the gradient descent algorithm in homogeneous neural networks, including fully-connected and convolutional neural networks with ReLU or LeakyReLU activations. In particular, we study the gradient descent or gradient flow (i.e., gradient descent with infinitesimal step size) optimizing the logistic loss or cross-entropy loss of any homogeneous model (possibly non-smooth), and show that if the training loss decreases below a certain threshold, then we can define a smoothed version of the normalized margin which increases over time. We also formulate a natural constrained optimization problem related to margin maximization, and prove that both the normalized margin and its smoothed version converge to the objective value at a KKT point of the optimization problem. Our results generalize the previous results for logistic regression with one-layer or multi-layer linear networks, and provide more quantitative convergence results with weaker assumptions than previous results for homogeneous smooth neural networks. We conduct several experiments to justify our theoretical finding on MNIST and CIFAR-10 datasets. Finally, as margin is closely related to robustness, we discuss potential benefits of training longer for improving the robustness of the model.",
            "keywords": "margin, homogeneous, gradient descent",
            "code": "<a href=\"https://github.com/vfleaking/max-margin\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/vfleaking/max-margin</a>",
            "original-pdf": "<a href=\"/attachment?id=SJeLIgBKPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJxSDxrKDr",
            "paper_title": "Adversarial Training and Provable Defenses: Bridging the Gap",
            "forum_link": "https://openreview.net/forum?id=SJxSDxrKDr",
            "pdf_link": "https://openreview.net/pdf?id=SJxSDxrKDr",
            "authors": [
                  "Mislav Balunovic",
                  "Martin Vechev"
            ],
            "tl;dr": "We propose a novel combination of adversarial training and provable defenses which produces a model with state-of-the-art accuracy and certified robustness on CIFAR-10.",
            "abstract": "We present COLT, a new method to train neural networks based on a novel combination of adversarial training and provable defenses. The key idea is to model neural network training as a procedure which includes both, the verifier and the adversary. In every iteration, the verifier aims to certify the network using convex relaxation while the adversary tries to find inputs inside that convex relaxation which cause verification to fail. We experimentally show that this training method, named convex layerwise adversarial training (COLT), is promising and achieves the best of both worlds -- it produces a state-of-the-art neural network with certified robustness of 60.5% and accuracy of 78.4% on the challenging CIFAR-10 dataset with a 2/255 L-infinity perturbation. This significantly improves over the best concurrent results of 54.0% certified robustness and 71.5% accuracy.",
            "keywords": "adversarial examples, adversarial training, provable defense, convex relaxations, deep learning",
            "original-pdf": "<a href=\"/attachment?id=SJxSDxrKDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJxstlHFPH",
            "paper_title": "Differentiable Reasoning over a Virtual Knowledge Base",
            "forum_link": "https://openreview.net/forum?id=SJxstlHFPH",
            "pdf_link": "https://openreview.net/pdf?id=SJxstlHFPH",
            "authors": [
                  "Bhuwan Dhingra",
                  "Manzil Zaheer",
                  "Vidhisha Balachandran",
                  "Graham Neubig",
                  "Ruslan Salakhutdinov",
                  "William W. Cohen"
            ],
            "tl;dr": "Differentiable multi-hop access to a textual knowledge base of indexed contextual representations",
            "abstract": "We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing up to 10-100x more queries per second than existing multi-hop systems.",
            "keywords": "Question Answering, Multi-Hop QA, Deep Learning, Knowledge Bases, Information Extraction, Data Structures for QA",
            "code": "<a href=\"http://www.cs.cmu.edu/~bdhingra/pages/drkit.html\" target=\"_blank\" rel=\"nofollow noreferrer\">http://www.cs.cmu.edu/~bdhingra/pages/drkit.html</a>",
            "original-pdf": "<a href=\"/attachment?id=SJxstlHFPH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BkluqlSFDS",
            "paper_title": "Federated Learning with Matched Averaging",
            "forum_link": "https://openreview.net/forum?id=BkluqlSFDS",
            "pdf_link": "https://openreview.net/pdf?id=BkluqlSFDS",
            "authors": [
                  "Hongyi Wang",
                  "Mikhail Yurochkin",
                  "Yuekai Sun",
                  "Dimitris Papailiopoulos",
                  "Yasaman Khazaeni"
            ],
            "tl;dr": "Communication efficient federated learning with layer-wise matching",
            "abstract": "Federated learning allows edge devices to collaboratively learn a shared model while keeping the training data on device, decoupling the ability to do model training from the need to store the data in the cloud. We propose Federated matched averaging (FedMA) algorithm designed for federated learning of modern neural network architectures e.g. convolutional neural networks (CNNs) and LSTMs. FedMA constructs the shared global model in a layer-wise manner by matching and averaging hidden elements (i.e. channels for convolution layers; hidden states for LSTM; neurons for fully connected layers) with similar feature extraction signatures. Our experiments indicate that FedMA not only outperforms popular state-of-the-art federated learning algorithms on deep CNN and LSTM architectures trained on real world datasets, but also reduces the overall communication burden.",
            "keywords": "federated learning",
            "code": "<a href=\"https://github.com/IBM/FedMA\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/IBM/FedMA</a>",
            "original-pdf": "<a href=\"/attachment?id=BkluqlSFDS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      }
]