[
      {
            "data_id": "SJgwNerKvB",
            "paper_title": "Continual learning with hypernetworks",
            "forum_link": "https://openreview.net/forum?id=SJgwNerKvB",
            "pdf_link": "https://openreview.net/pdf?id=SJgwNerKvB",
            "authors": [
                  "Johannes von Oswald",
                  "Christian Henning",
                  "Jo\u00e3o Sacramento",
                  "Benjamin F. Grewe"
            ],
            "abstract": "Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, we present a novel approach based on task-conditioned hypernetworks, i.e., networks that generate the weights of a target model based on task identity. Continual learning (CL) is less difficult for this class of models thanks to a simple key feature: instead of recalling the input-output relations of all previously seen data, task-conditioned hypernetworks only require rehearsing task-specific weight realizations, which can be maintained in memory using a simple regularizer. Besides achieving state-of-the-art performance on standard CL benchmarks, additional experiments on long task sequences reveal that task-conditioned hypernetworks display a very large capacity to retain previous memories. Notably, such long memory lifetimes are achieved in a compressive regime, when the number of trainable hypernetwork weights is comparable or smaller than target network size. We provide insight into the structure of low-dimensional task embedding spaces (the input space of the hypernetwork) and show that task-conditioned hypernetworks demonstrate transfer learning. Finally, forward information transfer is further supported by empirical results on a challenging CL benchmark based on the CIFAR-10/100 image datasets.",
            "keywords": "Continual Learning, Catastrophic Forgetting, Meta Model, Hypernetwork",
            "code": "<a href=\"https://github.com/chrhenning/hypercl\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/chrhenning/hypercl</a>",
            "original-pdf": "<a href=\"/attachment?id=SJgwNerKvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BkxUvnEYDH",
            "paper_title": "Program Guided Agent",
            "forum_link": "https://openreview.net/forum?id=BkxUvnEYDH",
            "pdf_link": "https://openreview.net/pdf?id=BkxUvnEYDH",
            "authors": [
                  "Shao-Hua Sun",
                  "Te-Lin Wu",
                  "Joseph J. Lim"
            ],
            "tl;dr": "We propose a modular framework that can accomplish tasks specified by programs and achieve zero-shot generalization to more complex tasks.",
            "abstract": "Developing agents that can learn to follow natural language instructions has been an emerging research direction. While being accessible and flexible, natural language instructions can sometimes be ambiguous even to humans. To address this, we propose to utilize programs, structured in a formal language, as a precise and expressive way to specify tasks. We then devise a modular framework that learns to perform a task specified by a program \u2013 as different circumstances give rise to diverse ways to accomplish the task, our framework can perceive which circumstance it is currently under, and instruct a multitask policy accordingly to fulfill each subtask of the overall task. Experimental results on a 2D Minecraft environment not only demonstrate that the proposed framework learns to reliably accomplish program instructions and achieves zero-shot generalization to more complex instructions but also verify the efficiency of the proposed modulation mechanism for learning the multitask policy. We also conduct an analysis comparing various models which learn from programs and natural language instructions in an end-to-end fashion.",
            "keywords": "Program Execution, Program Executor, Program Understanding, Program Guided Agent, Learning to Execute, Deep Learning",
            "original-pdf": "<a href=\"/attachment?id=BkxUvnEYDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BygPO2VKPH",
            "paper_title": "Sparse Coding with Gated Learned ISTA",
            "forum_link": "https://openreview.net/forum?id=BygPO2VKPH",
            "pdf_link": "https://openreview.net/pdf?id=BygPO2VKPH",
            "authors": [
                  "Kailun Wu",
                  "Yiwen Guo",
                  "Ziang Li",
                  "Changshui Zhang"
            ],
            "tl;dr": "We propose gated mechanisms to enhance learned ISTA for sparse coding, with theoretical guarantees on the superiority of the method.",
            "abstract": "In this paper, we study the learned iterative shrinkage thresholding algorithm (LISTA) for solving sparse coding problems.  Following assumptions made by prior works, we first discover that the code components in its estimations may be lower than expected, i.e., require gains, and to address this problem, a gated mechanism amenable to theoretical analysis is then introduced. Specific design of the gates is inspired by convergence analyses of the mechanism and hence its effectiveness can be formally guaranteed. In addition to the gain gates, we further introduce overshoot gates for compensating insufficient step size in LISTA. Extensive empirical results confirm our theoretical findings and verify the effectiveness of our method.",
            "keywords": "Sparse coding, deep learning, learned ISTA, convergence analysis",
            "code": "<a href=\"https://github.com/wukailun/GLISTA\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/wukailun/GLISTA</a>",
            "original-pdf": "<a href=\"/attachment?id=BygPO2VKPH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1ldO2EFPr",
            "paper_title": "Graph Neural Networks Exponentially Lose Expressive Power for Node Classification",
            "forum_link": "https://openreview.net/forum?id=S1ldO2EFPr",
            "pdf_link": "https://openreview.net/pdf?id=S1ldO2EFPr",
            "authors": [
                  "Kenta Oono",
                  "Taiji Suzuki"
            ],
            "tl;dr": "We relate the asymptotic behavior of graph neural networks to the graph spectra of underlying graphs and gives principled guidelines for normalizing weights.",
            "abstract": "Graph Neural Networks (graph NNs) are a promising deep learning approach for analyzing graph-structured data. However, it is known that they do not improve (or sometimes worsen) their predictive performance as we pile up many layers and add non-lineality. To tackle this problem, we investigate the expressive power of graph NNs via their asymptotic behaviors as the layer size tends to infinity.\n        Our strategy is to generalize the forward propagation of a Graph Convolutional Network (GCN), which is a popular graph NN variant, as a specific dynamical system. In the case of a GCN, we show that when its weights satisfy the conditions determined by the spectra of the (augmented) normalized Laplacian, its output exponentially approaches the set of signals that carry information of the connected components and node degrees only for distinguishing nodes.\n        Our theory enables us to relate the expressive power of GCNs with the topological information of the underlying graphs inherent in the graph spectra. To demonstrate this, we characterize the asymptotic behavior of GCNs on the Erd\\H{o}s -- R\\'{e}nyi graph.\n        We show that when the Erd\\H{o}s -- R\\'{e}nyi graph is sufficiently dense and large, a broad range of GCNs on it suffers from the ``information loss\" in the limit of infinite layers with high probability.\n        Based on the theory, we provide a principled guideline for weight normalization of graph NNs. We experimentally confirm that the proposed weight scaling enhances the predictive performance of GCNs in real data. Code is available at https://github.com/delta2323/gnn-asymptotics.",
            "code": "<a href=\"https://github.com/delta2323/gnn-asymptotics\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/delta2323/gnn-asymptotics</a>",
            "keywords": "Graph Neural Network, Deep Learning, Expressive Power",
            "original-pdf": "<a href=\"/attachment?id=S1ldO2EFPr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rJljdh4KDH",
            "paper_title": "Multi-Scale Representation Learning  for Spatial Feature Distributions using Grid Cells",
            "forum_link": "https://openreview.net/forum?id=rJljdh4KDH",
            "pdf_link": "https://openreview.net/pdf?id=rJljdh4KDH",
            "authors": [
                  "Gengchen Mai",
                  "Krzysztof Janowicz",
                  "Bo Yan",
                  "Rui Zhu",
                  "Ling Cai",
                  "Ni Lao"
            ],
            "keywords": "Grid cell, space encoding, spatially explicit model, multi-scale periodic representation, unsupervised learning",
            "tl;dr": "We propose a representation learning model called Space2vec to encode the absolute positions and spatial relationships of places.",
            "abstract": "Unsupervised text encoding models have recently fueled substantial progress in NLP. The key idea is to use neural networks to convert words in texts to vector space representations (embeddings) based on word positions in a sentence and their contexts, which are suitable for end-to-end training of downstream tasks. We see a strikingly similar situation in spatial analysis, which focuses on incorporating both absolute positions and spatial contexts of geographic objects such as POIs into models. A general-purpose representation model for space is valuable for a multitude of tasks. However, no such general model exists to date beyond simply applying discretization or feed-forward&nbsp;nets to coordinates, and little effort has been put into jointly modeling distributions with vastly different characteristics, which commonly emerges from GIS data. Meanwhile, Nobel Prize-winning Neuroscience research shows that grid cells in mammals provide a multi-scale periodic representation that functions as a metric for location encoding and is critical for recognizing places and for path-integration. Therefore, we propose a representation learning model called Space2Vec to encode the absolute positions and spatial relationships of places. We conduct experiments on two real-world geographic data for two different tasks: 1) predicting types of POIs given their positions and context, 2) image classification leveraging their geo-locations. Results show that because of its multi-scale representations, Space2Vec outperforms well-established ML approaches such as RBF kernels, multi-layer feed-forward nets, and tile embedding approaches for location modeling and image classification tasks. Detailed analysis shows that all baselines can at most well handle distribution at one scale but show poor performances in other scales. In contrast, Space2Vec \u2019s multi-scale representation can handle distributions at different scales.",
            "code": "<a href=\"https://github.com/gengchenmai/space2vec\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/gengchenmai/space2vec</a>",
            "original-pdf": "<a href=\"/attachment?id=rJljdh4KDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1lfF2NYvH",
            "paper_title": "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization",
            "forum_link": "https://openreview.net/forum?id=r1lfF2NYvH",
            "pdf_link": "https://openreview.net/pdf?id=r1lfF2NYvH",
            "authors": [
                  "Fan-Yun Sun",
                  "Jordan Hoffman",
                  "Vikas Verma",
                  "Jian Tang"
            ],
            "abstract": "This paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semisupervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.",
            "keywords": "graph-level representation learning, mutual information maximization",
            "code": "<a href=\"https://github.com/fanyun-sun/InfoGraph\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/fanyun-sun/InfoGraph</a>",
            "original-pdf": "<a href=\"/attachment?id=r1lfF2NYvH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "B1e9Y2NYvS",
            "paper_title": "On Robustness of Neural Ordinary Differential Equations",
            "forum_link": "https://openreview.net/forum?id=B1e9Y2NYvS",
            "pdf_link": "https://openreview.net/pdf?id=B1e9Y2NYvS",
            "authors": [
                  "Hanshu YAN",
                  "Jiawei DU",
                  "Vincent TAN",
                  "Jiashi FENG"
            ],
            "abstract": "Neural ordinary differential equations (ODEs) have been attracting increasing attention in various research domains recently.  There have been some works studying optimization issues and approximation capabilities of neural ODEs, but their robustness is still yet unclear. In this work, we fill this important gap by exploring robustness properties of neural ODEs both empirically and theoretically. We first present an empirical study on the robustness of the neural ODE-based networks (ODENets) by exposing them to inputs with various types of perturbations and subsequently investigating the changes of the corresponding outputs. In contrast to conventional convolutional neural networks (CNNs), we find that the ODENets are more robust against both random Gaussian perturbations and adversarial attack examples. We then provide an insightful understanding of this phenomenon by exploiting a certain desirable property of the flow of a continuous-time ODE, namely that integral curves are non-intersecting. Our work suggests that, due to their intrinsic robustness, it is promising to use neural ODEs as a basic block for building robust deep network models. To further enhance the robustness of vanilla neural ODEs, we propose the time-invariant steady neural ODE (TisODE), which regularizes the flow on perturbed data via the time-invariant property and the imposition of a steady-state constraint. We show that the TisODE method outperforms vanilla neural ODEs and also can work in conjunction with other state-of-the-art architectural methods to build more robust deep networks.",
            "keywords": "Neural ODE",
            "original-pdf": "<a href=\"/attachment?id=B1e9Y2NYvS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "H1xscnEKDr",
            "paper_title": "Defending Against Physically Realizable Attacks on Image Classification",
            "forum_link": "https://openreview.net/forum?id=H1xscnEKDr",
            "pdf_link": "https://openreview.net/pdf?id=H1xscnEKDr",
            "authors": [
                  "Tong Wu",
                  "Liang Tong",
                  "Yevgeniy Vorobeychik"
            ],
            "tl;dr": "Defending Against Physically Realizable Attacks on Image Classification",
            "abstract": "We study the problem of defending deep neural network approaches for image classification from physically realizable attacks. First, we demonstrate that the two most scalable and effective methods for learning robust models, adversarial training with PGD attacks and randomized smoothing, exhibit very limited effectiveness against three of the highest profile physical attacks. Next, we propose a new abstract adversarial model, rectangular occlusion attacks, in which an adversary places a small adversarially crafted rectangle in an image, and develop two approaches for efficiently computing the resulting adversarial examples. Finally, we demonstrate that adversarial training using our new attack yields image classification models that exhibit high robustness against the physically realizable attacks we study, offering the first effective generic defense against such attacks.",
            "keywords": "defense against physical attacks, adversarial machine learning",
            "code": "<a href=\"https://github.com/tongwu2020/phattacks\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/tongwu2020/phattacks</a>",
            "original-pdf": "<a href=\"/attachment?id=H1xscnEKDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rklEj2EFvB",
            "paper_title": "Estimating Gradients for Discrete Random Variables by Sampling without Replacement",
            "forum_link": "https://openreview.net/forum?id=rklEj2EFvB",
            "pdf_link": "https://openreview.net/pdf?id=rklEj2EFvB",
            "authors": [
                  "Wouter Kool",
                  "Herke van Hoof",
                  "Max Welling"
            ],
            "keywords": "gradient, estimator, discrete, categorical, sampling, without replacement, reinforce, baseline, variance, gumbel, vae, structured prediction",
            "tl;dr": "We derive a low-variance, unbiased gradient estimator for expectations over discrete random variables based on sampling without replacement",
            "abstract": "We derive an unbiased estimator for expectations over discrete random variables based on sampling without replacement, which reduces variance as it avoids duplicate samples. We show that our estimator can be derived as the Rao-Blackwellization of three different estimators. Combining our estimator with REINFORCE, we obtain a policy gradient estimator and we reduce its variance using a built-in control variate which is obtained without additional model evaluations. The resulting estimator is closely related to other gradient estimators. Experiments with a toy problem, a categorical Variational Auto-Encoder and a structured prediction problem show that our estimator is the only estimator that is consistently among the best estimators in both high and low entropy settings.",
            "code": "<a href=\"https://github.com/wouterkool/estimating-gradients-without-replacement\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/wouterkool/estimating-gradients-without-replacement</a>",
            "original-pdf": "<a href=\"/attachment?id=rklEj2EFvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HyeSin4FPB",
            "paper_title": "Learning to Control PDEs with Differentiable Physics",
            "forum_link": "https://openreview.net/forum?id=HyeSin4FPB",
            "pdf_link": "https://openreview.net/pdf?id=HyeSin4FPB",
            "authors": [
                  "Philipp Holl",
                  "Nils Thuerey",
                  "Vladlen Koltun"
            ],
            "keywords": "Differentiable physics, Optimal control, Deep learning",
            "tl;dr": "We train a combination of neural networks to predict optimal trajectories for complex physical systems.",
            "abstract": "Predicting outcomes and planning interactions with the physical world are long-standing goals for machine learning. A variety of such tasks involves continuous physical systems, which can be described by partial differential equations (PDEs) with many degrees of freedom. Existing methods that aim to control the dynamics of such systems are typically limited to relatively short time frames or a small number of interaction parameters. We present a novel hierarchical predictor-corrector scheme which enables neural networks to learn to understand and control complex nonlinear physical systems over long time frames. We propose to split the problem into two distinct tasks: planning and control. To this end, we introduce a predictor network that plans optimal trajectories and a control network that infers the corresponding control parameters. Both stages are trained end-to-end using a differentiable PDE solver. We demonstrate that our method successfully develops an understanding of complex physical systems and learns to control them for tasks involving PDEs such as the incompressible Navier-Stokes equations.",
            "original-pdf": "<a href=\"/attachment?id=HyeSin4FPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HygOjhEYDH",
            "paper_title": "Intensity-Free Learning of Temporal Point Processes",
            "forum_link": "https://openreview.net/forum?id=HygOjhEYDH",
            "pdf_link": "https://openreview.net/pdf?id=HygOjhEYDH",
            "authors": [
                  "Oleksandr Shchur",
                  "Marin Bilo\u0161",
                  "Stephan G\u00fcnnemann"
            ],
            "tl;dr": "Learn in temporal point processes by modeling the conditional density, not the conditional intensity.",
            "abstract": "Temporal point processes are the dominant paradigm for modeling sequences of events happening at irregular intervals. The standard way of learning in such models is by estimating the conditional intensity function.  However, parameterizing the intensity function usually incurs several trade-offs. We show how to overcome the limitations of intensity-based approaches by directly modeling the conditional distribution of inter-event times.  We draw on the literature on normalizing flows to design models that are flexible and efficient. We additionally propose a simple mixture model that matches the flexibility of flow-based models, but also permits sampling and computing moments in closed form.  The proposed models achieve state-of-the-art performance in standard prediction tasks and are suitable for novel applications, such as learning sequence embeddings and imputing missing data.",
            "code": "<a href=\"https://github.com/shchur/ifl-tpp\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/shchur/ifl-tpp</a>",
            "keywords": "Temporal point process, neural density estimation",
            "original-pdf": "<a href=\"/attachment?id=HygOjhEYDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HJeTo2VFwH",
            "paper_title": "A Signal Propagation Perspective for Pruning Neural Networks at Initialization",
            "forum_link": "https://openreview.net/forum?id=HJeTo2VFwH",
            "pdf_link": "https://openreview.net/pdf?id=HJeTo2VFwH",
            "authors": [
                  "Namhoon Lee",
                  "Thalaiyasingam Ajanthan",
                  "Stephen Gould",
                  "Philip H. S. Torr"
            ],
            "tl;dr": "We formally characterize the initialization conditions for effective pruning at initialization and analyze the signal propagation properties of the resulting pruned networks which leads to a method to enhance their trainability and pruning results.",
            "abstract": "Network pruning is a promising avenue for compressing deep neural networks. A typical approach to pruning starts by training a model and then removing redundant parameters while minimizing the impact on what is learned. Alternatively, a recent approach shows that pruning can be done at initialization prior to training, based on a saliency criterion called connection sensitivity. However, it remains unclear exactly why pruning an untrained, randomly initialized neural network is effective. In this work, by noting connection sensitivity as a form of gradient, we formally characterize initialization conditions to ensure reliable connection sensitivity measurements, which in turn yields effective pruning results. Moreover, we analyze the signal propagation properties of the resulting pruned networks and introduce a simple, data-free method to improve their trainability. Our modifications to the existing pruning at initialization method lead to improved results on all tested network models for image classification tasks. Furthermore, we empirically study the effect of supervision for pruning and demonstrate that our signal propagation perspective, combined with unsupervised pruning, can be useful in various scenarios where pruning is applied to non-standard arbitrarily-designed architectures.",
            "keywords": "neural network pruning, signal propagation perspective, sparse neural networks",
            "original-pdf": "<a href=\"/attachment?id=HJeTo2VFwH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJlRs34Fvr",
            "paper_title": "Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets",
            "forum_link": "https://openreview.net/forum?id=BJlRs34Fvr",
            "pdf_link": "https://openreview.net/pdf?id=BJlRs34Fvr",
            "authors": [
                  "Dongxian Wu",
                  "Yisen Wang",
                  "Shu-Tao Xia",
                  "James Bailey",
                  "Xingjun Ma"
            ],
            "tl;dr": "We identify the security weakness of skip connections in ResNet-like neural networks",
            "abstract": "Skip connections are an essential component of current state-of-the-art deep neural networks (DNNs) such as ResNet, WideResNet, DenseNet, and ResNeXt. Despite their huge success in building deeper and more powerful DNNs, we identify a surprising \\emph{security weakness} of skip connections in this paper. Use of skip connections \\textit{allows easier generation of highly transferable adversarial examples}. Specifically, in ResNet-like (with skip connections) neural networks, gradients can backpropagate through either skip connections or residual modules. We find that using more gradients from the skip connections rather than the residual modules according to a decay factor, allows one to craft adversarial examples with high transferability. Our method is termed \\emph{Skip Gradient Method} (SGM). We conduct comprehensive transfer attacks against state-of-the-art DNNs including ResNets, DenseNets, Inceptions, Inception-ResNet, Squeeze-and-Excitation Network (SENet) and robustly trained DNNs. We show that employing SGM on the gradient flow can greatly improve the transferability of crafted attacks in almost all cases. Furthermore, SGM can be easily combined with existing black-box attack techniques, and obtain high improvements over state-of-the-art transferability methods. Our findings not only motivate new research into the architectural vulnerability of DNNs, but also open up further challenges for the design of secure DNN architectures.",
            "keywords": "Adversarial Example, Transferability, Skip Connection, Neural Network",
            "original-pdf": "<a href=\"/attachment?id=BJlRs34Fvr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "H1ebhnEYDH",
            "paper_title": "White Noise Analysis of Neural Networks",
            "forum_link": "https://openreview.net/forum?id=H1ebhnEYDH",
            "pdf_link": "https://openreview.net/pdf?id=H1ebhnEYDH",
            "authors": [
                  "Ali Borji",
                  "Sikun Lin"
            ],
            "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\n        their biases at the whole network level or the single neuron level. Our analysis is\n        based on two popular and related methods in psychophysics and neurophysiology\n        namely classification images and spike triggered analysis. These methods have\n        been widely used to understand the underlying mechanisms of sensory systems\n        in humans and monkeys. We leverage them to investigate the inherent biases of\n        deep neural networks and to obtain a first-order approximation of their functionality.\n        We emphasize on CNNs since they are currently the state of the art methods\n        in computer vision and are a decent model of human visual processing. In\n        addition, we study multi-layer perceptrons, logistic regression, and recurrent neural\n        networks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\n        CIFAR-10, and ImageNet, show that the computed bias maps resemble the target\n        classes and when used for classification lead to an over two-fold performance than\n        the chance level. Further, we show that classification images can be used to attack\n        a black-box classifier and to detect adversarial patch attacks. Finally, we utilize\n        spike triggered averaging to derive the filters of CNNs and explore how the behavior\n        of a network changes when neurons in different layers are modulated. Our\n        effort illustrates a successful example of borrowing from neurosciences to study\n        ANNs and highlights the importance of cross-fertilization and synergy across machine\n        learning, deep learning, and computational neuroscience.",
            "keywords": "Classification images, spike triggered analysis, deep learning, network visualization, adversarial attack, adversarial defense, microstimulation, computational neuroscience",
            "code": "<a href=\"https://github.com/aliborji/WhiteNoiseAnalysis.git\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/aliborji/WhiteNoiseAnalysis.git</a>",
            "original-pdf": "<a href=\"/attachment?id=H1ebhnEYDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Byl8hhNYPS",
            "paper_title": "Neural Machine Translation with Universal Visual Representation",
            "forum_link": "https://openreview.net/forum?id=Byl8hhNYPS",
            "pdf_link": "https://openreview.net/pdf?id=Byl8hhNYPS",
            "authors": [
                  "Zhuosheng Zhang",
                  "Kehai Chen",
                  "Rui Wang",
                  "Masao Utiyama",
                  "Eiichiro Sumita",
                  "Zuchao Li",
                  "Hai Zhao"
            ],
            "tl;dr": "This work proposed a universal visual representation for neural machine translation (NMT) using retrieved images with similar topics to source sentence,  extending image applicability in NMT.",
            "abstract": "Though visual information has been introduced for enhancing neural machine translation (NMT), its effectiveness strongly relies on the availability of large amounts of bilingual parallel sentence pairs with manual image annotations. In this paper, we present a universal visual representation learned over the monolingual corpora with image annotations, which overcomes the lack of large-scale bilingual sentence-image pairs, thereby extending image applicability in NMT. In detail, a group of images with similar topics to the source sentence will be retrieved from a light topic-image lookup table learned over the existing sentence-image pairs, and then is encoded as image representations by a pre-trained ResNet. An attention layer with a gated weighting is to fuse the visual information and text information as input to the decoder for predicting target translations. In particular, the proposed method enables the visual information to be integrated into large-scale text-only NMT in addition to the multimodel NMT. Experiments on four widely used translation datasets, including the WMT'16 English-to-Romanian, WMT'14 English-to-German, WMT'14 English-to-French, and Multi30K, show that the proposed approach achieves significant improvements over strong baselines.",
            "keywords": "Neural Machine Translation, Visual Representation, Multimodal Machine Translation, Language Representation",
            "code": "<a href=\"https://github.com/cooelf/UVR-NMT\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/cooelf/UVR-NMT</a>",
            "original-pdf": "<a href=\"/attachment?id=Byl8hhNYPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJeKh3VYDH",
            "paper_title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds",
            "forum_link": "https://openreview.net/forum?id=BJeKh3VYDH",
            "pdf_link": "https://openreview.net/pdf?id=BJeKh3VYDH",
            "authors": [
                  "Lukas Prantl",
                  "Nuttapong Chentanez",
                  "Stefan Jeschke",
                  "Nils Thuerey"
            ],
            "keywords": "point clouds, spatio-temporal representations, Lagrangian data, temporal coherence, super-resolution, denoising",
            "tl;dr": "We propose a generative neural network approach for temporally coherent point clouds.",
            "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.",
            "original-pdf": "<a href=\"/attachment?id=BJeKh3VYDH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJlS634tPr",
            "paper_title": "PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search",
            "forum_link": "https://openreview.net/forum?id=BJlS634tPr",
            "pdf_link": "https://openreview.net/pdf?id=BJlS634tPr",
            "authors": [
                  "Yuhui Xu",
                  "Lingxi Xie",
                  "Xiaopeng Zhang",
                  "Xin Chen",
                  "Guo-Jun Qi",
                  "Qi Tian",
                  "Hongkai Xiong"
            ],
            "tl;dr": "Allowing partial channel connection in super-networks to regularize and accelerate differentiable architecture search",
            "abstract": "Differentiable architecture search (DARTS) provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads in jointly training a super-net and searching for an optimal architecture. In this paper, we present a novel approach, namely  Partially-Connected DARTS, by sampling a small part of super-net to reduce the redundancy in exploring the network space, thereby performing a more efficient search without comprising the performance. In particular, we perform operation search in a subset of channels while bypassing the held out part in a shortcut. This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels. We solve it by introducing  edge normalization, which adds a new set of edge-level hyper-parameters to reduce uncertainty in search. Thanks to the reduced memory cost, PC-DARTS can be trained with a larger batch size and, consequently, enjoy both faster speed and higher training stability. Experiment results demonstrate the effectiveness of the proposed method. Specifically, we achieve an error rate of 2.57% on CIFAR10 within merely 0.1 GPU-days for architecture search, and a state-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile setting) within 3.8 GPU-days for search. Our code has been made available at https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0.",
            "code": "<a href=\"https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0\" target=\"_blank\" rel=\"nofollow noreferrer\">https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0</a>",
            "keywords": "Neural Architecture Search, DARTS, Regularization, Normalization",
            "original-pdf": "<a href=\"/attachment?id=BJlS634tPr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rkxZyaNtwB",
            "paper_title": "Online and stochastic optimization beyond Lipschitz continuity: A Riemannian approach",
            "forum_link": "https://openreview.net/forum?id=rkxZyaNtwB",
            "pdf_link": "https://openreview.net/pdf?id=rkxZyaNtwB",
            "authors": [
                  "Kimon Antonakopoulos",
                  "E. Veronica Belmega",
                  "Panayotis Mertikopoulos"
            ],
            "keywords": "Online optimization, stochastic optimization, Poisson inverse problems",
            "tl;dr": "We introduce a novel version of Lipschitz objective continuity that allows stochastic mirror descent methodologies to achieve optimal convergence rates in problems with singularities.",
            "abstract": "Motivated by applications to machine learning and imaging science, we study a class of online and stochastic optimization problems with loss functions that are not Lipschitz continuous; in particular, the loss functions encountered by the optimizer could exhibit gradient singularities or be singular themselves. Drawing on tools and techniques from Riemannian geometry, we examine a Riemann\u2013Lipschitz (RL) continuity condition which is tailored to the singularity landscape of the problem\u2019s loss functions. In this way, we are able to tackle cases beyond the Lipschitz framework provided by a global norm, and we derive optimal regret bounds and last iterate convergence results through the use of regularized learning methods (such as online mirror descent). These results are subsequently validated in a class of stochastic Poisson inverse problems that arise in imaging science.",
            "original-pdf": "<a href=\"/attachment?id=rkxZyaNtwB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Skgvy64tvr",
            "paper_title": "Enhancing Adversarial Defense by k-Winners-Take-All",
            "forum_link": "https://openreview.net/forum?id=Skgvy64tvr",
            "pdf_link": "https://openreview.net/pdf?id=Skgvy64tvr",
            "authors": [
                  "Chang Xiao",
                  "Peilin Zhong",
                  "Changxi Zheng"
            ],
            "keywords": "adversarial defense, activation function, winner takes all",
            "tl;dr": "We propose a simple change to existing neural network structures for better defending against gradient-based adversarial attacks, using the k-winners-take-all activation function.",
            "abstract": "We propose a simple change to existing neural network structures for better defending against gradient-based adversarial attacks. Instead of using popular activation functions (such as ReLU), we advocate the use of k-Winners-Take-All (k-WTA) activation, a C0 discontinuous function that purposely invalidates the neural network model\u2019s gradient at densely distributed input data points. The proposed k-WTA activation can be readily used in nearly all existing networks and training methods with no significant overhead. Our proposal is theoretically rationalized. We analyze why the discontinuities in k-WTA networks can largely prevent gradient-based search of adversarial examples and why they at the same time remain innocuous to the network training. This understanding is also empirically backed. We test k-WTA activation on various network structures optimized by a training method, be it adversarial training or not. In all cases, the robustness of k-WTA networks outperforms that of traditional networks under white-box attacks.",
            "code": "<a href=\"https://github.com/a554b554/kWTA-Activation\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/a554b554/kWTA-Activation</a>",
            "original-pdf": "<a href=\"/attachment?id=Skgvy64tvr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Hke-WTVtwr",
            "paper_title": "Encoding word order in complex embeddings",
            "forum_link": "https://openreview.net/forum?id=Hke-WTVtwr",
            "pdf_link": "https://openreview.net/pdf?id=Hke-WTVtwr",
            "authors": [
                  "Benyou Wang",
                  "Donghao Zhao",
                  "Christina Lioma",
                  "Qiuchi Li",
                  "Peng Zhang",
                  "Jakob Grue Simonsen"
            ],
            "abstract": "Sequential word order is important when processing text. Currently, neural networks (NNs) address this by modeling word position using position embeddings. The problem is that position embeddings capture the position of individual words, but not the ordered relationship (e.g., adjacency or precedence) between individual word positions. We present a novel and principled solution for modeling both the global absolute positions of words and their order relationships. Our solution generalizes word embeddings, previously defined as independent vectors, to continuous word functions over a variable (position). The benefit of continuous functions over variable positions is that word representations shift smoothly with increasing positions. Hence, word representations in different positions can correlate with each other in a continuous function. The general solution of these functions can be extended to complex-valued variants. We extend CNN, RNN and Transformer NNs to complex-valued versions to incorporate our complex embedding (we make all code available). Experiments on text classification, machine translation and language modeling show gains over both classical word embeddings and position-enriched word embeddings. To our knowledge, this is the first work in NLP to link imaginary numbers in complex-valued representations to concrete meanings (i.e., word order).",
            "code": "<a href=\"https://github.com/iclr-complex-order/complex-order\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/iclr-complex-order/complex-order</a>",
            "keywords": "word embedding, complex-valued neural network, position embedding",
            "original-pdf": "<a href=\"/attachment?id=Hke-WTVtwr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "B1x1ma4tDr",
            "paper_title": "DDSP: Differentiable Digital Signal Processing",
            "forum_link": "https://openreview.net/forum?id=B1x1ma4tDr",
            "pdf_link": "https://openreview.net/pdf?id=B1x1ma4tDr",
            "authors": [
                  "Jesse Engel",
                  "Lamtharn (Hanoi) Hantrakul",
                  "Chenjie Gu",
                  "Adam Roberts"
            ],
            "tl;dr": "Better audio synthesis by combining interpretable DSP with end-to-end learning.",
            "abstract": "Most generative models of audio directly generate samples in one of two domains: time or frequency. While sufficient to express any signal, these representations are inefficient, as they do not utilize existing knowledge of how sound is generated and perceived. A third approach (vocoders/synthesizers) successfully incorporates strong domain knowledge of signal processing and perception, but has been less actively researched due to limited expressivity and difficulty integrating with modern auto-differentiation-based machine learning methods. In this paper, we introduce the Differentiable Digital Signal Processing (DDSP) library, which enables direct integration of classic signal processing elements with deep learning methods. Focusing on audio synthesis, we achieve high-fidelity generation without the need for large autoregressive models or adversarial losses, demonstrating that DDSP enables utilizing strong inductive biases without losing the expressive power of neural networks. Further, we show that combining interpretable modules permits manipulation of each separate model component, with applications such as independent control of pitch and loudness, realistic extrapolation to pitches not seen during training, blind dereverberation of room acoustics, transfer of extracted room acoustics to new environments, and transformation of timbre between disparate sources. In short, DDSP enables an interpretable and modular approach to generative modeling, without sacrificing the benefits of deep learning. The library will is available at https://github.com/magenta/ddsp and we encourage further contributions from the community and domain experts.",
            "keywords": "dsp, audio, music, nsynth, wavenet, wavernn, vocoder, synthesizer, sound, signal, processing, tensorflow, autoencoder, disentanglement",
            "code": "<a href=\"https://github.com/magenta/ddsp\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/magenta/ddsp</a>",
            "original-pdf": "<a href=\"/attachment?id=B1x1ma4tDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJl5Np4tPr",
            "paper_title": "Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation",
            "forum_link": "https://openreview.net/forum?id=SJl5Np4tPr",
            "pdf_link": "https://openreview.net/pdf?id=SJl5Np4tPr",
            "authors": [
                  "Hung-Yu Tseng",
                  "Hsin-Ying Lee",
                  "Jia-Bin Huang",
                  "Ming-Hsuan Yang"
            ],
            "abstract": "Few-shot classification aims to recognize novel categories with only few labeled images in each class. Existing metric-based few-shot classification algorithms predict categories by comparing the feature embeddings of query images with those from a few labeled images (support examples) using a learned metric function. While promising performance has been demonstrated, these methods often fail to generalize to unseen domains due to large discrepancy of the feature distribution across domains. In this work, we address the problem of few-shot classification under domain shifts for metric-based methods. Our core idea is to use feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. To capture variations of the feature distributions under different domains, we further apply a learning-to-learn approach to search for the hyper-parameters of the feature-wise transformation layers. We conduct extensive experiments and ablation studies under the domain generalization setting using five few-shot classification datasets: mini-ImageNet, CUB, Cars, Places, and Plantae. Experimental results demonstrate that the proposed feature-wise transformation layer is applicable to various metric-based models, and provides consistent improvements on the few-shot classification performance under domain shift.",
            "original-pdf": "<a href=\"/attachment?id=SJl5Np4tPr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HklRwaEKwB",
            "paper_title": "Ridge Regression: Structure, Cross-Validation, and Sketching",
            "forum_link": "https://openreview.net/forum?id=HklRwaEKwB",
            "pdf_link": "https://openreview.net/pdf?id=HklRwaEKwB",
            "authors": [
                  "Sifan Liu",
                  "Edgar Dobriban"
            ],
            "keywords": "ridge regression, sketching, random matrix theory, cross-validation, high-dimensional asymptotics",
            "tl;dr": "We study the structure of ridge regression in a high-dimensional asymptotic framework, and get insights about cross-validation and sketching.",
            "abstract": "We study the following three fundamental problems about ridge regression: (1) what is the structure of the estimator? (2) how to correctly use cross-validation to choose the regularization parameter? and (3) how to accelerate computation without losing too much accuracy? We consider the three problems in a unified large-data linear model. We give a precise representation of ridge regression as a covariance matrix-dependent linear combination of the true parameter and the noise. \n        We study the bias of <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"0\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43E TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></mjx-assistive-mml></mjx-container>-fold cross-validation for choosing the regularization parameter, and propose a simple bias-correction. We analyze the accuracy of primal and dual sketching for ridge regression, showing they are surprisingly accurate. Our results are illustrated by simulations and by analyzing empirical data.",
            "code": "<a href=\"https://github.com/liusf15/RidgeRegression\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/liusf15/RidgeRegression</a>",
            "original-pdf": "<a href=\"/attachment?id=HklRwaEKwB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJgndT4KwB",
            "paper_title": "Finite Depth and Width Corrections to the Neural Tangent Kernel",
            "forum_link": "https://openreview.net/forum?id=SJgndT4KwB",
            "pdf_link": "https://openreview.net/pdf?id=SJgndT4KwB",
            "authors": [
                  "Boris Hanin",
                  "Mihai Nica"
            ],
            "keywords": "Neural Tangent Kernel, Finite Width Corrections, Random ReLU Net, Wide Networks, Deep Networks",
            "tl;dr": "The neural tangent kernel in a randomly initialized ReLU net is non-trivial fluctuations as long as the depth and width are comparable.",
            "abstract": "We prove the precise scaling, at finite depth and width, for the mean and variance of the neural tangent kernel (NTK) in a randomly initialized ReLU network. The standard deviation is exponential in the ratio of network depth to width. Thus, even in the limit of infinite overparameterization, the NTK is not deterministic if depth and width simultaneously tend to infinity. Moreover, we prove that for such deep and wide networks, the NTK has a non-trivial evolution during training by showing that the mean of its first SGD update is also exponential in the ratio of network depth to width. This is sharp contrast to the regime where depth is fixed and network width is very large. Our results suggest that, unlike relatively shallow and wide networks, deep and wide ReLU networks are capable of learning data-dependent features even in the so-called lazy training regime.",
            "original-pdf": "<a href=\"/attachment?id=SJgndT4KwB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BklEFpEYwS",
            "paper_title": "Meta-Learning without Memorization",
            "forum_link": "https://openreview.net/forum?id=BklEFpEYwS",
            "pdf_link": "https://openreview.net/pdf?id=BklEFpEYwS",
            "authors": [
                  "Mingzhang Yin",
                  "George Tucker",
                  "Mingyuan Zhou",
                  "Sergey Levine",
                  "Chelsea Finn"
            ],
            "keywords": "meta-learning, memorization, regularization, overfitting, mutually-exclusive",
            "tl;dr": "We identify and formalize the memorization problem in meta-learning and solve this problem with novel meta-regularization method, which greatly expand the domain that meta-learning can be  applicable to and effective on.",
            "abstract": "The ability to learn new concepts with small amounts of data is a critical aspect of intelligence that has proven challenging for deep learning methods. Meta-learning has emerged as a promising technique for leveraging data from previous tasks to enable efficient learning of new tasks. However, most meta-learning algorithms implicitly require that the meta-training tasks be mutually-exclusive, such that no single model can solve all of the tasks at once. For example, when creating tasks for few-shot image classification, prior work uses a per-task random assignment of image classes to N-way classification labels. If this is not done, the meta-learner can ignore the task training data and learn a single model that performs all of the meta-training tasks zero-shot, but does not adapt effectively to new image classes.  This requirement means that the user must take great care in designing the tasks, for example by shuffling labels or removing task identifying information from the inputs. In some domains, this makes meta-learning entirely inapplicable. In this paper, we address this challenge by designing a meta-regularization objective using information theory that places precedence on data-driven adaptation. This causes the meta-learner to decide what must be learned from the task training data and what should be inferred from the task testing input. By doing so, our algorithm can successfully use data from non-mutually-exclusive tasks to efficiently adapt to novel tasks. We demonstrate its applicability to both contextual and gradient-based meta-learning algorithms, and apply it in practical settings where applying standard meta-learning has been difficult. Our approach substantially outperforms standard meta-learning algorithms in these settings.&nbsp;",
            "code": "<a href=\"https://github.com/google-research/google-research/tree/master/meta_learning_without_memorization\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/google-research/google-research/tree/master/meta_learning_without_memorization</a>",
            "poster": "<a href=\"/attachment?id=BklEFpEYwS&amp;name=poster\" class=\"attachment-download-link\" title=\"Download Poster\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>",
            "full-presentation-video": "<a href=\"https://slideslive.com/38922670/invited-talk-the-big-problem-with-metalearning-and-how-bayesians-can-fix-it\" target=\"_blank\" rel=\"nofollow noreferrer\">https://slideslive.com/38922670/invited-talk-the-big-problem-with-metalearning-and-how-bayesians-can-fix-it</a>",
            "slides": "<a href=\"https://mingzhang-yin.github.io/assets/pdfs/iclr2020_slides.pdf\" target=\"_blank\" rel=\"nofollow noreferrer\">https://mingzhang-yin.github.io/assets/pdfs/iclr2020_slides.pdf</a>",
            "spotlight-video": "<a href=\"https://www.youtube.com/watch?v=emUvd3WqHMs&amp;feature=youtu.be\" target=\"_blank\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=emUvd3WqHMs&amp;feature=youtu.be</a>",
            "original-pdf": "<a href=\"/attachment?id=BklEFpEYwS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJgy96EYvr",
            "paper_title": "Influence-Based Multi-Agent Exploration",
            "forum_link": "https://openreview.net/forum?id=BJgy96EYvr",
            "pdf_link": "https://openreview.net/pdf?id=BJgy96EYvr",
            "authors": [
                  "Tonghan Wang*",
                  "Jianhao Wang*",
                  "Yi Wu",
                  "Chongjie Zhang"
            ],
            "keywords": "Multi-agent reinforcement learning, Exploration",
            "abstract": "Intrinsically motivated reinforcement learning aims to address the exploration challenge for sparse-reward tasks. However, the study of exploration methods in transition-dependent multi-agent settings is largely absent from the literature. We aim to take a step towards solving this problem. We present two exploration methods: exploration via information-theoretic influence (EITI) and exploration via decision-theoretic influence (EDTI), by exploiting the role of interaction in coordinated behaviors of agents. EITI uses mutual information to capture the interdependence between the transition dynamics of agents. EDTI uses a novel intrinsic reward, called Value of Interaction (VoI), to characterize and quantify the influence of one agent's behavior on expected returns of other agents. By optimizing EITI or EDTI objective as a regularizer, agents are encouraged to coordinate their exploration and learn policies to optimize the team performance. We show how to optimize these regularizers so that they can be easily integrated with policy gradient reinforcement learning. The resulting update rule draws a connection between coordinated exploration and intrinsic reward distribution. Finally, we empirically demonstrate the significant strength of our methods in a variety of multi-agent scenarios.",
            "code": "<a href=\"https://github.com/TonghanWang/EITI-EDTI\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/TonghanWang/EITI-EDTI</a>",
            "original-pdf": "<a href=\"/attachment?id=BJgy96EYvr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SJeqs6EFvB",
            "paper_title": "HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS",
            "forum_link": "https://openreview.net/forum?id=SJeqs6EFvB",
            "pdf_link": "https://openreview.net/pdf?id=SJeqs6EFvB",
            "authors": [
                  "Elizabeth Dinella",
                  "Hanjun Dai",
                  "Ziyang Li",
                  "Mayur Naik",
                  "Le Song",
                  "Ke Wang"
            ],
            "tl;dr": "An learning-based approach for detecting and fixing bugs in Javascript",
            "abstract": "We present a learning-based approach to detect and fix a broad range of bugs in Javascript programs. We frame the problem in terms of learning a sequence of graph transformations: given a buggy program modeled by a graph structure, our model makes a sequence of predictions including the position of bug nodes and corresponding graph edits to produce a fix. Unlike previous works that use deep neural networks, our approach targets bugs that are more complex and semantic in nature (i.e.~bugs that require adding or deleting statements to fix). We have realized our approach in a tool called HOPPITY. By training on 290,715 Javascript code change commits on Github, HOPPITY correctly detects and fixes bugs in 9,490 out of 36,361 programs in an end-to-end fashion. Given the bug location and type of the fix, HOPPITY also outperforms the baseline approach by a wide margin.",
            "keywords": "Bug Detection, Program Repair, Graph Neural Network, Graph Transformation",
            "code": "<a href=\"https://github.com/AI-nstein/hoppity\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/AI-nstein/hoppity</a>",
            "original-pdf": "<a href=\"/attachment?id=SJeqs6EFvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJge3TNKwH",
            "paper_title": "Sliced Cramer Synaptic Consolidation for Preserving Deeply Learned Representations",
            "forum_link": "https://openreview.net/forum?id=BJge3TNKwH",
            "pdf_link": "https://openreview.net/pdf?id=BJge3TNKwH",
            "authors": [
                  "Soheil Kolouri",
                  "Nicholas A. Ketz",
                  "Andrea Soltoggio",
                  "Praveen K. Pilly"
            ],
            "keywords": "selective plasticity, catastrophic forgetting, intransigence",
            "tl;dr": "\"A novel framework for overcoming catastrophic forgetting by preserving the distribution of the network's output at an arbitrary layer.\"",
            "abstract": "Deep neural networks suffer from the inability to preserve the learned data representation (i.e., catastrophic forgetting) in domains where the input data distribution is non-stationary, and it changes during training.  Various selective synaptic plasticity approaches have been recently proposed to preserve network parameters, which are crucial for previously learned tasks while learning new tasks. We explore such selective synaptic plasticity approaches through a unifying lens of memory replay and show the close relationship between methods like Elastic Weight Consolidation (EWC) and Memory-Aware-Synapses (MAS).  We then propose a fundamentally different class of preservation methods that aim at preserving the distribution of internal neural representations for previous tasks while learning a new one. We propose the sliced Cram\\'{e}r distance as a suitable choice for such preservation and evaluate our Sliced Cramer Preservation (SCP) algorithm through extensive empirical investigations on various network architectures in both supervised and unsupervised learning settings. We show that SCP consistently utilizes the learning capacity of the network better than online-EWC and MAS methods on various incremental learning tasks.",
            "original-pdf": "<a href=\"/attachment?id=BJge3TNKwH&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rJeB36NKvB",
            "paper_title": "How much Position Information Do Convolutional Neural Networks Encode?",
            "forum_link": "https://openreview.net/forum?id=rJeB36NKvB",
            "pdf_link": "https://openreview.net/pdf?id=rJeB36NKvB",
            "authors": [
                  "Md Amirul Islam*",
                  "Sen Jia*",
                  "Neil D. B. Bruce"
            ],
            "keywords": "network understanding, absolute position information",
            "tl;dr": "Our work shows positional information has been implicitly encoded in a network. This information is important for detecting position-dependent features, e.g. semantic and saliency.",
            "abstract": "In contrast to fully connected networks, Convolutional Neural Networks (CNNs) achieve efficiency by learning weights associated with local filters with a finite spatial extent. An implication of this is that a filter may know what it is looking at, but not where it is positioned in the image. Information concerning absolute position is inherently useful, and it is reasonable to assume that deep CNNs may implicitly learn to encode this information if there is a means to do so. In this paper, we test this hypothesis revealing the surprising degree of absolute position information that is encoded in commonly used neural networks. A comprehensive set of experiments show the validity of this hypothesis and shed light on how and where this information is represented while offering clues to where positional information is derived from in deep CNNs.",
            "original-pdf": "<a href=\"/attachment?id=rJeB36NKvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HJenn6VFvB",
            "paper_title": "Hamiltonian Generative Networks",
            "forum_link": "https://openreview.net/forum?id=HJenn6VFvB",
            "pdf_link": "https://openreview.net/pdf?id=HJenn6VFvB",
            "authors": [
                  "Peter Toth",
                  "Danilo J. Rezende",
                  "Andrew Jaegle",
                  "S\u00e9bastien Racani\u00e8re",
                  "Aleksandar Botev",
                  "Irina Higgins"
            ],
            "tl;dr": "We introduce a class of generative models that reliably learn Hamiltonian dynamics from high-dimensional observations. The learnt Hamiltonian can be applied to sequence modeling or as a normalising flow.",
            "abstract": "The Hamiltonian formalism plays a central role in classical and quantum physics. Hamiltonians are the main tool for modelling the continuous time evolution of systems with conserved quantities, and they come equipped with many useful properties, like time reversibility and smooth interpolation in time. These properties are important for many machine learning problems - from sequence prediction to reinforcement learning and density modelling - but are not typically provided out of the box by standard tools such as recurrent neural networks. In this paper, we introduce the Hamiltonian Generative Network (HGN), the first approach capable of consistently learning Hamiltonian dynamics from high-dimensional observations (such as images) without restrictive domain assumptions. Once trained, we can use HGN to sample new trajectories, perform rollouts both forward and backward in time, and even speed up or slow down the learned dynamics. We demonstrate how a simple modification of the network architecture turns HGN into a powerful normalising flow model, called Neural Hamiltonian Flow (NHF), that uses Hamiltonian dynamics to model expressive densities. Hence, we hope that our work serves as a first practical demonstration of the value that the Hamiltonian formalism can bring to machine learning. More results and video evaluations are available at: http://tiny.cc/hgn",
            "keywords": "Hamiltonian dynamics, normalising flows, generative model, physics",
            "original-pdf": "<a href=\"/attachment?id=HJenn6VFvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SkeyppEFvS",
            "paper_title": "CoPhy: Counterfactual Learning of Physical Dynamics",
            "forum_link": "https://openreview.net/forum?id=SkeyppEFvS",
            "pdf_link": "https://openreview.net/pdf?id=SkeyppEFvS",
            "authors": [
                  "Fabien Baradel",
                  "Natalia Neverova",
                  "Julien Mille",
                  "Greg Mori",
                  "Christian Wolf"
            ],
            "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.",
            "keywords": "intuitive physics, visual reasoning",
            "code": "<a href=\"https://github.com/fabienbaradel/cophy\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/fabienbaradel/cophy</a>",
            "original-pdf": "<a href=\"/attachment?id=SkeyppEFvS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BJg866NFvB",
            "paper_title": "Estimating counterfactual treatment outcomes over time through adversarially balanced representations",
            "forum_link": "https://openreview.net/forum?id=BJg866NFvB",
            "pdf_link": "https://openreview.net/pdf?id=BJg866NFvB",
            "authors": [
                  "Ioana Bica",
                  "Ahmed M Alaa",
                  "James Jordon",
                  "Mihaela van der Schaar"
            ],
            "keywords": "treatment effects over time, causal inference, counterfactual estimation",
            "abstract": "Identifying when to give treatments to patients and how to select among multiple treatments over time are important medical problems with a few existing solutions. In this paper, we introduce the Counterfactual Recurrent Network (CRN), a novel sequence-to-sequence model that leverages the increasingly available patient observational data to estimate treatment effects over time and answer such medical questions. To handle the bias from time-varying confounders, covariates affecting the treatment assignment policy in the observational data, CRN uses domain adversarial training to build balancing representations of the patient history. At each timestep, CRN constructs a treatment invariant representation which removes the association between patient history and treatment assignments and thus can be reliably used for making counterfactual predictions. On a simulated model of tumour growth, with varying degree of time-dependent confounding, we show how our model achieves lower error in estimating counterfactuals and in choosing the correct treatment and timing of treatment than current state-of-the-art methods.",
            "original-pdf": "<a href=\"/attachment?id=BJg866NFvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Skep6TVYDB",
            "paper_title": "Gradientless Descent: High-Dimensional Zeroth-Order Optimization",
            "forum_link": "https://openreview.net/forum?id=Skep6TVYDB",
            "pdf_link": "https://openreview.net/pdf?id=Skep6TVYDB",
            "authors": [
                  "Daniel Golovin",
                  "John Karro",
                  "Greg Kochanski",
                  "Chansoo Lee",
                  "Xingyou Song",
                  "Qiuyi Zhang"
            ],
            "keywords": "Zeroth Order Optimization",
            "tl;dr": "Gradientless Descent is a provably efficient gradient-free algorithm that is monotone-invariant and fast for high-dimensional zero-th order optimization.",
            "abstract": "Zeroth-order optimization is the process of minimizing an objective <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"1\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D453 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D465 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></math></mjx-assistive-mml></mjx-container>, given oracle access to evaluations at adaptively chosen inputs <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"2\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D465 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>x</mi></math></mjx-assistive-mml></mjx-container>. In this paper, we present two simple yet powerful GradientLess Descent (GLD) algorithms that do not rely on an underlying gradient estimate and are numerically stable. We analyze our algorithm from a novel geometric perspective and we show that for {\\it any monotone transform} of a smooth and strongly convex objective with latent dimension <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"3\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D458 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\" space=\"4\"><mjx-c class=\"mjx-c2265\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\" space=\"4\"><mjx-c class=\"mjx-c1D45B TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi><mo>\u2265</mo><mi>n</mi></math></mjx-assistive-mml></mjx-container>, we present a novel analysis that shows convergence within an <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"4\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D716 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>\u03f5</mi></math></mjx-assistive-mml></mjx-container>-ball of the optimum in <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"5\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D442 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D458 TEX-I\"></mjx-c></mjx-mi><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D444 TEX-I\"></mjx-c></mjx-mi><mjx-mi class=\"mjx-n\" space=\"2\"><mjx-c class=\"mjx-c6C\"></mjx-c><mjx-c class=\"mjx-c6F\"></mjx-c><mjx-c class=\"mjx-c67\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2061\"></mjx-c></mjx-mo><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D45B TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-n\" space=\"2\"><mjx-c class=\"mjx-c6C\"></mjx-c><mjx-c class=\"mjx-c6F\"></mjx-c><mjx-c class=\"mjx-c67\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2061\"></mjx-c></mjx-mo><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c28\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D445 TEX-I\"></mjx-c></mjx-mi><mjx-texatom texclass=\"ORD\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2F\"></mjx-c></mjx-mo></mjx-texatom><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D716 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c29\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>k</mi><mi>Q</mi><mi>log</mi><mo data-mjx-texclass=\"NONE\">\u2061</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mi>log</mi><mo data-mjx-texclass=\"NONE\">\u2061</mo><mo stretchy=\"false\">(</mo><mi>R</mi><mrow><mo>/</mo></mrow><mi>\u03f5</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></math></mjx-assistive-mml></mjx-container> evaluations, where the input dimension is <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"6\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D45B TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></mjx-assistive-mml></mjx-container>, <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"7\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D445 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>R</mi></math></mjx-assistive-mml></mjx-container> is the diameter of the input space and <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"8\" style=\"font-size: 113.1%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D444 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi></math></mjx-assistive-mml></mjx-container> is the condition number. Our rates are the first of its kind to be both 1) poly-logarithmically dependent on dimensionality and 2) invariant under monotone transformations. We further leverage our geometric perspective to show that our analysis is optimal. Both monotone invariance and its ability to utilize a low latent dimensionality are key to the empirical success of our algorithms, as demonstrated on synthetic and MuJoCo benchmarks.",
            "original-pdf": "<a href=\"/attachment?id=Skep6TVYDB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Hkekl0NFPr",
            "paper_title": "Conditional Learning of Fair Representations",
            "forum_link": "https://openreview.net/forum?id=Hkekl0NFPr",
            "pdf_link": "https://openreview.net/pdf?id=Hkekl0NFPr",
            "authors": [
                  "Han Zhao",
                  "Amanda Coston",
                  "Tameem Adel",
                  "Geoffrey J. Gordon"
            ],
            "keywords": "algorithmic fairness, representation learning",
            "tl;dr": "We propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups.",
            "abstract": "We propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups in the classification setting. Two key components underpinning the design of our algorithm are balanced error rate and conditional alignment of representations. We show how these two components contribute to ensuring accuracy parity and equalized false-positive and false-negative rates across groups without impacting demographic parity. Furthermore, we also demonstrate both in theory and on two real-world experiments that the proposed algorithm leads to a better utility-fairness trade-off on balanced datasets compared with existing algorithms on learning fair representations for classification.",
            "original-pdf": "<a href=\"/attachment?id=Hkekl0NFPr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "ByxxgCEYDS",
            "paper_title": "Inductive Matrix Completion Based on Graph Neural Networks",
            "forum_link": "https://openreview.net/forum?id=ByxxgCEYDS",
            "pdf_link": "https://openreview.net/pdf?id=ByxxgCEYDS",
            "authors": [
                  "Muhan Zhang",
                  "Yixin Chen"
            ],
            "keywords": "matrix completion, graph neural network",
            "abstract": "We propose an inductive matrix completion model without using side information. By factorizing the (rating) matrix into the product of low-dimensional latent embeddings of rows (users) and columns (items), a majority of existing matrix completion methods are transductive, since the learned embeddings cannot generalize to unseen rows/columns or to new matrices. To make matrix completion inductive, most previous works use content (side information), such as user's age or movie's genre, to make predictions. However, high-quality content is not always available, and can be hard to extract. Under the extreme setting where not any side information is available other than the matrix to complete, can we still learn an inductive matrix completion model? In this paper, we propose an Inductive Graph-based Matrix Completion (IGMC) model to address this problem. IGMC trains a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps these subgraphs to their corresponding ratings. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive -- it can generalize to users/items unseen during the training (given that their interactions exist), and can even transfer to new tasks. Our transfer learning experiments show that a model trained out of the MovieLens dataset can be directly used to predict Douban movie ratings with surprisingly good performance. Our work demonstrates that: 1) it is possible to train inductive matrix completion models without using side information while achieving similar or better performances than state-of-the-art transductive methods; 2) local graph patterns around a (user, item) pair are effective predictors of the rating this user gives to the item; and 3) Long-range dependencies might not be necessary for modeling recommender systems.",
            "code": "<a href=\"https://github.com/muhanzhang/IGMC\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/muhanzhang/IGMC</a>",
            "original-pdf": "<a href=\"/attachment?id=ByxxgCEYDS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Hkx7xRVYDr",
            "paper_title": "Duration-of-Stay Storage Assignment under Uncertainty",
            "forum_link": "https://openreview.net/forum?id=Hkx7xRVYDr",
            "pdf_link": "https://openreview.net/pdf?id=Hkx7xRVYDr",
            "authors": [
                  "Michael Lingzhi Li",
                  "Elliott Wolf",
                  "Daniel Wintz"
            ],
            "keywords": "Storage Assignment, Deep Learning, Duration-of-Stay, Application, Natural Language Processing, Parallel Network",
            "tl;dr": "We develop a new storage assignment framework with a novel neural network that enables large efficiency gains in the warehouse.",
            "abstract": "Storage assignment, the act of choosing what goods are placed in what locations in a warehouse, is a central problem of supply chain logistics. Past literature has shown that the optimal method to assign pallets is to arrange them in increasing duration of stay in the warehouse (the Duration-of-Stay, or DoS, method), but the methodology requires perfect prior knowledge of DoS for each pallet, which is unknown and uncertain under realistic conditions. Attempts to predict DoS have largely been unfruitful due to the multi-valuedness nature (every shipment contains multiple identical pallets with different DoS) and data sparsity induced by lack of matching historical conditions. In this paper, we introduce a new framework for storage assignment that provides a solution to the DoS prediction problem through a distributional reformulation and a novel neural network, ParallelNet. Through collaboration with a world-leading cold storage company, we show that the system is able to predict DoS with a MAPE of 29%, a decrease of ~30% compared to a CNN-LSTM model, and suffers less performance decay into the future. The framework is then integrated into a first-of-its-kind Storage Assignment system, which is being deployed in warehouses across United States, with initial results showing up to 21% in labor savings. We also release the first publicly available set of warehousing records to facilitate research into this central problem.",
            "code": "<a href=\"https://anonymous.4open.science/r/8de2111c-d496-423e-86f3-b5e31792bead/\" target=\"_blank\" rel=\"nofollow noreferrer\">https://anonymous.4open.science/r/8de2111c-d496-423e-86f3-b5e31792bead/</a>",
            "original-pdf": "<a href=\"/attachment?id=Hkx7xRVYDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HklSeREtPB",
            "paper_title": "Emergence of functional and structural properties of the head direction system by optimization of recurrent neural networks",
            "forum_link": "https://openreview.net/forum?id=HklSeREtPB",
            "pdf_link": "https://openreview.net/pdf?id=HklSeREtPB",
            "authors": [
                  "Christopher J. Cueva",
                  "Peter Y. Wang",
                  "Matthew Chin",
                  "Xue-Xin Wei"
            ],
            "tl;dr": "Artificial neural networks trained with gradient descent are capable of recapitulating both realistic neural activity and the anatomical organization of a biological circuit.",
            "abstract": "Recent work suggests goal-driven training of neural networks can be used to model neural activity in the brain. While response properties of neurons in artificial neural networks bear similarities to those in the brain, the network architectures are often constrained to be different. Here we ask if a neural network can recover both neural representations and, if the architecture is unconstrained and optimized, also the anatomical properties of neural circuits. We demonstrate this in a system where the connectivity and the functional organization have been characterized, namely, the head direction circuit of the rodent and fruit fly. We trained recurrent neural networks (RNNs) to estimate head direction through integration of angular velocity. We found that the two distinct classes of neurons observed in the head direction system, the Compass neurons and the Shifter neurons, emerged naturally in artificial neural networks as a result of training. Furthermore, connectivity analysis and in-silico neurophysiology revealed structural and mechanistic similarities between artificial networks and the head direction system. Overall, our results show that optimization of RNNs in a goal-driven task can recapitulate the structure and function of biological circuits, suggesting that artificial neural networks can be used to study the brain at the level of both neural activity and anatomical organization.",
            "keywords": "recurrent network, head direction system, neural circuits, neural coding",
            "original-pdf": "<a href=\"/attachment?id=HklSeREtPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "SyxrxR4KPS",
            "paper_title": "Deep neuroethology of a virtual rodent",
            "forum_link": "https://openreview.net/forum?id=SyxrxR4KPS",
            "pdf_link": "https://openreview.net/pdf?id=SyxrxR4KPS",
            "authors": [
                  "Josh Merel",
                  "Diego Aldarondo",
                  "Jesse Marshall",
                  "Yuval Tassa",
                  "Greg Wayne",
                  "Bence Olveczky"
            ],
            "keywords": "computational neuroscience, motor control, deep RL",
            "tl;dr": "We built a physical simulation of a rodent, trained it to solve a set of tasks, and analyzed the resulting networks.",
            "abstract": "Parallel developments in neuroscience and deep learning have led to mutually productive exchanges, pushing our understanding of real and artificial neural networks in sensory and cognitive systems. However, this interaction between fields is less developed in the study of motor control. In this work, we develop a virtual rodent as a platform for the grounded study of motor activity in artificial models of embodied control. We then use this platform to study motor activity across contexts by training a model to solve four complex tasks. Using methods familiar to neuroscientists, we describe the behavioral representations and algorithms employed by different layers of the network using a neuroethological approach to characterize motor activity relative to the rodent's behavior and goals. We find that the model uses two classes of representations which respectively encode the task-specific behavioral strategies and task-invariant behavioral kinematics. These representations are reflected in the sequential activity and population dynamics of neural subpopulations. Overall, the virtual rodent facilitates grounded collaborations between deep reinforcement learning and motor neuroscience.",
            "original-pdf": "<a href=\"/attachment?id=SyxrxR4KPS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1glGANtDr",
            "paper_title": "Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation",
            "forum_link": "https://openreview.net/forum?id=S1glGANtDr",
            "pdf_link": "https://openreview.net/pdf?id=S1glGANtDr",
            "authors": [
                  "Ziyang Tang*",
                  "Yihao Feng*",
                  "Lihong Li",
                  "Dengyong Zhou",
                  "Qiang Liu"
            ],
            "tl;dr": "We develop a new doubly robust estimator based on the infinite horizon density ratio and off policy value estimation.",
            "abstract": "Infinite horizon off-policy policy evaluation is a highly challenging task due to the excessively large variance of typical importance sampling (IS) estimators. Recently, Liu et al. (2018) proposed an approach that significantly reduces the variance of infinite-horizon off-policy evaluation by estimating the stationary density ratio, but at the cost of introducing potentially high risks due to the error in density ratio estimation. In this paper, we develop a bias-reduced augmentation of their method, which can take advantage of a learned value function to obtain higher accuracy. Our method is doubly robust in that the bias vanishes when either the density ratio or value function estimation is perfect.  In general, when either of them is accurate, the bias can also be reduced. Both theoretical and empirical results show that our method yields significant advantages over previous methods.",
            "keywords": "off-policy evaluation, infinite horizon, doubly robust, reinforcement learning",
            "original-pdf": "<a href=\"/attachment?id=S1glGANtDr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "H1ldzA4tPr",
            "paper_title": "Learning Compositional Koopman Operators for Model-Based Control",
            "forum_link": "https://openreview.net/forum?id=H1ldzA4tPr",
            "pdf_link": "https://openreview.net/pdf?id=H1ldzA4tPr",
            "authors": [
                  "Yunzhu Li",
                  "Hao He",
                  "Jiajun Wu",
                  "Dina Katabi",
                  "Antonio Torralba"
            ],
            "keywords": "Koopman operators, graph neural networks, compositionality",
            "tl;dr": "Learning compositional Koopman operators for efficient system identification and model-based control.",
            "abstract": "Finding an embedding space for a linear approximation of a nonlinear dynamical system enables efficient system identification and control synthesis. The Koopman operator theory lays the foundation for identifying the nonlinear-to-linear coordinate transformations with data-driven methods. Recently, researchers have proposed to use deep neural networks as a more expressive class of basis functions for calculating the Koopman operators. These approaches, however, assume a fixed dimensional state space; they are therefore not applicable to scenarios with a variable number of objects. In this paper, we propose to learn compositional Koopman operators, using graph neural networks to encode the state into object-centric embeddings and using a block-wise linear transition matrix to regularize the shared structure across objects. The learned dynamics can quickly adapt to new environments of unknown physical parameters and produce control signals to achieve a specified goal. Our experiments on manipulating ropes and controlling soft robots show that the proposed method has better efficiency and generalization ability than existing baselines.",
            "original-pdf": "<a href=\"/attachment?id=H1ldzA4tPr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HkxYzANYDB",
            "paper_title": "CLEVRER: Collision Events for Video Representation and Reasoning",
            "forum_link": "https://openreview.net/forum?id=HkxYzANYDB",
            "pdf_link": "https://openreview.net/pdf?id=HkxYzANYDB",
            "authors": [
                  "Kexin Yi*",
                  "Chuang Gan*",
                  "Yunzhu Li",
                  "Pushmeet Kohli",
                  "Jiajun Wu",
                  "Antonio Torralba",
                  "Joshua B. Tenenbaum"
            ],
            "tl;dr": "We present a diagnostic dataset for systematic study of temporal and casual reasoning in videos.",
            "abstract": "The ability to reason about temporal and causal events from videos lies at the core of human intelligence. Most video reasoning benchmarks, however, focus on pattern recognition from complex visual and language input, instead of on causal structure. We study the complementary problem, exploring the temporal and causal structures behind videos of objects with simple visual appearance. To this end, we introduce the CoLlision Events for Video REpresentation and Reasoning (CLEVRER) dataset, a  diagnostic video dataset for systematic evaluation of computational models on a wide range of reasoning tasks.  Motivated by the theory of human casual judgment, CLEVRER includes four types of question:  descriptive (e.g., \u2018what color\u2019), explanatory (\u2018what\u2019s responsible for\u2019), predictive (\u2018what will happen next\u2019), and counterfactual (\u2018what if\u2019).  We evaluate various state-of-the-art models for visual reasoning on our benchmark. While these models thrive on the perception-based task (descriptive), they perform poorly on the causal tasks (explanatory, predictive and counterfactual), suggesting that a principled approach for causal reasoning should incorporate the capability of both perceiving complex visual and language inputs, and understanding the underlying dynamics and causal relations. We also study an oracle model that explicitly combines these components via symbolic representations.",
            "keywords": "Neuro-symbolic, Reasoning",
            "code": "<a href=\"http://clevrer.csail.mit.edu/\" target=\"_blank\" rel=\"nofollow noreferrer\">http://clevrer.csail.mit.edu/</a>",
            "original-pdf": "<a href=\"/attachment?id=HkxYzANYDB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1lZ7AEKvB",
            "paper_title": "The Logical Expressiveness of Graph Neural Networks",
            "forum_link": "https://openreview.net/forum?id=r1lZ7AEKvB",
            "pdf_link": "https://openreview.net/pdf?id=r1lZ7AEKvB",
            "authors": [
                  "Pablo Barcel\u00f3",
                  "Egor V. Kostylev",
                  "Mikael Monet",
                  "Jorge P\u00e9rez",
                  "Juan Reutter",
                  "Juan Pablo Silva"
            ],
            "tl;dr": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.",
            "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.",
            "code": "<a href=\"https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/\" target=\"_blank\" rel=\"nofollow noreferrer\">https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/</a>",
            "keywords": "Graph Neural Networks, First Order Logic, Expressiveness",
            "original-pdf": "<a href=\"/attachment?id=r1lZ7AEKvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1g87C4KwB",
            "paper_title": "The Break-Even Point on Optimization Trajectories of Deep Neural Networks",
            "forum_link": "https://openreview.net/forum?id=r1g87C4KwB",
            "pdf_link": "https://openreview.net/pdf?id=r1g87C4KwB",
            "authors": [
                  "Stanislaw Jastrzebski",
                  "Maciej Szymczak",
                  "Stanislav Fort",
                  "Devansh Arpit",
                  "Jacek Tabor",
                  "Kyunghyun Cho*",
                  "Krzysztof Geras*"
            ],
            "tl;dr": "In the early phase of training of deep neural networks there exists a \"break-even point\" which determines properties of the entire optimization trajectory.",
            "abstract": "The early phase of training of deep neural networks is critical for their final performance. In this work, we study how the hyperparameters of stochastic gradient descent (SGD) used in the early phase of training affect the rest of the optimization trajectory. We argue for the existence of the \"``break-even\" point on this trajectory, beyond which the curvature of the loss surface and noise in the gradient are implicitly regularized by SGD. In particular, we demonstrate on multiple classification tasks that using a large learning rate in the initial phase of training reduces the variance of the gradient, and improves the conditioning of the covariance of gradients. These effects are beneficial from the optimization perspective and become visible after the break-even point. Complementing prior work, we also show that using a low learning rate results in bad conditioning of the loss surface even for a neural network with batch normalization layers. In short, our work shows that key properties of the loss surface are strongly influenced by SGD in the early phase of training. We argue that studying the impact of the identified effects on generalization is a promising future direction.",
            "keywords": "generalization, sgd, learning rate, batch size, hessian, curvature, trajectory, optimization",
            "original-pdf": "<a href=\"/attachment?id=r1g87C4KwB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "H1eA7AEtvS",
            "paper_title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
            "forum_link": "https://openreview.net/forum?id=H1eA7AEtvS",
            "pdf_link": "https://openreview.net/pdf?id=H1eA7AEtvS",
            "authors": [
                  "Zhenzhong Lan",
                  "Mingda Chen",
                  "Sebastian Goodman",
                  "Kevin Gimpel",
                  "Piyush Sharma",
                  "Radu Soricut"
            ],
            "keywords": "Natural Language Processing, BERT, Representation Learning",
            "tl;dr": "A new pretraining method that establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large.",
            "abstract": "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems,  we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT~\\citep{devlin2018bert}. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT.",
            "code": "<a href=\"https://github.com/google-research/ALBERT\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/google-research/ALBERT</a>",
            "original-pdf": "<a href=\"/attachment?id=H1eA7AEtvS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "HJxrVA4FDS",
            "paper_title": "Disentangling neural mechanisms for perceptual grouping",
            "forum_link": "https://openreview.net/forum?id=HJxrVA4FDS",
            "pdf_link": "https://openreview.net/pdf?id=HJxrVA4FDS",
            "authors": [
                  "Junkyung Kim*",
                  "Drew Linsley*",
                  "Kalpit Thakkar",
                  "Thomas Serre"
            ],
            "keywords": "Perceptual grouping, visual cortex, recurrent feedback, horizontal connections, top-down connections",
            "tl;dr": "Horizontal and top-down feedback connections are responsible for complementary perceptual grouping strategies in biological and recurrent vision systems.",
            "abstract": "Forming perceptual groups and individuating objects in visual scenes is an essential step towards visual intelligence. This ability is thought to arise in the brain from computations implemented by bottom-up, horizontal, and top-down connections between neurons. However, the relative contributions of these connections to perceptual grouping are poorly understood. We address this question by systematically evaluating neural network architectures featuring combinations bottom-up, horizontal, and top-down connections on two synthetic visual tasks, which stress low-level \"Gestalt\" vs. high-level object cues for perceptual grouping. We show that increasing the difficulty of either task strains learning for networks that rely solely on bottom-up connections. Horizontal connections resolve straining on tasks with Gestalt cues by supporting incremental grouping, whereas top-down connections rescue learning on tasks with high-level object cues by modifying coarse predictions about the position of the target object. Our findings dissociate the computational roles of bottom-up, horizontal and top-down connectivity, and demonstrate how a model featuring all of these interactions can more flexibly learn to form perceptual groups.",
            "code": "<a href=\"https://bit.ly/2wdQYGd\" target=\"_blank\" rel=\"nofollow noreferrer\">https://bit.ly/2wdQYGd</a>",
            "original-pdf": "<a href=\"/attachment?id=HJxrVA4FDS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "rJgJDAVKvB",
            "paper_title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees",
            "forum_link": "https://openreview.net/forum?id=rJgJDAVKvB",
            "pdf_link": "https://openreview.net/pdf?id=rJgJDAVKvB",
            "authors": [
                  "Binghong Chen",
                  "Bo Dai",
                  "Qinjie Lin",
                  "Guo Ye",
                  "Han Liu",
                  "Le Song"
            ],
            "keywords": "learning to plan, representation learning, learning to design algorithm, reinforcement learning, meta learning",
            "tl;dr": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.",
            "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.",
            "code": "<a href=\"https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb</a>",
            "original-pdf": "<a href=\"/attachment?id=rJgJDAVKvB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "BkgYPREtPr",
            "paper_title": "Symplectic Recurrent Neural Networks",
            "forum_link": "https://openreview.net/forum?id=BkgYPREtPr",
            "pdf_link": "https://openreview.net/pdf?id=BkgYPREtPr",
            "authors": [
                  "Zhengdao Chen",
                  "Jianyu Zhang",
                  "Martin Arjovsky",
                  "L\u00e9on Bottou"
            ],
            "keywords": "Hamiltonian systems, learning physical laws, symplectic integrators, recurrent neural networks, inverse problems",
            "abstract": "We propose Symplectic Recurrent Neural Networks (SRNNs) as learning algorithms that capture the dynamics of physical systems from observed trajectories. SRNNs model the Hamiltonian function of the system by a neural networks, and leverage symplectic integration, multiple-step training and initial state optimization to address the challenging numerical issues associated with Hamiltonian systems. We show SRNNs succeed reliably on complex and noisy Hamiltonian systems. Finally, we show how to augment the SRNN integration scheme in order to handle stiff dynamical systems such as bouncing billiards.",
            "original-pdf": "<a href=\"/attachment?id=BkgYPREtPr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "S1gFvANKDS",
            "paper_title": "Asymptotics of Wide Networks from Feynman Diagrams",
            "forum_link": "https://openreview.net/forum?id=S1gFvANKDS",
            "pdf_link": "https://openreview.net/pdf?id=S1gFvANKDS",
            "authors": [
                  "Ethan Dyer",
                  "Guy Gur-Ari"
            ],
            "tl;dr": "A general method for computing the asymptotic behavior of wide networks using Feynman diagrams",
            "abstract": "Understanding the asymptotic behavior of wide networks is of considerable interest. In this work, we present a general method for analyzing this large width behavior. The method is an adaptation of Feynman diagrams, a standard tool for computing multivariate Gaussian integrals. We apply our method to study training dynamics, improving existing bounds and deriving new results on wide network evolution during stochastic gradient descent. Going beyond the strict large width limit, we present closed-form expressions for higher-order terms governing wide network training, and test these predictions empirically.",
            "original-pdf": "<a href=\"/attachment?id=S1gFvANKDS&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "Sklgs0NFvr",
            "paper_title": "Learning The Difference That Makes A Difference With Counterfactually-Augmented Data",
            "forum_link": "https://openreview.net/forum?id=Sklgs0NFvr",
            "pdf_link": "https://openreview.net/pdf?id=Sklgs0NFvr",
            "authors": [
                  "Divyansh Kaushik",
                  "Eduard Hovy",
                  "Zachary Lipton"
            ],
            "tl;dr": "Humans in the loop revise documents to accord with counterfactual labels, resulting resource helps to reduce reliance on spurious associations.",
            "abstract": "Despite alarm over the reliance of machine learning systems on so-called spurious patterns, the term lacks coherent meaning in standard statistical frameworks. However, the language of causality offers clarity: spurious associations are due to confounding (e.g., a common cause), but not direct or indirect causal effects. In this paper, we focus on natural language processing, introducing methods and resources  for training models less sensitive to spurious patterns. Given documents and their initial labels, we task humans with revising each document so that it (i) accords with a counterfactual target label; (ii) retains internal coherence;  and (iii) avoids unnecessary changes. Interestingly, on sentiment analysis and natural language inference tasks, classifiers trained on original data fail on their  counterfactually-revised counterparts and vice versa. Classifiers trained on combined datasets  perform remarkably well, just shy of those specialized to either domain. While classifiers trained on either original or manipulated data alone  are sensitive to spurious features (e.g., mentions of genre), models trained on the combined data are less sensitive to this signal. Both datasets are publicly available.",
            "keywords": "humans in the loop, annotation artifacts, text classification, sentiment analysis, natural language inference",
            "code": "<a href=\"https://github.com/dkaushik96/counterfactually-augmented-data\" target=\"_blank\" rel=\"nofollow noreferrer\">https://github.com/dkaushik96/counterfactually-augmented-data</a>",
            "original-pdf": "<a href=\"/attachment?id=Sklgs0NFvr&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      },
      {
            "data_id": "r1genAVKPB",
            "paper_title": "Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?",
            "forum_link": "https://openreview.net/forum?id=r1genAVKPB",
            "pdf_link": "https://openreview.net/pdf?id=r1genAVKPB",
            "authors": [
                  "Simon S. Du",
                  "Sham M. Kakade",
                  "Ruosong Wang",
                  "Lin F. Yang"
            ],
            "keywords": "reinforcement learning, function approximation, lower bound, representation",
            "tl;dr": "Exponential lower bounds for value-based and policy-based reinforcement learning with function approximation.",
            "abstract": "Modern deep learning methods provide effective means to learn good representations. However, is a good representation itself sufficient for sample efficient reinforcement learning? This question has largely been studied only with respect to (worst-case) approximation error, in the more classical approximate dynamic programming literature. With regards to the statistical viewpoint, this question is largely unexplored, and the extant body of literature mainly focuses on conditions which \\emph{permit} sample efficient reinforcement learning with little understanding of what are \\emph{necessary} conditions for efficient reinforcement learning.\n        This work shows that, from the statistical viewpoint, the situation is far subtler than suggested by the more traditional approximation viewpoint, where the requirements on the representation that suffice for sample efficient RL are even more stringent. Our main results&nbsp;provide sharp thresholds for reinforcement learning methods, showing that there are hard limitations on what constitutes good function approximation (in terms of the dimensionality of the representation), where we focus on natural representational conditions relevant to value-based, model-based, and policy-based learning. These lower bounds highlight that having a good (value-based, model-based, or policy-based) representation in and of itself is insufficient for efficient reinforcement learning, unless the quality of this approximation passes certain hard thresholds. Furthermore, our lower bounds also imply exponential separations on the sample complexity between 1) value-based learning with perfect representation and value-based learning with a good-but-not-perfect representation, 2) value-based learning and policy-based learning, 3) policy-based learning and supervised learning and 4) reinforcement learning and imitation learning.",
            "original-pdf": "<a href=\"/attachment?id=r1genAVKPB&amp;name=original_pdf\" class=\"attachment-download-link\" title=\"Download Original Pdf\" target=\"_blank\"><span class=\"glyphicon glyphicon-download-alt\" aria-hidden=\"true\"></span> &nbsp;pdf</a>"
      }
]